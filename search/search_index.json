{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"pages/cheatsheet/","title":"Cheatsheet","text":""},{"location":"pages/cheatsheet/#executable-code-replit","title":"Executable Code (REPLIT)","text":"<p>Change values <code>ASTRA_DB_TOKEN</code>, <code>ASTRA_DB_ID</code>, <code>ASTRA_DB_REGION</code>, <code>ASTRA_DB_KEYSPACE</code> in the code below and execute with</p> <p></p>"},{"location":"pages/cheatsheet/#mermaids","title":"Mermaids","text":""},{"location":"pages/cheatsheet/#1-flow","title":"1\ufe0f\u20e3 Flow","text":"<p>Cassandra</p> GraphCode <pre><code>graph LR\n    user&gt;fa:fa-user Developer]-- Create Database --&gt; cassandra[(fa:fa-database Cassandra)]\n\n    user-- Design --&gt;usecase{{fa:fa-cube Use Case}}\n    usecase-- Workflow --&gt;queries[fa:fa-bezier-curve queries]\n    usecase-- MCD --&gt;entities[fa:fa-grip-vertical entities]\n    queries-- Chebotko modelization --&gt;schema[fa:fa-list schema]\n    entities-- Chebotko modelization --&gt;schema[fa:fa-list schema]\n    schema[fa:fa-list  schema]-- Inject --&gt;cassandra[(fa:fa-database Cassandra)]\n\n    user-- prepare --&gt;dataset{{fa:fa-coings DataSet}}\n    dataset-- input --&gt;dsbulk-- load data --&gt;cassandra\n\n    user-- Create Token --&gt;token{{fa:fa-key Token}}\n    usecase--&gt;API\n\n    API--&gt;Request\n    token--&gt;Request\n    schema--&gt;Request\n    Request-- invoke --&gt;cassandra</code></pre> <pre><code>graph LR\n    user&gt;fa:fa-user Developer]-- Create Database --&gt; cassandra[(fa:fa-database Cassandra)]\nuser-- Design --&gt;usecase{{fa:fa-cube Use Case}}\nusecase-- Workflow --&gt;queries[fa:fa-bezier-curve queries]\nusecase-- MCD --&gt;entities[fa:fa-grip-vertical entities]\nqueries-- Chebotko modelization --&gt;schema[fa:fa-list schema]\nentities-- Chebotko modelization --&gt;schema[fa:fa-list schema]\nschema[fa:fa-list  schema]-- Inject --&gt;cassandra[(fa:fa-database Cassandra)]\nuser-- prepare --&gt;dataset{{fa:fa-coings DataSet}}\ndataset-- input --&gt;dsbulk-- load data --&gt;cassandra\n\nuser-- Create Token --&gt;token{{fa:fa-key Token}}\nusecase--&gt;API\n\nAPI--&gt;Request\n    token--&gt;Request\n    schema--&gt;Request\n    Request-- invoke --&gt;cassandra\n</code></pre> <p>Example #1</p> OutputMarkdown <pre><code>graph TD;\n  A--&gt;B;\n  A--&gt;C;\n  B--&gt;D;\n  C--&gt;D;</code></pre> <pre><code>   ```mermaid\n   graph TD;\n     A--&gt;B;\n     A--&gt;C;\n     B--&gt;D;\n     C--&gt;D;\n   ```\n</code></pre> <p>Example3</p> OutputMarkdown <pre><code>graph TD\n  A[Hard] --&gt;|Text| B(Round)\n  B --&gt; C{Decision}\n  C --&gt;|One| D[Result 1]\n  C --&gt;|Two| E[Result 2]</code></pre> <pre><code>   ```mermaid\n   graph TD\n     A[Hard] --&gt;|Text| B(Round)\n     B --&gt; C{Decision}\n     C --&gt;|One| D[Result 1]\n     C --&gt;|Two| E[Result 2]\n   ```\n</code></pre>"},{"location":"pages/cheatsheet/#2-sequence","title":"2\ufe0f\u20e3 Sequence","text":"OutputMarkdown <pre><code>sequenceDiagram\nAlice-&gt;&gt;John: Hello John, how are you?\nloop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\nend\nNote right of John: Rational thoughts!\nJohn--&gt;&gt;Alice: Great!\nJohn-&gt;&gt;Bob: How about you?\nBob--&gt;&gt;John: Jolly good!</code></pre> <pre><code>   ```mermaid\n   sequenceDiagram\n   Alice-&gt;&gt;John: Hello John, how are you?\n   loop Healthcheck\n       John-&gt;&gt;John: Fight against hypochondria\n   end\n   Note right of John: Rational thoughts!\n   John--&gt;&gt;Alice: Great!\n   John-&gt;&gt;Bob: How about you?\n   Bob--&gt;&gt;John: Jolly good!\n\n   ```\n</code></pre>"},{"location":"pages/cheatsheet/#3-gantt","title":"3\ufe0f\u20e3 Gantt","text":"OutputMarkdown <pre><code>gantt\nsection Section\nCompleted :done,    des1, 2014-01-06,2014-01-08\nActive        :active,  des2, 2014-01-07, 3d\nParallel 1   :         des3, after des1, 1d\nParallel 2   :         des4, after des1, 1d\nParallel 3   :         des5, after des3, 1d\nParallel 4   :         des6, after des4, 1d</code></pre> <pre><code>   ```mermaid\n   gantt\n   section Section\n   Completed :done,    des1, 2014-01-06,2014-01-08\n   Active        :active,  des2, 2014-01-07, 3d\n   Parallel 1   :         des3, after des1, 1d\n   Parallel 2   :         des4, after des1, 1d\n   Parallel 3   :         des5, after des3, 1d\n   Parallel 4   :         des6, after des4, 1d\n\n   ```\n</code></pre>"},{"location":"pages/cheatsheet/#4-class","title":"4\ufe0f\u20e3 Class","text":"OutputMarkdown <pre><code>classDiagram\nClass01 &lt;|-- AveryLongClass : Cool\n&lt;&lt;interface&gt;&gt; Class01\nClass09 --&gt; C2 : Where am i?\nClass09 --* C3\nClass09 --|&gt; Class07\nClass07 : equals()\nClass07 : Object[] elementData\nClass01 : size()\nClass01 : int chimp\nClass01 : int gorilla\nclass Class10 {\n &lt;&lt;service&gt;&gt;\n int id\n size()\n}</code></pre> <pre><code>   ```mermaid\n   classDiagram\n   Class01 &lt;|-- AveryLongClass : Cool\n   &lt;&lt;interface&gt;&gt; Class01\n   Class09 --&gt; C2 : Where am i?\n   Class09 --* C3\n   Class09 --|&gt; Class07\n   Class07 : equals()\n   Class07 : Object[] elementData\n   Class01 : size()\n   Class01 : int chimp\n   Class01 : int gorilla\n   class Class10 {\n    &lt;&lt;service&gt;&gt;\n    int id\n    size()\n   }\n\n   ```\n</code></pre>"},{"location":"pages/cheatsheet/#5-state","title":"5\ufe0f\u20e3 State","text":"OutputMarkdown <pre><code>stateDiagram-v2\n[*] --&gt; Still\nStill --&gt; [*]\nStill --&gt; Moving\nMoving --&gt; Still\nMoving --&gt; Crash\nCrash --&gt; [*]</code></pre> <pre><code>   ```mermaid\n   stateDiagram-v2\n   [*] --&gt; Still\n   Still --&gt; [*]\n   Still --&gt; Moving\n   Moving --&gt; Still\n   Moving --&gt; Crash\n   Crash --&gt; [*]\n\n   ```\n</code></pre>"},{"location":"pages/cheatsheet/#6-pie","title":"6\ufe0f\u20e3 Pie","text":"OutputMarkdown <pre><code>pie\n\"Dogs\" : 386\n\"Cats\" : 85\n\"Rats\" : 15</code></pre> <pre><code>   ```mermaid\n   pie\n   \"Dogs\" : 386\n   \"Cats\" : 85\n   \"Rats\" : 15\n\n   ```\n</code></pre>"},{"location":"pages/cheatsheet/#7-journey","title":"7\ufe0f\u20e3 Journey","text":"OutputMarkdown <pre><code>journey\n  title My working day\n  section Go to work\n    Make tea: 5: Me\n    Go upstairs: 3: Me\n    Do work: 1: Me, Cat\n  section Go home\n    Go downstairs: 5: Me\n    Sit down: 3: Me</code></pre> <pre><code>   ```mermaid\n   journey\n    title My working day\n    section Go to work\n      Make tea: 5: Me\n      Go upstairs: 3: Me\n      Do work: 1: Me, Cat\n    section Go home\n      Go downstairs: 5: Me\n      Sit down: 3: Me\n\n   ```\n</code></pre>"},{"location":"pages/cheatsheet/#8-er","title":"8\ufe0f\u20e3 ER","text":"OutputMarkdown <pre><code>erDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses</code></pre> <pre><code>   ```mermaid\n   erDiagram\n     CUSTOMER ||--o{ ORDER : places\n     ORDER ||--|{ LINE-ITEM : contains\n     CUSTOMER }|..|{ DELIVERY-ADDRESS : uses\n   ```\n</code></pre>"},{"location":"pages/cheatsheet/#sample-blocs","title":"Sample Blocs","text":"<p>THis is a note</p> <p>my note</p> <p>abstract</p> <p>my note</p> <p>info</p> <p>info</p> Sample tip  <p>tip</p> How to add plugins to the Docker image? <p>Import Stuff</p> <p>Success</p> <p>my note</p> <p>Sample warning</p> <p>This is so cool.</p> <p>failure</p> <p>my note</p> <p>danger</p> <p>danger</p> <p>bug</p> <p>bug</p> Sample example <p>example</p> <p>Sample warning</p> <p>warning</p> Sample wuote <p>quote</p>"},{"location":"pages/cheatsheet/#tooltip","title":"Tooltip","text":"<pre><code>wanna a tooltip ? # (1)!\n</code></pre> <ol> <li> <p>Cedrick rock</p> <pre><code>mkdocs serve\n</code></pre> </li> </ol>"},{"location":"pages/cheatsheet/#icons","title":"Icons","text":""},{"location":"pages/cheatsheet/#material","title":"Material","text":"<p>HERE is the full list</p>"},{"location":"pages/cheatsheet/#font-awesome","title":"Font Awesome","text":"<p>HTML</p> <li> = fa-camera-retro</li> <p>MARKDOWN </p> <p>HERE is the full list</p>"},{"location":"pages/cheatsheet/#opticons","title":"Opticons","text":"<p> Sample</p>"},{"location":"pages/cheatsheet/#adding-buttons","title":"Adding buttons","text":"<p>In order to render a link as a button, suffix it with curly braces and add the <code>.md-button</code> class selector to it. The button will receive the selected [primary color] and [accent color] if active.</p> Button<pre><code>[Subscribe to our newsletter](#){ .md-button }\n</code></pre> <p>[Subscribe to our newsletter][demo]{ .md-button }</p> <p>[Subscribe to our newsletter][demo]{ .md-button .md-button--primary }</p>"},{"location":"pages/astra/","title":"Getting Started With Astra","text":""},{"location":"pages/astra/#greetings-developers","title":"Greetings Developers !","text":"<p>Datastax created Astra which provides Apache Cassandra databases in the cloud. You can start for free with no credit card and no time limits.</p> <p>A lot of effort has been put to ease the usage of the database with some developer friendly apis.</p> <p> <p></p> <p></p>"},{"location":"pages/astra/#whats-next","title":"What's NEXT ?","text":"<p>With your database running, you may want to learn more about Apis exposed by running Quick Start guides.</p> <p>info</p> <p>The Getting started guides for each Api are being created as we speak, please come back in a week to get them.</p> <p>Then when you feel confident, pick the language of your choice in friendly apis and start building amazing apps.</p>"},{"location":"pages/astra/astra-cli/","title":"\u2023 Astra CLI","text":""},{"location":"pages/astra/astra-cli/#overview","title":"Overview","text":"<p>CLI Latest version : </p> <p>Astra CLI is a <code>command line interface</code> used to interact with Datastax astra resources (create, read, update, delete). On top of administration tasks it provides extra features like backup, restore and  migration. It also allows native integration (downloads, setup, execution) with tools from the ecosystem  like cqlsh, dsbulk, dsbulk-migrator, or pulsar-shell.</p>"},{"location":"pages/astra/astra-cli/#1-installation","title":"1. Installation","text":""},{"location":"pages/astra/astra-cli/#11-installation-on-linux","title":"1.1. Installation on <code>Linux</code>","text":"<p>This software has been built with Java and compiled as native executables for each platform. The installation script will download the archives and extract all files in <code>~/.astra</code>, it is inspired from <code>sdkman</code>. </p> Information Path Installation Folder: Contains archive and third-party tools <code>~/.astra</code> Configuration File: Hold configs and credentials, will not be lost when updating <code>~/.astrarc</code> <p>Your <code>bash_profile, bashrc, zhrc</code> will be amended to add <code>astra</code> in the path and run the bash autocompletion file at startup.</p> <p>\u2705 Installation</p> <pre><code>curl -Ls \"https://dtsx.io/get-astra-cli\" | bash\n</code></pre> <p>\u2705 Upgrade</p> <pre><code>curl -Ls \"https://dtsx.io/get-astra-cli\" | bash\n</code></pre> <p>\u2705 Uninstall</p> <pre><code>rm -R ~/.astra\nrm ~/.astrarc\n</code></pre>"},{"location":"pages/astra/astra-cli/#12-installation-on-osx","title":"1.2. Installation on <code>osx</code>","text":"<p>Homebrew is a package manager for OSX install homebrew</p> <p>Homebrew is the recommended solution to manage Astra CLI. It provides convenient ways to install, update, and uninstall. It will install tools required for external components as well like proper Java and python versions.</p> Do not want to use homebrew ? <p><code>osx</code> is based on a linux kernel and can run shell scripts.  The Linux installation procedure also work on mac machines.</p> <p>\u2705 Installation</p> <pre><code>brew install datastax/astra-cli/astra-cli\n</code></pre> <p>\u2705 Update</p> <pre><code>brew upgrade datastax/astra-cli/astra-cli\n</code></pre> <p>\u2705 Uninstall</p> <pre><code>brew uninstall datastax/astra-cli/astra-cli\n</code></pre>"},{"location":"pages/astra/astra-cli/#13-installation-on-windows","title":"1.3. Installation on <code>Windows</code>","text":"<p>Limited features of <code>astra.exe</code></p> <p>This software has been built with Java and compiled as native executables for each platform. As such we provide a windows executable <code>astra.exe</code>. Unfortunately, it does not support execution of external components like <code>DSBULK</code>, <code>CQLSH</code> or <code>PULSAR-SHELL</code>. We recommend to use the <code>Linux</code> procecure in <code>WSL</code>.</p> <p>\u2705 Installation</p> <p>Download a Windows archive astra-cli-${version}-windows.zip. Unzip the archive into a folder of your choice, for instance <code>C:/Programs/astra-cli</code> and add <code>C:/Programs/astra-cli/astra.exe</code> to your path using this tutorial.</p> <p>\u2705 Update</p> <p>No special command, remove the folder <code>C:/Programs/astra-cli/</code> and reinstall.</p> <p>\u2705 Uninstall</p> <p>Remove folder <code>C:/Programs/astra-cli/</code> and <code>.astrarc</code> file in your user home.</p>"},{"location":"pages/astra/astra-cli/#2-getting-started","title":"2. Getting Started","text":""},{"location":"pages/astra/astra-cli/#21-astra-setup","title":"2.1. Astra Setup","text":"<p>\u2705 Create an account on Astra Platform: SIGN IN</p> <p>\u2705 Create a security token with <code>Organization Administration</code> role HOW TO. Your token should start with <code>AstraCS:...</code>.</p>"},{"location":"pages/astra/astra-cli/#22-local-configuration","title":"2.2. Local Configuration","text":"Make sur to have <code>astra</code> in your path <p>After installation you need to open a new terminal for <code>astra</code> to be in your path.</p> <p>\u2705 Issue <code>setup</code> command and provide your token when prompted. It must start by <code>AstraCS:...</code>. Make sure to have the <code>Organization Administrator</code> role to avoid any permission limitations later on.</p> <pre><code>astra setup\n</code></pre> \ud83d\udda5\ufe0f <code>astra setup</code> command output <pre><code> _____            __                  \n/  _  \\   _______/  |_____________    \n/  /_\\  \\ /  ___/\\   __\\_  __ \\__  \\  \n/    |    \\\\___ \\  |  |  |  | \\ //__ \\_ \n\\____|__  /____  &gt; |__|  |__|  (____  /\n        \\/     \\/                   \\/ \n\n                        Version: 0.2.2\n\n-----------------------\n---      SETUP      ---\n-----------------------\n\n$ Enter an Astra token:\n</code></pre> Skip interactive mode <p>This can also be done non-interactively (for example, using a script) by providing token as a flag. Do do it, run:</p> <pre><code>astra setup --token AstraCS:******\n</code></pre> <p>\u2705 Display your local configuration list, validating setup is complete. </p> <pre><code>astra config list\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>+-----------------------------------------+\n| configuration                           |\n+-----------------------------------------+\n| default (cedrick.lunven@datastax.com)   |\n| cedrick.lunven@datastax.com             |\n+-----------------------------------------+\n</code></pre> <p>You can work with multiple organizations and swap from one to another. Creating and managing extra configurations is covered in Advanced Configuration chapter.</p> Scope of Astra security tokens <p>The security tokens are created for an organization only. If you need to work with multiple organizations then multiple tokens are required. You limit the scope of a token to a single database.</p>"},{"location":"pages/astra/astra-cli/#23-autocompletion","title":"2.3. Autocompletion","text":"<p>The cli provides bash autocompletion for <code>bash</code> and <code>zsh</code> shells. Use <code>TAB</code> key twice to get a list of available options.</p> <p>\u2705 Autocomplete</p> <pre><code>astra &lt;TAB&gt; &lt;TAB&gt;\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>--no-color  config      db          help        role        setup       shell       user  \n</code></pre>"},{"location":"pages/astra/astra-cli/#24-documentation","title":"2.4. Documentation","text":"<p>The better documentation of the code is the code itself. This page will provide you samples but where you are not sure use the <code>astra help &lt;my_command&gt;</code></p> <p>\u2705 Display main help</p> <pre><code>astra help\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>usage: astra &lt;command&gt; [ &lt;args&gt; ]\n\nCommands are:\n    ?           Display this help version\n    help        Display help information\n    setup       Initialize configuration file\n    config      Manage configuration file\n    db          Manage databases\n    org         Display Organization Info\n    role        Manage roles\n    streaming   Manage Streaming tenants\n    token       Manage tokens\n    user        Manage users\n\nSee 'astra help &lt;command&gt;' for more information on a specific command.\n</code></pre> <p>\u2705 Display help for a command group <code>astra db</code></p> <pre><code>astra help db\n</code></pre> <p>\u2705 Display help for unitary command <code>astra db list</code></p> <pre><code>astra help db list\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>NAME\n        astra db list - Display the list of Databases in an organization\n\nSYNOPSIS\n        astra db list [ {-conf | --config} &lt;CONFIG_SECTION&gt; ]\n                [ --config-file &lt;CONFIG_FILE&gt; ] [ --log &lt;LOG_FILE&gt; ]\n                [ --no-color ] [ {-o | --output} &lt;FORMAT&gt; ]\n                [ --token &lt;AUTH_TOKEN&gt; ] [ {-v | --verbose} ]\n\nOPTIONS\n        -conf &lt;CONFIG_SECTION&gt;, --config &lt;CONFIG_SECTION&gt;\n            Section in configuration file (default = ~/.astrarc)\n\n        --config-file &lt;CONFIG_FILE&gt;\n            Configuration file (default = ~/.astrarc)\n\n        --log &lt;LOG_FILE&gt;\n            Logs will go in the file plus on console\n\n        --no-color\n            Remove all colors in output\n\n        -o &lt;FORMAT&gt;, --output &lt;FORMAT&gt;\n            Output format, valid values are: human,json,csv\n\n        --token &lt;AUTH_TOKEN&gt;\n            Key to use authenticate each call.\n\n        -v, --verbose\n            Verbose mode with log in console\n</code></pre>"},{"location":"pages/astra/astra-cli/#25-important-options","title":"2.5. Important Options","text":"<p>Each commands has some specific parameters but all commands share have the following options.</p> Name Option Description verbose <code>-v</code> Make the output more verbose, debug remove colors <code>--no-color</code> Remove colors, ease parsing and display json output <code>-o json</code> To ease parsing output can be json csv output <code>-o csv</code> To ease export output can be CSV override token <code>--token ...</code> Enforce token for this command override config <code>--config ...</code> Change section use in <code>~/.astrarc</code> for the command override config-file <code>--config-file ...</code> Do not use <code>~/.astrarc</code> for the command"},{"location":"pages/astra/astra-cli/#3-astra-db","title":"3. Astra DB","text":"Synchronous/Asynchronous <p>Some commands can take a while like a DB creation or the creation of a new region and data replication. Default behaviour is to be <code>synchronous</code> and <code>wait</code> until the operation is done. You can change this behaviour by using the option <code>--no-wait</code></p>"},{"location":"pages/astra/astra-cli/#31-db-commands-glossary","title":"3.1. DB commands glossary","text":"<p>\u2705 Display available commands for DB</p> <p>The documentation is the tool itself with the following command:</p> <p><pre><code>astra help db\n</code></pre> Still, for ease of use here is a glossary of the commands:</p> Command Purpose <code>count &lt;DB&gt;</code> Count records in a table <code>cqlsh &lt;DB&gt;</code> Setup and run <code>cqlsh</code>: interactive, <code>-e</code> and <code>-f</code> all supported <code>create &lt;DB&gt;</code> Create a database <code>create-cdc &lt;DB&gt;</code> Create Change Data Capture to Pulsar <code>create-dotenv &lt;DB&gt;</code> Create environment file <code>.env</code> <code>create-keyspace &lt;DB&gt;</code> Create a keyspace <code>create-region &lt;DB&gt;</code> Expand database to a rew region (multi-region) <code>delete &lt;DB&gt;</code> Delete a database <code>delete-cdc &lt;DB&gt;</code> Delete a change data capture <code>delete-keyspace &lt;DB&gt;</code> Delete a keyspace <code>delete-region &lt;DB&gt;</code> Remove a region from a database <code>describe &lt;DB&gt;</code> Describe metadata of a database <code>download-scb &lt;DB&gt;</code> Download the secure connect bundle for database region <code>get &lt;DB&gt;</code> Describe metadata of a database <code>list</code> List databases in the organization <code>list-cdc &lt;DB&gt;</code> List Change Data Captures <code>list-clouds</code> List clouds available to deploy db <code>list-keyspaces &lt;DB&gt;</code> List keyspaces for a DB <code>list-regions &lt;DB&gt;</code> List regions (datacenters) for a DB <code>list-regions-classic</code> List available regions for classic <code>list-regions-serverless</code> List available regions for serverless <code>load &lt;DB&gt;</code> Load a CSV into a table <code>playground &lt;DB&gt;</code> Show GraphQL Playground URL <code>resume &lt;DB&gt;</code> Resume DB that was hibernated <code>status &lt;DB&gt;</code> Show DB Status <code>swagger &lt;DB&gt;</code> Show swagger url <code>unload &lt;DB&gt;</code> Leverage DSbulk to dump data"},{"location":"pages/astra/astra-cli/#32-list","title":"3.2. List","text":"<p>\u2705 1a - list</p> <p>To get the list of non-terminated databases in your organization, use the command <code>list</code> in the group <code>db</code>.</p> <pre><code>astra db list\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>+---------------------+--------------------------------------+---------------------+----------------+\n| Name                | id                                   | Default Region      | Status         |\n+---------------------+--------------------------------------+---------------------+----------------+\n| mtg                 | dde308f5-a8b0-474d-afd6-81e5689e3e25 | eu-central-1        | ACTIVE         |\n| workshops           | 3ed83de7-d97f-4fb6-bf9f-82e9f7eafa23 | eu-west-1           | ACTIVE         |\n| sdk_tests           | 06a9675a-ca62-4cd0-9b94-aefaf395922b | us-east-1           | ACTIVE         |\n| test                | 7677a789-bd57-455d-ab2c-a3bdfa35ba68 | eu-central-1        | ACTIVE         |\n| demo                | 071d7059-d55b-4cdb-90c6-41c26da1a029 | us-east-1           | ACTIVE         |\n| ac201               | 48c7178c-58cb-4657-b3d2-8a9e3cc89461 | us-east-1           | ACTIVE         |\n+---------------------+--------------------------------------+---------------------+----------------+\n</code></pre> <p>\u2705 1b - Get Help</p> <p>To get help on a command, always prefix with <code>astra help XXX</code></p> <pre><code>astra help db list\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>NAME\n        astra db list - Display the list of Databases in an organization\n\nSYNOPSIS\n        astra db list [ {-conf | --config} &lt;CONFIG_SECTION&gt; ]\n                [ --config-file &lt;CONFIG_FILE&gt; ] [ --log &lt;LOG_FILE&gt; ]\n                [ --no-color ] [ {-o | --output} &lt;FORMAT&gt; ]\n                [ --token &lt;AUTH_TOKEN&gt; ] [ {-v | --verbose} ]\n\nOPTIONS\n        -conf &lt;CONFIG_SECTION&gt;, --config &lt;CONFIG_SECTION&gt;\n            Section in configuration file (default = ~/.astrarc)\n\n        --config-file &lt;CONFIG_FILE&gt;\n            Configuration file (default = ~/.astrarc)\n\n        --log &lt;LOG_FILE&gt;\n            Logs will go in the file plus on console\n\n        --no-color\n            Remove all colors in output\n\n        -o &lt;FORMAT&gt;, --output &lt;FORMAT&gt;\n            Output format, valid values are: human,json,csv\n\n        --token &lt;AUTH_TOKEN&gt;\n            Key to use authenticate each call.\n\n        -v, --verbose\n            Verbose mode with log in console\n</code></pre> <p>\u2705 1c - Change output</p> <pre><code>astra db list -o csv\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>Name,id,Default Region,Status\nmtg,dde308f5-a8b0-474d-afd6-81e5689e3e25,eu-central-1,ACTIVE\nworkshops,3ed83de7-d97f-4fb6-bf9f-82e9f7eafa23,eu-west-1,ACTIVE\nsdk_tests,06a9675a-ca62-4cd0-9b94-aefaf395922b,us-east-1,ACTIVE\ntest,7677a789-bd57-455d-ab2c-a3bdfa35ba68,eu-central-1,ACTIVE\ndemo,071d7059-d55b-4cdb-90c6-41c26da1a029,us-east-1,ACTIVE\nac201,48c7178c-58cb-4657-b3d2-8a9e3cc89461,us-east-1,ACTIVE\n</code></pre> <pre><code>astra db list -o json\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>  {\n\"code\" : 0,\n\"message\" : \"astra db list -o json\",\n\"data\" : [ {\n\"Status\" : \"ACTIVE\",\n\"Default Region\" : \"eu-central-1\",\n\"id\" : \"dde308f5-a8b0-474d-afd6-81e5689e3e25\",\n\"Name\" : \"mtg\"\n}, {\n\"Status\" : \"ACTIVE\",\n\"Default Region\" : \"eu-west-1\",\n\"id\" : \"3ed83de7-d97f-4fb6-bf9f-82e9f7eafa23\",\n\"Name\" : \"workshops\"\n}, {\n\"Status\" : \"ACTIVE\",\n\"Default Region\" : \"us-east-1\",\n\"id\" : \"06a9675a-ca62-4cd0-9b94-aefaf395922b\",\n\"Name\" : \"sdk_tests\"\n}, {\n\"Status\" : \"ACTIVE\",\n\"Default Region\" : \"eu-central-1\",\n\"id\" : \"7677a789-bd57-455d-ab2c-a3bdfa35ba68\",\n\"Name\" : \"test\"\n}, {\n\"Status\" : \"ACTIVE\",\n\"Default Region\" : \"us-east-1\",\n\"id\" : \"071d7059-d55b-4cdb-90c6-41c26da1a029\",\n\"Name\" : \"demo\"\n}, {\n\"Status\" : \"ACTIVE\",\n\"Default Region\" : \"us-east-1\",\n\"id\" : \"48c7178c-58cb-4657-b3d2-8a9e3cc89461\",\n\"Name\" : \"ac201\"\n} ]\n}\n</code></pre>"},{"location":"pages/astra/astra-cli/#2-create-database","title":"2. Create database","text":"<p>\u2705 2a - Create Database </p> <p>If not provided, the region will be the default free region, and the keyspace will be the database name, but you can change them with the <code>-r</code> and <code>-k</code> flags, respectively.</p> <pre><code>astra db create demo\n</code></pre> <p>\u2705 2b - Options <code>--if-not-exist</code> and <code>--wait</code> </p> <ul> <li> <p>The database name does not ensure unicity (the database id does). As such, if you issue the command multiple times, you will end up with multiple instances. To change this behavior, you can use <code>--if-not-exist</code></p> </li> <li> <p>Database creation is an asynchronous operation. In some situations, such as during your CI/CD, you will most likely want the db to be <code>ACTIVE</code> before moving forward. The option <code>--wait</code> will trigger a blocking command until the db is ready</p> </li> <li> <p>On the free tier, after a period of inactivity, the database moves to a <code>HIBERNATED</code> state. The creation command will resume the db when needed.</p> </li> </ul> <pre><code>astra db create demo -k ks2 --if-not-exist --wait\n</code></pre> <p>\u2705 2c - Get help </p> <p>To show help, enter the following command: </p> <pre><code>astra help db create\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>NAME\n        astra db create - Create a database with cli\n\nSYNOPSIS\n        astra db create [ {-cf | --config-file} &lt;CONFIG_FILE&gt; ]\n                [ {-conf | --config} &lt;CONFIG_SECTION&gt; ]\n                [ {--if-not-exist | --if-not-exists} ]\n                [ {-k | --keyspace} &lt;KEYSPACE&gt; ] [ --no-color ]\n                [ {-o | --output} &lt;FORMAT&gt; ] [ {-r | --region} &lt;DB_REGION&gt; ]\n                [ --timeout &lt;timeout&gt; ] [ --token &lt;AUTH_TOKEN&gt; ]\n                [ {-v | --verbose} ] [ --wait ] [--] &lt;DB&gt;\n\nOPTIONS\n        -cf &lt;CONFIG_FILE&gt;, --config-file &lt;CONFIG_FILE&gt;\n            Configuration file (default = ~/.astrarc)\n\n        -conf &lt;CONFIG_SECTION&gt;, --config &lt;CONFIG_SECTION&gt;\n            Section in configuration file (default = ~/.astrarc)\n\n        --if-not-exist, --if-not-exists\n            will create a new DB only if none with same name\n\n        -k &lt;KEYSPACE&gt;, --keyspace &lt;KEYSPACE&gt;\n            Default keyspace created with the Db\n\n        --no-color\n            Remove all colors in output\n\n        -o &lt;FORMAT&gt;, --output &lt;FORMAT&gt;\n            Output format, valid values are: human,json,csv\n\n        -r &lt;DB_REGION&gt;, --region &lt;DB_REGION&gt;\n            Cloud provider region to provision\n\n        --timeout &lt;timeout&gt;\n            Provide a limit to the wait period in seconds, default is 300s.\n\n        --token &lt;AUTH_TOKEN&gt;\n            Key to use authenticate each call.\n\n        -v, --verbose\n            Verbose mode with log in console\n\n        --wait\n            Will wait until the database become ACTIVE\n\n        --\n            This option can be used to separate command-line options from the\n            list of arguments (useful when arguments might be mistaken for\n            command-line options)\n\n        &lt;DB&gt;\n            Database name (not unique)\n</code></pre>"},{"location":"pages/astra/astra-cli/#3-resume-database","title":"3. Resume database","text":"<p>In the free tier, after 23H of inactivity, your database will be hibernated. To wake up the db, you can use the <code>resume</code> command.</p> <p>\u2705 2a - Resuming </p> <ul> <li>Assuming you have an hibernating database.</li> </ul> <pre><code>astra db list\n</code></pre> <pre><code>+---------------------+--------------------------------------+---------------------+----------------+\n| Name                | id                                   | Default Region      | Status         |\n+---------------------+--------------------------------------+---------------------+----------------+\n| hemidactylus        | 643c6bb8-2336-4649-97d5-39c33491f5c1 | eu-central-1        | HIBERNATED     |\n+---------------------+--------------------------------------+---------------------+----------------+\n</code></pre> <ul> <li>Trigger an explicit resuming with:</li> </ul> <pre><code>astra db resume hemidactylus\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>+---------------------+--------------------------------------+---------------------+----------------+\n| Name                | id                                   | Default Region      | Status         |\n+---------------------+--------------------------------------+---------------------+----------------+\n| hemidactylus        | 643c6bb8-2336-4649-97d5-39c33491f5c1 | eu-central-1        | RESUMING       |\n+---------------------+--------------------------------------+---------------------+----------------+\n\nAnd after a few time\n+---------------------+--------------------------------------+---------------------+----------------+\n| Name                | id                                   | Default Region      | Status         |\n+---------------------+--------------------------------------+---------------------+----------------+\n| hemidactylus        | 643c6bb8-2336-4649-97d5-39c33491f5c1 | eu-central-1        | ACTIVE         |\n+---------------------+--------------------------------------+---------------------+----------------+\n</code></pre>"},{"location":"pages/astra/astra-cli/#4-get-database-details","title":"4. Get database details","text":"<p>\u2705 4a. To get general information or details on an entity use the command <code>get</code>.</p> <pre><code>astra db get demo\n</code></pre> <p>In the output, you specially see the list of keyspaces available and the different regions.</p> \ud83d\udda5\ufe0f Sample output <pre><code>+------------------------+-----------------------------------------+\n| Attribute              | Value                                   |\n+------------------------+-----------------------------------------+\n| Name                   | demo                                    |\n| id                     | 071d7059-d55b-4cdb-90c6-41c26da1a029    |\n| Status                 | ACTIVE                                  |\n| Default Cloud Provider | AWS                                     |\n| Default Region         | us-east-1                               |\n| Default Keyspace       | demo                                    |\n| Creation Time          | 2022-07-26T15:41:18Z                    |\n|                        |                                         |\n| Keyspaces              | [0] demo                                |\n|                        |                                         |\n| Regions                | [0] us-east-1                           |\n+------------------------+-----------------------------------------+\n</code></pre> <p>\u2705 4b. To get a special property, you can add the option <code>--key</code>. Multiple keys are available: <code>id</code>, <code>status</code>, <code>cloud</code>, <code>keyspace</code>, <code>keyspaces</code>, <code>region</code>, <code>regions</code>. Notice that the output is raw. This command is expected to be used in scripts</p> <pre><code>astra db get demo --key id\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>dde308f5-a8b0-474d-afd6-81e5689e3e25\n</code></pre> <p>\u2705 4c. To get database status in a human-readable form, use <code>status</code> command</p> <pre><code>astra db status demo\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>[ INFO ] - Database 'demo' has status 'ACTIVE'\n</code></pre>"},{"location":"pages/astra/astra-cli/#5-delete-database","title":"5. Delete Database","text":"<p>\u2705 5a. To delete a db use the command <code>delete</code>.</p> <pre><code>astra db delete demo2\n</code></pre>"},{"location":"pages/astra/astra-cli/#6-working-with-keyspaces","title":"6. Working with keyspaces","text":"<p>A keyspace is created when you create the database. The default CLI behaviour is to provide the same values for keyspace and database names. You can also define your own keyspace name with the flag <code>-k</code>.</p> <p>\u2705 6a - Create new keyspace </p> <ul> <li>To add a keyspace <code>ks2</code> to an existing database <code>demo</code> use the following. The option <code>--if-not-exist</code> is optional but could help you provide idempotent scripts.</li> </ul> <pre><code>astra db create-keyspace demo -k ks2 --if-not-exist\n</code></pre> <ul> <li>If the database is not found, you will get a warning message and a dedicated code returned. To see your new keyspace, you can display your database details.</li> </ul> <pre><code>astra db list-keyspaces demo\n</code></pre> <p>\u2705 6b - Get help </p> <pre><code>astra help db create-keyspace\n</code></pre>"},{"location":"pages/astra/astra-cli/#7-cqlsh","title":"7. Cqlsh","text":"<p>Cqlsh is a standalone shell to work with Apache Cassandra\u2122. It is compliant with Astra but requires a few extra steps of configuration. The purpose of the CLI is to integrate with <code>cqlsh</code> and do the integration for you.</p> <p>Astra CLI will download, install, setup and wrap <code>cqlsh</code> for you to interact with Astra.</p> <p>\u2705 7a - Interactive mode </p> <p>If no options are provided,  you enter <code>cqlsh</code> interactive mode</p> <pre><code>astra db cqlsh demo\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>Cqlsh is starting please wait for connection establishment...\nConnected to cndb at 127.0.0.1:9042.\n[cqlsh 6.8.0 | Cassandra 4.0.0.6816 | CQL spec 3.4.5 | Native protocol v4]\nUse HELP for help.\ntoken@cqlsh&gt;\n</code></pre> <p>\u2705 7b - Execute CQL </p> <p>To execute CQL Statements with <code>cqlsh</code> use the flag <code>-e</code>.</p> <pre><code>astra db cqlsh demo -e \"describe keyspaces;\"\n</code></pre> <p>\u2705 7b - Execute CQL Files </p> <p>To execute CQL Files with <code>cqlsh</code> use the flag <code>-f</code>. You could also use the CQL syntax SOURCE.</p> <pre><code>astra db cqlsh demo -f sample.cql\n</code></pre>"},{"location":"pages/astra/astra-cli/#8-dsbulk-commands","title":"8. DSBulk Commands","text":"<p>\u2705 8a - Setup </p> <p>DSBulk stands for DataStax Bulk Loader. It is a standalone program to load, unload, and count data in an efficient way with Apache Cassandra\u2122. It is compliant with DataStax Astra DB.</p> <p>Similar to <code>cqlsh</code> the CLI will download, install, setup and wrap the dsbulk command for you. All options are available. To give you an idea, let's take a simple example.</p> <ul> <li>Make sure we have a db <code>demo</code> with a keyspace <code>demo</code></li> </ul> <pre><code>astra db create demo\n</code></pre> <ul> <li>Looking at a dataset of cities in the world. cities.csv. We can show here the first lines of the  file.</li> </ul> <pre><code>id,name,state_id,state_code,state_name,country_id,country_code,country_name,latitude,longitude,wikiDataId\n52,Ashk\u0101sham,3901,BDS,Badakhshan,1,AF,Afghanistan,36.68333000,71.53333000,Q4805192\n68,Fayzabad,3901,BDS,Badakhshan,1,AF,Afghanistan,37.11664000,70.58002000,Q156558\n...\n</code></pre> <ul> <li>Let's create a table to store those values. Connect to CQLSH</li> </ul> <pre><code>astra db cqlsh demo -k demo\n</code></pre> <ul> <li>Create the table </li> </ul> <pre><code>CREATE TABLE cities_by_country (\ncountry_name text,\nname       text,\nid         int,\nstate_id   text,\nstate_code text,\nstate_name text,\ncountry_id text,\ncountry_code text,\nlatitude double,\nlongitude double,\nwikiDataId text,\nPRIMARY KEY ((country_name), name)\n);\ndescribe table cities_by_country;\nquit\n</code></pre> <p>\u2705 8b - Load Data </p> <pre><code>astra db load demo \\\n  -url https://raw.githubusercontent.com/awesome-astra/docs/main/docs/assets/cities.csv \\\n  -k demo \\\n  -t cities_by_country \\\n  --schema.allowMissingFields true\n</code></pre> <p>The first time the line <code>DSBulk is starting please wait</code> can take a few seconds to appear. The reason is that the CLI is downloading <code>dsbulk</code> if it was not downloaded before.</p> \ud83d\udda5\ufe0f Sample output <pre><code>DSBulk is starting please wait ...\nUsername and password provided but auth provider not specified, inferring PlainTextAuthProvider\nA cloud secure connect bundle was provided: ignoring all explicit contact points.\nA cloud secure connect bundle was provided and selected operation performs writes: changing default consistency level to LOCAL_QUORUM.\nOperation directory: /Users/cedricklunven/Downloads/logs/LOAD_20220823-182343-074618\nSetting executor.maxPerSecond not set when connecting to DataStax Astra: applying a limit of 9,000 ops/second based on the number of coordinators (3).\nIf your Astra database has higher limits, please define executor.maxPerSecond explicitly.\n  total | failed | rows/s |  p50ms |  p99ms | p999ms | batches\n148,266 |      0 |  8,361 | 663.86 | 767.56 | 817.89 |   30.91\nOperation LOAD_20220823-182343-074618 completed successfully in 17 seconds.\nLast processed positions can be found in positions.txt\n</code></pre> <p>\u2705 8c - Count </p> <p>Check that the data has been imported with cqlsh.</p> <pre><code>astra db cqlsh demo -e \"select * from demo.cities_by_country LIMIT 20;\"\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>Cqlsh is starting please wait for connection establishment...\n\ncountry_name | name                | country_code | country_id | id   | latitude | longitude | state_code | state_id | state_name          | wikidataid\n--------------+---------------------+--------------+------------+------+----------+-----------+------------+----------+---------------------+------------\n  Bangladesh |             Azimpur |           BD |         19 | 8454 |  23.7298 |   90.3854 |         13 |      771 |      Dhaka District |       null\n  Bangladesh |           Badarganj |           BD |         19 | 8455 | 25.67419 |  89.05377 |         55 |      759 |    Rangpur District |       null\n  Bangladesh |            Bagerhat |           BD |         19 | 8456 |     22.4 |     89.75 |         27 |      811 |     Khulna District |       null\n  Bangladesh |           Bandarban |           BD |         19 | 8457 |       22 |  92.33333 |          B |      803 | Chittagong Division |       null\n  Bangladesh |          Baniachang |           BD |         19 | 8458 | 24.51863 |  91.35787 |         60 |      767 |     Sylhet District |       null\n  Bangladesh |             Barguna |           BD |         19 | 8459 | 22.13333 |  90.13333 |         06 |      818 |    Barisal District |       null\n  Bangladesh |             Barisal |           BD |         19 | 8460 |     22.8 |      90.5 |         06 |      818 |    Barisal District |       null\n  Bangladesh |                Bera |           BD |         19 | 8462 | 24.07821 |  89.63262 |         54 |      813 |   Rajshahi District |       null\n  Bangladesh |       Bhairab B\u0101z\u0101r |           BD |         19 | 8463 |  24.0524 |   90.9764 |         13 |      771 |      Dhaka District |       null\n  Bangladesh |           Bher\u0101m\u0101ra |           BD |         19 | 8464 | 24.02452 |  88.99234 |         27 |      811 |     Khulna District |       null\n  Bangladesh |               Bhola |           BD |         19 | 8465 | 22.36667 |  90.81667 |         06 |      818 |    Barisal District |       null\n  Bangladesh |           Bh\u0101nd\u0101ria |           BD |         19 | 8466 | 22.48898 |  90.06273 |         06 |      818 |    Barisal District |       null\n  Bangladesh | Bh\u0101tp\u0101ra Abhaynagar |           BD |         19 | 8467 | 23.01472 |  89.43936 |         27 |      811 |     Khulna District |       null\n  Bangladesh |           Bibir Hat |           BD |         19 | 8468 | 22.68347 |  91.79058 |          B |      803 | Chittagong Division |       null\n  Bangladesh |               Bogra |           BD |         19 | 8469 | 24.78333 |     89.35 |         54 |      813 |   Rajshahi District |       null\n  Bangladesh |        Brahmanbaria |           BD |         19 | 8470 | 23.98333 |  91.16667 |          B |      803 | Chittagong Division |       null\n  Bangladesh |         Burh\u0101nuddin |           BD |         19 | 8471 | 22.49518 |  90.72391 |         06 |      818 |    Barisal District |       null\n  Bangladesh |            B\u0101jitpur |           BD |         19 | 8472 | 24.21623 |  90.95002 |         13 |      771 |      Dhaka District |       null\n  Bangladesh |            Chandpur |           BD |         19 | 8474 |    23.25 |  90.83333 |          B |      803 | Chittagong Division |       null\n  Bangladesh |    Chapai Nababganj |           BD |         19 | 8475 | 24.68333 |     88.25 |         54 |      813 |   Rajshahi District |       null\n</code></pre> <ul> <li>Count with ds bulkd</li> </ul> <pre><code>astra db count demo -k demo -t cities_by_country\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>DSBulk is starting please wait ...\n[INFO ] - RUNNING: /Users/cedricklunven/.astra/dsbulk-1.9.1/bin/dsbulk count -k demo -t cities_by_country -u token -p AstraCS:gdZaqzmFZszaBTOlLgeecuPs:edd25600df1c01506f5388340f138f277cece2c93cb70f4b5fa386490daa5d44 -b /Users/cedricklunven/.astra/scb/scb_071d7059-d55b-4cdb-90c6-41c26da1a029_us-east-1.zip\nUsername and password provided but auth provider not specified, inferring PlainTextAuthProvider\nA cloud secure connect bundle was provided: ignoring all explicit contact points.\nOperation directory: /Users/cedricklunven/Downloads/logs/COUNT_20220823-182833-197954\n  total | failed | rows/s |  p50ms |  p99ms | p999ms\n134,574 |      0 | 43,307 | 315.71 | 457.18 | 457.18\n</code></pre> <p>\u2705 8d - Unload Data </p> <pre><code>astra db unload demo -k demo -t cities_by_country -url /tmp/unload\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>DSBulk is starting please wait ...\nUsername and password provided but auth provider not specified, inferring PlainTextAuthProvider\nA cloud secure connect bundle was provided: ignoring all explicit contact points.\nOperation directory: /Users/cedricklunven/Downloads/logs/UNLOAD_20220823-183054-208353\n  total | failed | rows/s |  p50ms |    p99ms |   p999ms\n134,574 |      0 | 14,103 | 927.51 | 1,853.88 | 1,853.88\nOperation UNLOAD_20220823-183054-208353 completed successfully in 9 seconds.\n</code></pre>"},{"location":"pages/astra/astra-cli/#9-download-secure-bundle","title":"9. Download Secure bundle","text":"<p>\u2705 9a - Default values </p> <p>Download the different secure bundles (one per region) with the pattern <code>scb_${dbid}-${dbregion}.zip</code> in a current folder.</p> <pre><code>mkdir db-demo\ncd db-demo\nastra db download-scb demo\nls\n</code></pre> <p>\u2705 9b - Download in target folder </p> <p>Download the different secure bundles (one per region) with the pattern <code>scb_${dbid}-${dbregion}.zip</code> in the folder provided with option <code>-d</code> (<code>--output-director</code>).</p> <pre><code>astra db download-scb demo -d /tmp\n</code></pre> <p>\u2705 9c - Download in target folder </p> <p>Provide the target filename with <code>-f</code> (<code>--output-file</code>). It will work only if you have a SINGLE REGION for your database (or you will have to use the flag <code>-d</code>)</p> <pre><code>astra db download-scb demo -f /tmp/demo.zip\n</code></pre>"},{"location":"pages/astra/astra-cli/#10-create-env-file","title":"10. Create <code>.env</code> file","text":"<p>To code your application against Astra, a set of metadata could be handy like the database name, database region, url of the APIs.... </p> <p>This command will create a file <code>.env</code> with a set of variables that are relevant to be defined as environment variables</p> <pre><code>astra db create-dotenv -f /tmp/.env\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>ASTRA_DB_APPLICATION_TOKEN=\"AstraCS:QeUmROP...\"\nASTRA_DB_GRAPHQL_URL=\"https://a6b5cb4c-3267-4414-8bba-6706086a943a-us-east-1.apps.astra.datastax.com/api/graphql/order_management_data\"\nASTRA_DB_GRAPHQL_URL_ADMIN=\"https://a6b5cb4c-3267-4414-8bba-6706086a943a-us-east-1.apps.astra.datastax.com/api/graphql-admin\"\nASTRA_DB_GRAPHQL_URL_PLAYGROUND=\"https://a6b5cb4c-3267-4414-8bba-6706086a943a-us-east-1.apps.astra.datastax.com/api/playground\"\nASTRA_DB_GRAPHQL_URL_SCHEMA=\"https://a6b5cb4c-3267-4414-8bba-6706086a943a-us-east-1.apps.astra.datastax.com/api/graphql-schema\"\nASTRA_DB_ID=\"a6b5cb4c-3267-4414-8bba-6706086a943a\"\nASTRA_DB_KEYSPACE=\"order_management_data\"\nASTRA_DB_REGION=\"us-east-1\"\nASTRA_DB_REST_URL=\"https://a6b5cb4c-3267-4414-8bba-6706086a943a-us-east-1.apps.astra.datastax.com/api/rest\"\nASTRA_DB_REST_URL_SWAGGER=\"https://a6b5cb4c-3267-4414-8bba-6706086a943a-us-east-1.apps.astra.datastax.com/api/rest/swagger-ui/\"\nASTRA_DB_SECURE_BUNDLE_PATH=\"/Users/cedricklunven/.astra/scb/scb_a6b5cb4c-3267-4414-8bba-6706086a943a_us-east-1.zip\"\nASTRA_DB_SECURE_BUNDLE_URL=\"https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/a6b5cb4c-3267-4414-8bba-6706086....X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIA2AI.....\"\nASTRA_ORG_ID=\"f9460f14-9879-....\"\nASTRA_ORG_NAME=\"ced...\"\nASTRA_ORG_TOKEN=\"AstraCS:QeUmROPLeNbd...\"\n</code></pre> <ol> <li>List Regions</li> </ol> <p>For database creation or regions management, the region name is expected. Depending on the cloud provider needed or even the Astra service, the region names are not exactly the same.</p> <p>With Astra CLI, one can list every available regions per service.</p> <p>List Serverless regions</p> <pre><code>astra db list-regions-serverless -c aws\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>+----------------+---------------------+-------------------------------+\n| Cloud Provider | Region              | Full Name                     |\n+----------------+---------------------+-------------------------------+\n| aws            | ap-east-1           | Asia Pacific (Hong Kong)      |\n| aws            | ap-south-1          | Asia Pacific (Mumbai)         |\n| aws            | ap-southeast-1      | Asia Pacific (Singapore)      |\n| aws            | ap-southeast-2      | Asia Pacific (Sydney)         |\n| aws            | eu-central-1        | Europe (Frankfurt)            |\n| aws            | eu-west-1           | Europe (Ireland)              |\n| aws            | sa-east-1           | South America (Sao Paulo)     |\n| aws            | us-east-1           | US East (N. Virginia)         |\n| aws            | us-east-2           | US East (Ohio)                |\n| aws            | us-west-2           | US West (Oregon)              |\n+----------------+---------------------+-------------------------------+\n</code></pre> <ul> <li><code>-c</code> or <code>--cloud</code> allows to select a cloud provider, the 3 accepted values will be <code>aws</code>, <code>gcp</code> and <code>azure</code></li> <li><code>-f</code> or <code>--filter</code> allows to look for either a location of region (eg. <code>-f France</code>, -f <code>us</code></li> <li><code>-o</code> or <code>--output</code> to change output from table (human) to csv or json</li> <li><code>-v</code> for verbose mode</li> <li><code>-t</code> to provide token of organization if not default selected</li> </ul> <p>List Serverless regions</p> <pre><code>astra db list-regions-classic\n</code></pre>"},{"location":"pages/astra/astra-cli/#astra-streaming","title":"Astra STREAMING","text":""},{"location":"pages/astra/astra-cli/#1-list-tenants","title":"1. List tenants","text":"<p>\u2705 1a - list</p> <p>To get the list of tenants in your organization, use the command <code>list</code> in the group <code>streaming</code>.</p> <pre><code>astra streaming list\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>+---------------------+-----------+----------------+----------------+\n| name                | cloud     | region         | Status         |\n+---------------------+-----------+----------------+----------------+\n| cedrick-20220910    | aws       | useast2        | active         |\n| trollsquad-2022     | aws       | useast2        | active         |\n+---------------------+-----------+----------------+----------------+\n</code></pre> <p>\u2705 1b - Change output as <code>csv</code> amd <code>json</code></p> <pre><code>astra streaming list -o csv\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>name,cloud,region,Status\ncedrick-20220910,aws,useast2,active\ntrollsquad-2022,aws,useast2,active\n</code></pre> <pre><code>astra streaming list -o json\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>{\n\"code\" : 0,\n\"message\" : \"astra streaming list -o json\",\n\"data\" : [ {\n\"cloud\" : \"aws\",\n\"Status\" : \"active\",\n\"name\" : \"cedrick-20220910\",\n\"region\" : \"useast2\"\n}, {\n\"cloud\" : \"aws\",\n\"Status\" : \"active\",\n\"name\" : \"trollsquad-2022\",\n\"region\" : \"useast2\"\n} ]\n}\n</code></pre>"},{"location":"pages/astra/astra-cli/#2-create-tenant","title":"2. Create tenant","text":"<p>\u2705 2a - Check tenant existence with <code>exist</code> </p> <p>The tenant name needs to be unique for the cluster (Cloud provider / region). It may be useful to check if the name is already in use by somebody else.</p> <pre><code>astra streaming exist new_tenant_from_cli\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>[ INFO ] - Tenant 'new_tenant_from_cli' does not exist.\n</code></pre> <p>\u2705 2b - Create tenant </p> <p>To create a tenant with default cloud (<code>aws</code>), default region (<code>useast2</code>), plan (<code>free</code>) and namespace (<code>default</code>):</p> <pre><code>astra streaming create new_tenant_from_cli\n</code></pre> <p>To view all supported options, please use:</p> <pre><code>astra help streaming create\n</code></pre>"},{"location":"pages/astra/astra-cli/#3-get-tenant-details","title":"3. Get tenant details","text":"<p>\u2705 3a - To get i nformation or details on an entity use the command <code>get</code>.</p> <pre><code>astra streaming get trollsquad-2022\n</code></pre> <p>The pulsar token is not displayed in this view as it is too long, but there are dedicated commands to display it.</p> \ud83d\udda5\ufe0f Sample output <pre><code>+------------------+-------------------------------------------------------------+\n| Attribute        | Value                                                       |\n+------------------+-------------------------------------------------------------+\n| Name             | trollsquad-2022                                             |\n| Status           | active                                                      |\n| Cloud Provider   | aws                                                         |\n| Cloud region     | useast2                                                     |\n| Cluster Name     | pulsar-aws-useast2                                          |\n| Pulsar Version   | 2.10                                                        |\n| Jvm Version      | JDK11                                                       |\n| Plan             | payg                                                        |\n| WebServiceUrl    | https://pulsar-aws-useast2.api.streaming.datastax.com       |\n| BrokerServiceUrl | pulsar+ssl://pulsar-aws-useast2.streaming.datastax.com:6651 |\n| WebSocketUrl     | wss://pulsar-aws-useast2.streaming.datastax.com:8001/ws/v2  |\n+------------------+-------------------------------------------------------------+\n</code></pre> <p>\u2705 3b. To get a special property you can add the option <code>--key</code>. Multiple keys are available: <code>status</code>, <code>cloud</code>, <code>pulsar_token</code>. Notice that the output is raw. This command is expected to be used in scripts</p> <pre><code>astra streaming get trollsquad-2022 --key cloud\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>aws\n</code></pre> <p>\u2705 3c. To get tenant pulsar-token please use <code>pulsar-token</code> command</p> <pre><code>astra streaming pulsar-token trollsquad-2022\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE2NjI5NzcyNzksImlzcyI6ImRhdGFzdGF4Iiwic3ViIjoiY2xpZW50O2Y5NDYwZjE0LTk4NzktNGViZS04M2YyLTQ4ZDNmM2RjZTEzYztkSEp2Ykd4emNYVmhaQzB5TURJeTsxOTZlYjg0YTMzIiwidG9rZW5pZCI6IjE5NmViODRhMzMifQ.rjJYDG_nJu0YpgATfjeKeUUAqwJGyVlvzpA5iP-d5-bReQf1FPaDlGxo40ADHHn2kx2NOdgMsm-Ys4K...\n</code></pre> <p>\u2705 3d. To get tenant status in a human readble for use <code>status</code> command</p> <pre><code>astra streaming status trollsquad-2022\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>[ INFO ] - Tenant 'trollsquad-2022' has status 'active'\n</code></pre>"},{"location":"pages/astra/astra-cli/#4-delete-tenant","title":"4. Delete Tenant","text":"<p>\u2705 4a. To delete a tenant simply use the command <code>delete</code></p> <pre><code>astra streaming delete trollsquad\n</code></pre>"},{"location":"pages/astra/astra-cli/#5-pulsar-shell","title":"5. Pulsar-Shell","text":"<p>Pulsar-Shell is a standalone shell to work with Apache Pulsar. It is compliant with Astra but requires a few extra steps of configuration. The purpose of the CLI is to integrate with <code>pulsar-shell</code> and do the integration and setup for you.</p> <p>Astra CLI will download, install, setup and wrap <code>pulsar-shell</code> for you to interact with Astra.</p> <p>\u2705 5a - Interactive mode </p> <p>If no options are provided,  you enter <code>pulsar-shell</code> interactive mode</p> <pre><code>astra streaming pulsar-shell trollsquad-2022\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>/Users/cedricklunven/.astra/lunastreaming-shell-2.10.1.1/conf/client-aws-useast2-trollsquad-2022.conf\nPulsar-shell is starting please wait for connection establishment...\nUsing directory: /Users/cedricklunven/.pulsar-shell\nWelcome to Pulsar shell!\n    Service URL: pulsar+ssl://pulsar-aws-useast2.streaming.datastax.com:6651\n    Admin URL: https://pulsar-aws-useast2.api.streaming.datastax.com\n\nType help to get started or try the autocompletion (TAB button).\nType exit or quit to end the shell session.\n\ndefault(pulsar-aws-useast2.streaming.datastax.com)&gt;\n</code></pre> <p>You can quit with exit.</p> <p>\u2705 5b - Execute Pulsar Shell command </p> <p>To execute command with <code>pushar-shell</code> use the flag <code>-e</code>.</p> <pre><code>astra streaming pulsar-shell trollsquad-2022 -e \"admin namespaces list trollsquad-2022\"\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>/Users/cedricklunven/.astra/lunastreaming-shell-2.10.1.1/conf/client-aws-useast2-trollsquad-2022.conf\nPulsar-shell is starting please wait for connection establishment...\nUsing directory: /Users/cedricklunven/.pulsar-shell\n[1/1] Executing admin namespaces list trollsquad-2022\n[1/1] \u2714 admin namespaces list trollsquad-2022\n</code></pre> <p>\u2705 5c - Execute Pulsar Shell files </p> <p>To execute CQL Files with  <code>pushar-shell</code> use the flag <code>-e</code>.</p> <pre><code>astra streaming pulsar-shell trollsquad-2022 -f create_topics.txt\n</code></pre>"},{"location":"pages/astra/astra-cli/#6-pulsar-client-and-admin","title":"6. Pulsar-client and Admin","text":"<p>Pulsar client and admin are provided within pulsar-shell. This section simply provides some examples to write and read in a topic with a client.</p> <p>\u2705 6a - Create a topic <code>demo</code>.</p> <ul> <li>First start the pulsar-shell on 2 different terminals</li> </ul> <pre><code>astra streaming pulsar-shell trollsquad-2022\n</code></pre> <ul> <li>Then on first terminal create a topic <code>demo</code> in the namespace <code>default</code></li> </ul> <pre><code>admin topics create persistent://trollsquad-2022/default/demo\n</code></pre> <ul> <li>You can now list the different topics in the namespace <code>default</code></li> </ul> <pre><code>admin topics list trollsquad-2022/default\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>persistent://trollsquad-2022/default/demo\n</code></pre> <ul> <li>Start a consumer on this topic</li> </ul> <pre><code>client consume persistent://trollsquad-2022/default/demo -s astra_cli_tuto -n 0\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>.. init ...\n83 - R:pulsar-aws-useast2.streaming.datastax.com/3.16.119.226:6651]] Connected to server\n2022-09-12T12:28:34,869+0200 [pulsar-client-io-1-1] INFO  org.apache.pulsar.client.impl.ClientCnx - [id: 0xc5ce3ec4, L:/192.168.82.1:53683 - R:pulsar-aws-useast2.streaming.datastax.com/3.16.119.226:6651] Connected through proxy to target broker at 192.168.7.141:6650\n2022-09-12T12:28:35,460+0200 [pulsar-client-io-1-1] INFO  org.apache.pulsar.client.impl.ConsumerImpl - [persistent://trollsquad-2022/default/demo][astra_cli_tuto] Subscribing to topic on cnx [id: 0xc5ce3ec4, L:/192.168.82.1:53683 - R:pulsar-aws-useast2.streaming.datastax.com/3.16.119.226:6651], consumerId 0\n2022-09-12T12:28:35,645+0200 [pulsar-client-io-1-1] INFO  org.apache.pulsar.client.impl.ConsumerImpl - [persistent://trollsquad-2022/default/demo][astra_cli_tuto] Subscribed to topic on pulsar-aws-useast2.streaming.datastax.com/3.16.119.226:6651 -- consumer: 0\n</code></pre> <ul> <li>On the second terminal you can now start a producer</li> </ul> <pre><code>client produce persistent://trollsquad-2022/default/demo -m \"hello,world\" -n 20 \n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>2022-09-12T12:36:28,684+0200 [pulsar-client-io-14-1] INFO  org.apache.pulsar.client.impl.ClientCnx - [id: 0x682890b5, L:/192.168.1.106:53796 ! R:pulsar-aws-useast2.streaming.datastax.com/3.138.177.230:6651] Disconnected\n2022-09-12T12:36:30,756+0200 [main] INFO  org.apache.pulsar.client.cli.PulsarClientTool - 40 messages successfully produced\n\nAnd on the client side\nkey:[null], properties:[], content:world\n----- got message -----\nkey:[null], properties:[], content:hello\n</code></pre>"},{"location":"pages/astra/astra-cli/#7-list-regions","title":"7. List Regions","text":"<pre><code>astra streaming list-regions\n</code></pre> <ul> <li><code>-c</code> or <code>--cloud</code> allows to select a cloud provider, the 3 accepted values will be <code>aws</code>, <code>gcp</code> and <code>azure</code></li> <li><code>-f</code> or <code>--filter</code> allows to look for either a location of region (eg. <code>-f France</code>, -f <code>us</code></li> <li><code>-o</code> or <code>--output</code> to change output from table (human) to csv or json</li> <li><code>-v</code> for verbose mode</li> <li><code>-t</code> to provide token of organization if not default selected</li> </ul>"},{"location":"pages/astra/astra-cli/#8-create-env-file","title":"8. Create <code>.env</code> file","text":"<pre><code>astra streaming create-dot-env &lt;tenant&gt; [-d &lt;destination_folder&gt;]\n</code></pre>"},{"location":"pages/astra/astra-cli/#user-and-roles","title":"User and Roles","text":""},{"location":"pages/astra/astra-cli/#1-list-users","title":"1. List users","text":"<pre><code>astra user list\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>+--------------------------------------+-----------------------------+---------------------+\n| User Id                              | User Email                  | Status              |\n+--------------------------------------+-----------------------------+---------------------+\n| b665658a-ae6a-4f30-a740-2342a7fb469c | cedrick.lunven@datastax.com | active              |\n+--------------------------------------+-----------------------------+---------------------+\n</code></pre>"},{"location":"pages/astra/astra-cli/#2-invite-user","title":"2. Invite User","text":"<pre><code>astra user invite cedrick.lunven@gmail.com\n</code></pre> <p>Check the list of users and notice the new user invited.</p> <pre><code>astra user list\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>+--------------------------------------+-----------------------------+---------------------+\n| User Id                              | User Email                  | Status              |\n+--------------------------------------+-----------------------------+---------------------+\n| 825bd3d3-82ae-404b-9aad-bbb4c53da315 | cedrick.lunven@gmail.com    | invited             |\n| b665658a-ae6a-4f30-a740-2342a7fb469c | cedrick.lunven@datastax.com | active              |\n+--------------------------------------+-----------------------------+---------------------+\n</code></pre>"},{"location":"pages/astra/astra-cli/#3-revoke-user","title":"3. Revoke User","text":"<pre><code>astra user delete cedrick.lunven@gmail.com\n</code></pre> \ud83d\udda5\ufe0f Sample output <pre><code>+--------------------------------------+-----------------------------+---------------------+\n| User Id                              | User Email                  | Status              |\n+--------------------------------------+-----------------------------+---------------------+\n| b665658a-ae6a-4f30-a740-2342a7fb469c | cedrick.lunven@datastax.com | active              |\n+--------------------------------------+-----------------------------+---------------------+\n</code></pre>"},{"location":"pages/astra/astra-cli/#4-list-roles","title":"4. List roles","text":"<pre><code>astra role list\n</code></pre>"},{"location":"pages/astra/astra-cli/#6-get-role-infos","title":"6. Get role infos","text":"<pre><code>astra role get \"Database Administrator\"\n</code></pre>"},{"location":"pages/astra/astra-cli/#configuration","title":"Configuration","text":"<p>If you work with multiple organizations, it could be useful to switch from one configuration to another, one token to another. The CLI provides a configuration management solution to handle this use case.</p> <p>\u2705 1a - List available configuration</p> <pre><code>astra config list\n</code></pre> <p>\u2705 1b - Create a new section</p> <pre><code>astra config create dev --token &lt;token_of_org_2&gt;\n</code></pre> <p>\u2705 1c - Use your section config anywhere</p> <p>You can use any organization anytime with <code>--config &lt;onfig_name&gt;</code>.</p> <pre><code>astra user list --config dev\n</code></pre> <p>\u2705 1d - Select a section as defaul</p> <ul> <li>Change the current org</li> </ul> <pre><code>astra config use dev\n</code></pre> <ul> <li>See your new list </li> </ul> <pre><code>astra config list\n</code></pre> <p>\u2705 1e - Delete a section</p> <p>You can delete any organization. If you delete the selected organization you will have to pick a new one.</p> <ul> <li> <p>Delete you config <pre><code>astra config delete dev\n</code></pre></p> </li> <li> <p>See the new list</p> </li> </ul> <pre><code>astra config list\n</code></pre>"},{"location":"pages/astra/astra-httpie/","title":"\u2023 HTTPie","text":"<p>We've created a tool to let you make Stargate calls from the command line.</p> <p>The quick start is in this repository.</p> <p>If you want to use it on your own system, follow these steps:</p>"},{"location":"pages/astra/astra-httpie/#install-the-python-library-and-httpie","title":"Install the python library and httpie","text":"<pre><code>pip3 install httpie-astra\n</code></pre>"},{"location":"pages/astra/astra-httpie/#setup-your-astra-account","title":"Setup your Astra account","text":"<p>To use the Astra CLI you need to create a DataStax Astra account. You also need to create a token with the <code>Organization Administration</code> role.</p>"},{"location":"pages/astra/astra-httpie/#install-astra-cli","title":"Install Astra CLI","text":"<p>To get everything working, you need to have the Astra CLi installed and setup.</p>"},{"location":"pages/astra/astra-httpie/#initialize-your-setup","title":"Initialize your setup","text":"<p>We need to initialize the configuration file at <code>~/.astrarc</code>. To to so run the following command. You will be asked to provide your token (AstraCS:...). It will be saved and reused for your commands in the future.</p> <pre><code>astra setup\n</code></pre>"},{"location":"pages/astra/astra-httpie/#create-your-environment-files","title":"Create your environment files","text":"<p>In order to use httpie, you need to initialize a configuration file.</p> <p>As an example, for the example in the Katapod example, you could use \"stargate\" as the database and \"workshop\" for the keyspace - but you can use any combination you like for general exploration.</p> <pre><code>astra db create &lt;database&gt;\nastra db create-dotenv -k &lt;keyspace&gt; &lt;database&gt;\necho \"[stargate]\" &gt;&gt; ~/.astrarc\ncat .env &gt;&gt; ~/.astrarc\n</code></pre> <p>From here, you can call any Stargate API endpoint.  Check the example repository to see how this works.</p>"},{"location":"pages/astra/astra-httpie/#configuration-file","title":"Configuration file.","text":"<p>You can create a configuration file in ~/.config/httpie/config.json.  Adding this configuration file allows you to use a shorter command to call the endpoints.</p> <p>~/.config/httpie/config.json <pre><code>{\n    \"default_options\": [\n      \"--auth-type=astra\",\n      \"--auth=stargate:\"\n    ]\n}\n</code></pre></p> <p>This means that instead of using this command:</p> <pre><code>http --auth-type astra -a stargate: :/rest/v1/keyspaces\n</code></pre> <p>You can use this command:</p> <pre><code>http :/rest/v1/keyspaces\n</code></pre>"},{"location":"pages/astra/astra-httpie/#example-rest-calls","title":"Example REST calls","text":"<p>Create a table <pre><code>http POST :/rest/v2/schemas/keyspaces/workshop/tables json:='{\n  \"name\": \"cavemen\",\n  \"ifNotExists\": false,\n  \"columnDefinitions\": [\n    {\n      \"name\": \"firstname\",\n      \"typeDefinition\": \"text\",\n      \"static\": false\n    },\n    {\n      \"name\": \"lastname\",\n      \"typeDefinition\": \"text\",\n      \"static\": false\n    },\n        {\n          \"name\": \"occupation\",\n          \"typeDefinition\": \"text\"\n        }\n  ],\n  \"primaryKey\": {\n    \"partitionKey\": [\n      \"lastname\"\n    ],\n    \"clusteringKey\": [\n      \"firstname\"\n    ]\n  }\n}'\n</code></pre></p> <p>List tables in your keyspace <pre><code>http :/rest/v2/schemas/keyspaces/workshop/tables\n</code></pre></p> <p>Add a row <pre><code>http POST :/rest/v2/keyspaces/workshop/cavemen json:='\n{\n            \"firstname\" : \"Fred\",\n            \"lastname\": \"Flintstone\"\n}'\n</code></pre></p> <p>Update a row <pre><code>http PUT :/rest/v2/keyspaces/workshop/cavemen/Flintstone/Fred json:='\n{ \"occupation\": \"Quarry Screamer\"}'\n</code></pre></p> <p>Delete a row <pre><code>http DELETE :/rest/v2/keyspaces/workshop/cavemen/Flintstone/Fred\n</code></pre></p> <p>For more examples, check out the katapod exercises.</p>"},{"location":"pages/astra/cdc-for-astra/","title":"\u2023 CDC for Astra Streaming","text":"\ud83d\udcd6 Reference Documentation and resources <ol> <li>\ud83d\udcd6  Astra Docs - Reference documentation <li>\ud83c\udfa5 Youtube Video - Astra Streaming demo <li>\ud83c\udfa5 Pulsar Documentation - Getting Started <li>\ud83c\udfa5 Apache Pulsar Documentation"},{"location":"pages/astra/cdc-for-astra/#cdc-for-astra-db","title":"CDC for Astra DB","text":"<p>CDC for Astra DB automatically captures changes in real time, de-duplicates the changes, and streams the clean set of changed data into Astra Streaming where it can be processed by client applications or sent to downstream systems.</p> <p>Astra Streaming processes data changes via a Pulsar topic. By design, the Change Data Capture (CDC) component is simple, with a 1:1 correspondence between the table and a single Pulsar topic.</p> <p>This doc will show you how to create a CDC connector for your Astra DB deployment and send change data to an Elasticsearch sink.</p>"},{"location":"pages/astra/cdc-for-astra/#creating-a-tenant-and-topic","title":"Creating a tenant and topic","text":"<ol> <li>In astra.datastax.com, select Create Streaming.</li> <li> <p>Enter the name for your new streaming tenant and select a provider. </p> </li> <li> <p>Select Create Tenant.</p> </li> </ol> <p>Use the default persistent and non-partitioned topic settings.</p> <p>Note</p> <p>Astra Streaming CDC can only be used in a region that supports both Astra Streaming and AstraDB. See Regions for more information.</p>"},{"location":"pages/astra/cdc-for-astra/#creating-a-table","title":"Creating a table","text":"<ol> <li> <p>In your Astra Database, create a table with a primary key column: <pre><code>CREATE TABLE IF NOT EXISTS &lt;keyspacename&gt;.tbl1 (key text PRIMARY KEY, c1 text);\n</code></pre></p> </li> <li> <p>Confirm you created your table: <pre><code>select * from &lt;mykeyspace&gt;.tbl1;\n</code></pre></p> </li> </ol> <p>Results:</p> <p></p>"},{"location":"pages/astra/cdc-for-astra/#connecting-to-cdc-for-astra-db","title":"Connecting to CDC for Astra DB","text":"<ol> <li>Select the CDC tab in your database dashboard.</li> <li>Select Enable CDC.</li> <li> <p>Complete the fields to connect CDC. </p> </li> <li> <p>Select Enable CDC. Once created, your CDC connector will appear: </p> </li> <li> <p>Enabling CDC creates a new <code>astracdc</code> namespace with two new topics, <code>data-</code> and <code>log-</code>. The <code>log-</code> topic consumes schema changes, processes them, and then writes clean data to the <code>data-</code> topic. The <code>log-</code> topic is for CDC functionality and should not be used. The <code>data-</code> topic can be used to consume CDC data in Astra Streaming. </p> </li> </ol>"},{"location":"pages/astra/cdc-for-astra/#connecting-elasticsearch-sink","title":"Connecting Elasticsearch sink","text":"<p>After creating your CDC connector, connect an Elasticsearch sink to it. DataStax recommends using the default Astra Streaming settings.</p> <ol> <li> <p>Select Add Elastic Search Sink from the database CDC console to enforce the default settings.  </p> </li> <li> <p>Use your Elasticsearch deployment to complete the fields. To find your Elasticsearch URL, navigate to your deployment within the Elastic Common Schema (ECS).</p> </li> <li> <p>Copy the Elasticsearch endpoint to the Elastic Search URL field.  </p> </li> <li> <p>Complete the remaining fields. Most values will auto-populate. These values are recommended:</p> <ul> <li><code>ignoreKey</code> as <code>false</code></li> <li><code>nullValueAction</code> as <code>DELETE</code></li> <li><code>enabled</code> as <code>true</code> </li> </ul> </li> <li> <p>When the fields are completed, select Create. If creation is successful, <code>&lt;sink-name&gt; created successfully</code> appears at the top of the screen. You can confirm your new sink was created in the Sinks tab. </p> </li> </ol>"},{"location":"pages/astra/cdc-for-astra/#sending-messages","title":"Sending messages","text":"<p>Let's process some changes with CDC.</p> <ol> <li>Go to the CQL console.</li> <li> <p>Modify the table you created.  <pre><code>INSERT INTO &lt;keyspacename&gt;.tbl1 (key,c1) VALUES ('32a','bob3123');\nINSERT INTO &lt;keyspacename&gt;.tbl1 (key,c1) VALUES ('32b','bob3123b');\n</code></pre></p> </li> <li> <p>Confirm the changes you've made: <pre><code>select * from &lt;keyspacename&gt;.tbl1;\n</code></pre> Results:</p> </li> </ol> <p></p>"},{"location":"pages/astra/cdc-for-astra/#confirming-ecs-is-receiving-data","title":"Confirming ECS is receiving data","text":"<p>To confirm ECS is receiving your CDC changes, use a <code>curl</code> request to your ECS deployment.</p> <ol> <li> <p>Get your index name from your ECS sink tab: </p> </li> <li> <p>Issue your <code>curl</code> request with your Elastic <code>username</code>, <code>password</code>, and <code>index name</code>: <pre><code>curl  -u &lt;username&gt;:&lt;password&gt;  \\\n   -XGET \"https://asdev.es.westus2.azure.elastic-cloud.com:9243/&lt;index_name&gt;.tbl1/_search?pretty=true\"  \\\n   -H 'Content-Type: application/json'\n</code></pre></p> </li> </ol> <p>Note</p> <p>If you have a trial account, the username is <code>elastic</code>.</p> <p>You will receive a JSON response with your changes to the index, which confirms Astra Streaming is sending your CDC changes to your ECS sink.</p> <pre><code>{\n    \"_index\" : \"index.tbl1\",\n    \"_type\" : \"_doc\",\n    \"_id\" : \"32a\",\n    \"_score\" : 1.0,\n    \"_source\" : {\n        \"c1\" : \"bob3123\"\n    }\n}\n\n{\n    \"_index\" : \"index.tbl1\",\n    \"_type\" : \"_doc\",\n    \"_id\" : \"32b\",\n    \"_score\" : 1.0,\n    \"_source\" : {\n        \"c1\" : \"bob3123b\"\n    }\n}\n</code></pre>"},{"location":"pages/astra/cqlproxy/","title":"\u2023 CQL Proxy","text":"<p>This page is a copy</p> <p>This page is a copy of CQL PROXY Reference Documentation. if you encounter some discrepancies please open a JIRA in our repository.</p>"},{"location":"pages/astra/cqlproxy/#what-is-cql-proxy","title":"What is <code>cql-proxy</code>?","text":"<p><code>cql-proxy</code> is designed to forward your application's CQL traffic to an appropriate database service. It listens on a local address and securely forwards that traffic.</p> <p>Note: <code>cql-proxy</code> was made as a genrally available release on <code>2/16/2022</code>. See this blog for additional details.</p> <p>Please give it a try and let us know what you think!</p>"},{"location":"pages/astra/cqlproxy/#when-to-use-cql-proxy","title":"When to use <code>cql-proxy</code>","text":"<p>The <code>cql-proxy</code> sidecar enables unsupported CQL drivers to work with DataStax Astra. These drivers include both legacy DataStax drivers and community-maintained CQL drivers, such as the gocql driver and the rust-driver.</p> <p><code>cql-proxy</code> also enables applications that are currently using Apache Cassandra or DataStax Enterprise (DSE) to use Astra without requiring any code changes. Your application just needs to be configured to use the proxy.</p> <p>If you're building a new application using DataStax drivers, <code>cql-proxy</code> is not required, as the drivers can communicate directly with Astra. DataStax drivers have excellent support for Astra out-of-the-box, and are well-documented in the driver-guide guide.</p>"},{"location":"pages/astra/cqlproxy/#configuration","title":"Configuration","text":"<p>Use the <code>-h</code> or <code>--help</code> flag to display a listing all flags and their corresponding descriptions and environment variables (shown below as items starting with <code>$</code>):</p> <pre><code>$ ./cql-proxy -h\nUsage: cql-proxy\n\nFlags:\n  -h, --help                                              Show context-sensitive help.\n  -b, --astra-bundle=STRING                               Path to secure connect bundle for an Astra database. Requires '--username' and '--password'. Ignored if using the token or contact points option\n                                                          ($ASTRA_BUNDLE).\n  -t, --astra-token=STRING                                Token used to authenticate to an Astra database. Requires '--astra-database-id'. Ignored if using the bundle path or contact points option\n                                                          ($ASTRA_TOKEN).\n  -i, --astra-database-id=STRING                          Database ID of the Astra database. Requires '--astra-token' ($ASTRA_DATABASE_ID)\n--astra-api-url=\"https://api.astra.datastax.com\"    URL for the Astra API ($ASTRA_API_URL)\n-c, --contact-points=CONTACT-POINTS,...                 Contact points for cluster. Ignored if using the bundle path or token option ($CONTACT_POINTS).\n  -u, --username=STRING                                   Username to use for authentication ($USERNAME)\n-p, --password=STRING                                   Password to use for authentication ($PASSWORD)\n-r, --port=9042                                         Default port to use when connecting to cluster ($PORT)\n-n, --protocol-version=\"v4\"                             Initial protocol version to use when connecting to the backend cluster (default: v4, options: v3, v4, v5, DSEv1, DSEv2) ($PROTOCOL_VERSION)\n-m, --max-protocol-version=\"v4\"                         Max protocol version supported by the backend cluster (default: v4, options: v3, v4, v5, DSEv1, DSEv2) ($MAX_PROTOCOL_VERSION)\n-a, --bind=\":9042\"                                      Address to use to bind server ($BIND)\n-f, --config=CONFIG                                     YAML configuration file ($CONFIG_FILE)\n--debug                                             Show debug logging ($DEBUG)\n--health-check                                      Enable liveness and readiness checks ($HEALTH_CHECK)\n--http-bind=\":8000\"                                 Address to use to bind HTTP server used for health checks ($HTTP_BIND)\n--heartbeat-interval=30s                            Interval between performing heartbeats to the cluster ($HEARTBEAT_INTERVAL)\n--idle-timeout=60s                                  Duration between successful heartbeats before a connection to the cluster is considered unresponsive and closed ($IDLE_TIMEOUT)\n--readiness-timeout=30s                             Duration the proxy is unable to connect to the backend cluster before it is considered not ready ($READINESS_TIMEOUT)\n--num-conns=1                                       Number of connection to create to each node of the backend cluster ($NUM_CONNS)\n--rpc-address=STRING                                Address to advertise in the 'system.local' table for 'rpc_address'. It must be set if configuring peer proxies ($RPC_ADDRESS)\n--data-center=STRING                                Data center to use in system tables ($DATA_CENTER)\n--tokens=TOKENS,...                                 Tokens to use in the system tables. It's not recommended ($TOKENS)\n</code></pre> <p>To pass configuration to <code>cql-proxy</code>, either command-line flags, environment variables, or a configuration file can be used. Using the <code>docker</code> method as an example, the following samples show how the token and database ID are defined with each method.</p>"},{"location":"pages/astra/cqlproxy/#using-flags","title":"Using flags","text":"<pre><code>docker run -p 9042:9042 \\\n--rm datastax/cql-proxy:v0.1.2 \\\n--astra-token &lt;astra-token&gt; --astra-database-id &lt;astra-datbase-id&gt;\n</code></pre>"},{"location":"pages/astra/cqlproxy/#using-environment-variables","title":"Using environment variables","text":"<pre><code>docker run -p 9042:9042  \\\n--rm datastax/cql-proxy:v0.1.2 \\\n-e ASTRA_TOKEN=&lt;astra-token&gt; -e ASTRA_DATABASE_ID=&lt;astra-datbase-id&gt;\n</code></pre>"},{"location":"pages/astra/cqlproxy/#using-a-configuration-file","title":"Using a configuration file","text":"<p>Proxy settings can also be passed using a configuration file with the <code>--config /path/to/proxy.yaml</code> flag. This can be mixed and matched with command-line flags and environment variables. Here are some example configuration files:</p> <pre><code>contact-points:\n- 127.0.0.1\nusername: cassandra\npassword: cassandra\nport: 9042\nbind: 127.0.0.1:9042\n# ...\n</code></pre> <p>or with a Astra token:</p> <pre><code>astra-token: &lt;astra-token&gt;\nastra-database-id: &lt;astra-database-id&gt;\nbind: 127.0.0.1:9042\n# ...\n</code></pre> <p>All configuration keys match their command-line flag counterpart, e.g. <code>--astra-bundle</code> is <code>astra-bundle:</code>, <code>--contact-points</code> is <code>contact-points:</code> etc.</p>"},{"location":"pages/astra/cqlproxy/#setting-up-peer-proxies","title":"Setting up peer proxies","text":"<p>Multi-region failover with DC-aware load balancing policy is the most useful case for a multiple proxy setup.</p> <p>When configuring <code>peers:</code> it is required to set <code>--rpc-address</code> (or <code>rpc-address:</code> in the yaml) for each proxy and it must match is corresponding <code>peers:</code> entry. Also, <code>peers:</code> is only available in the configuration file and cannot be set using a command-line flag.</p>"},{"location":"pages/astra/cqlproxy/#multi-region-setup","title":"Multi-region setup","text":"<p>Here's an example of configuring multi-region failover with two proxies. A proxy is started for each region of the cluster connecting to it using that region's bundle. They all share a common configuration file that contains the full list of proxies.</p> <p>Note: Only bundles are supported for multi-region setups.</p> <pre><code>cql-proxy --astra-bundle astra-region1-bundle.zip --username token --passowrd &lt;astra-token&gt; \\\n--bind 127.0.0.1:9042 --rpc-address 127.0.0.1 --data-center dc-1 --config proxy.yaml\n</code></pre> <pre><code>cql-proxy ---astra-bundle astra-region2-bundle.zip --username token --passowrd &lt;astra-token&gt; \\\n--bind 127.0.0.2:9042 --rpc-address 127.0.0.2 --data-center dc-2 --config proxy.yaml\n</code></pre> <p>The peers settings are configured using a yaml file. It's a good idea to explicitly provide the <code>--data-center</code> flag, otherwise; these values are pulled from the backend cluster and would need to be pulled from the <code>system.local</code> and <code>system.peers</code> table to properly setup the peers <code>data-center:</code> values. Here's an example <code>proxy.yaml</code>:</p> <pre><code>peers:\n- rpc-address: 127.0.0.1\ndata-center: dc-1\n- rpc-address: 127.0.0.2\ndata-center: dc-2\n</code></pre> <p>Note: It's okay for the <code>peers:</code> to contain entries for the current proxy itself because they'll just be omitted.</p>"},{"location":"pages/astra/cqlproxy/#getting-started","title":"Getting started","text":"<p>There are three methods for using <code>cql-proxy</code>:</p> <ul> <li>Locally build and run <code>cql-proxy</code></li> <li>Run a docker image that has <code>cql-proxy</code> installed</li> <li>Install locally on a Mac with Homebrew</li> <li>Use a Kubernetes container to run <code>cql-proxy</code></li> </ul>"},{"location":"pages/astra/cqlproxy/#locally-build-and-run","title":"Locally build and run","text":"<ol> <li>Build <code>cql-proxy</code>.</li> </ol> <pre><code>go build\n</code></pre> <ol> <li> <p>Run with your desired database.</p> </li> <li> <p>DataStax Astra cluster:</p> <pre><code>./cql-proxy --astra-token &lt;astra-token&gt; --astra-database-id &lt;astra-database-id&gt;\n</code></pre> <p>The <code>&lt;astra-token&gt;</code> can be generated using these instructions. The proxy also supports using the Astra Secure Connect Bundle along with a client ID and secret generated using these instructions:</p> <pre><code>./cql-proxy --astra-bundle &lt;your-secure-connect-zip&gt; \\\n--username &lt;astra-client-id&gt; --password &lt;astra-client-secret&gt;\n</code></pre> </li> <li> <p>Apache Cassandra cluster:</p> <pre><code>./cql-proxy --contact-points &lt;cluster node IPs or DNS names&gt; [--username &lt;username&gt;] [--password &lt;password&gt;]\n</code></pre> </li> </ol>"},{"location":"pages/astra/cqlproxy/#run-a-cql-proxy-docker-image","title":"Run a <code>cql-proxy</code> docker image","text":"<ol> <li> <p>Run with your desired database.</p> <ul> <li>DataStax Astra cluster:</li> </ul> <pre><code>docker run -p 9042:9042 \\\ndatastax/cql-proxy:v0.1.2 \\\n--astra-token &lt;astra-token&gt; --astra-database-id &lt;astra-database-id&gt;\n</code></pre> <p>The <code>&lt;astra-token&gt;</code> can be generated using these instructions. The proxy also supports using the Astra Secure Connect Bundle, but it requires mounting the bundle to a volume in the container:</p> <pre><code>docker run -v &lt;your-secure-connect-bundle.zip&gt;:/tmp/scb.zip -p 9042:9042 \\\n--rm datastax/cql-proxy:v0.1.2 \\\n--astra-bundle /tmp/scb.zip --username &lt;astra-client-id&gt; --password &lt;astra-client-secret&gt;\n</code></pre> <ul> <li> <p>Apache Cassandra cluster:</p> <pre><code>docker run -p 9042:9042 \\\ndatastax/cql-proxy:v0.1.2 \\\n--contact-points &lt;cluster node IPs or DNS names&gt; [--username &lt;username&gt;] [--password &lt;password&gt;]\n</code></pre> </li> </ul> <p>If you wish to have the docker image removed after you are done with it, add <code>--rm</code> before the image name <code>datastax/cql-proxy:v0.1.2</code>.</p> </li> </ol>"},{"location":"pages/astra/cqlproxy/#homebrew-on-a-mac","title":"Homebrew on a Mac","text":"<p>Install with one simple command: <pre><code>brew install cql-proxy\n</code></pre></p>"},{"location":"pages/astra/cqlproxy/#use-kubernetes","title":"Use Kubernetes","text":"<p>Using Kubernetes with <code>cql-proxy</code> requires a number of steps:</p> <ol> <li> <p>Generate a token following the Astra instructions. This step will display your Client ID, Client Secret, and Token; make sure you download the information for the next steps. Store the secure bundle in <code>/tmp/scb.zip</code> to match the example below.</p> </li> <li> <p>Create <code>cql-proxy.yaml</code>. You'll need to add three sets of information: arguments, volume mounts, and volumes.</p> </li> <li> <p>Argument: Modify the local bundle location, username and password, using the client ID and client secret obtained in the last step to the container argument.</p> </li> </ol> <pre><code>command: [\"./cql-proxy\"]\nargs: [\"--astra-bundle=/tmp/scb.zip\",\"--username=Client ID\",\"--password=Client Secret\"]\n</code></pre> <ul> <li> <p>Volume mounts: Modify <code>/tmp/</code> as a volume mount as required.</p> <p>volumeMounts:     - name: my-cm-vol     mountPath: /tmp/</p> </li> <li> <p>Volume: Modify the <code>configMap</code> filename as required. In this example, it is named <code>cql-proxy-configmap</code>. Use the same name for the <code>volumes</code> that you used for the <code>volumeMounts</code>.</p> <p>volumes:     - name: my-cm-vol       configMap:         name: cql-proxy-configmap</p> </li> <li> <p>Create a configmap. Use the same secure bundle that was specified in the <code>cql-proxy.yaml</code>.</p> </li> </ul> <pre><code>kubectl create configmap cql-proxy-configmap --from-file /tmp/scb.zip\n</code></pre> <ol> <li>Check the configmap that was created.</li> </ol> <pre><code>kubectl describe configmap config\n\nName:         config\n  Namespace:    default\n  Labels:       &lt;none&gt;\n  Annotations:  &lt;none&gt;\n\nData\n====\nBinaryData\n====\nscb.zip: 12311 bytes\n</code></pre> <ol> <li>Create a Kubernetes deployment with the YAML file you created:</li> </ol> <pre><code>kubectl create -f cql-proxy.yaml\n</code></pre> <ol> <li>Check the logs:    <pre><code>kubectl logs &lt;deployment-name&gt;\n</code></pre></li> </ol>"},{"location":"pages/astra/cqlproxy/#known-issues","title":"Known issues","text":""},{"location":"pages/astra/cqlproxy/#token-aware-load-balancing","title":"Token-aware load balancing","text":"<p>Drivers that use token-aware load balancing may print a warning or may not work when using cql-proxy. Because cql-proxy abstracts the backend cluster as a single endpoint this doesn't always work well with token-aware drivers that expect there to be at least \"replication factor\" number of nodes in the cluster. Many drivers print a warning (which can be ignored) and fallback to something like round-robin, but other drivers might fail with an error. For the drivers that fail with an error it is required that they disable token-aware or configure the round-robin load balancing policy.</p>"},{"location":"pages/astra/create-account/","title":"\u2023 Create Account","text":""},{"location":"pages/astra/create-account/#a-overview","title":"A - Overview","text":"<p>ASTRA DB is the simplest way to run Cassandra with zero operations. No credit card required and $25.00 USD credit every month (roughly 20M reads/writes, 80GB storage monthly) which is sufficient to run small production workloads.</p> <p>https://astra.datastax.com is the URL create an account and get started with the solution.</p> <p></p>"},{"location":"pages/astra/create-account/#b-sign-up","title":"B - Sign Up","text":"<p>You can use your <code>Github</code>, <code>Google</code> accounts or register with an <code>email</code>.</p>"},{"location":"pages/astra/create-account/#1-sign-in-with-github","title":"1. Sign In with Github","text":"Click the <code>[Sign In with Github]</code> button 1\ufe0f\u20e3 Click <code>Continue</code> on the OAuth claims delegation <p>The OAuth2 delegation screen from github is asking for permissions.</p> <p></p> 2\ufe0f\u20e3 You are redirected to the homepage <p></p>"},{"location":"pages/astra/create-account/#2-sign-in-with-google","title":"2. Sign In with Google","text":"1\ufe0f\u20e3 Click the <code>[Sign In with Google]</code> button 2\ufe0f\u20e3 You are redirected to the homepage"},{"location":"pages/astra/create-account/#3-sign-up","title":"3. Sign Up","text":"1\ufe0f\u20e3 Click the <code>Sign up</code> on the bottom of the page 2\ufe0f\u20e3 Provide your information and validate the captcha 3\ufe0f\u20e3 Accept terms and policies <p>Astra is now looking for you to validate your email adress</p> <p></p> 4\ufe0f\u20e3 Open the mail in your inbox and validate with the <code>Verify my email</code> link <p></p> <ul> <li>Astra will show a validation message, select Click Here to proceed.</li> </ul> <p></p> <ul> <li>Select back to application </li> </ul> 5\ufe0f\u20e3 You are redirected to the homepage <p></p>"},{"location":"pages/astra/create-account/#c-account-and-organization","title":"C - Account and Organization","text":""},{"location":"pages/astra/create-account/#1-overview","title":"1. Overview","text":"<p>When you create an account your personal Organization is created, this is your tenant:</p> <ul> <li>The name of the organization is your email address, (1) in the picture below</li> <li>The unique identifier (GUID) is present in the URL on the dashboard. (2) in the picture below</li> </ul> <p></p>"},{"location":"pages/astra/create-account/#2-organization-objects","title":"2. Organization Objects","text":"<p><code>Databases</code>, <code>Tenants</code> and <code>Security Tokens</code> objects are created within the organization, as shown on the Organization Dashboard.</p> <pre><code>  graph TD\n    User(User) --&gt;|1..n| ORG(Organization)\n    ORG(Organization) --&gt;|0..n| DB(Databases)\n    ORG(Organization) --&gt;|0..n| ST(Streaming Tenants)\n    ORG(Organization) --&gt;|0..n| ROLE(Roles)\n    ORG(Organization) --&gt;|0..n| TOK(Security Tokens)\n    TOK(Security Tokens) --&gt;|1..1| ROLE\n    DB(Databases) --&gt;|1..n| KEY(Keyspaces)\n    KEY(Keyspaces) --&gt;|0..n| TABLE(Tables)\n    ST(Streaming Tenants) --&gt;|0..n| TOPIC(Topics)</code></pre> <p></p>"},{"location":"pages/astra/create-account/#3-multiple-organizations","title":"3. Multiple Organizations","text":"<p>You can create multiple organizations through the <code>Manage Organizations</code> menu option and invite other users to join as well. It is useful when the same database could be accessed by multiple users with different emails.</p> <p></p> <p>As a consequence a user can be part of multiple organizations; the personal organization created during registration, new user-defined organizations, and shared organizations.</p> <pre><code>  graph TD\n    USER(User) --&gt;|1..n| PORG(Personal Organization - registration)\n    USER --&gt;|0..n| CORG(Organizations he created)\n    USER --&gt;|0...n| IORG(Organizations he was invited to)</code></pre>"},{"location":"pages/astra/create-instance/","title":"\u2023 Create Database","text":"\ud83d\udcd6 Reference Documentation and resources <ol> <li>\ud83d\udcd6  Astra Docs - The Astra database creation procedure <li>\ud83c\udfa5 Youtube Video - Walk through instance creation"},{"location":"pages/astra/create-instance/#a-overview","title":"A - Overview","text":"<p><code>ASTRA DB</code> is the simplest way to run Cassandra with zero operations - just push the button and get your cluster. No credit card required and $25.00 USD credit every month (roughly 20M reads/writes, 80GB storage monthly) which is sufficient to run small production workloads.</p>"},{"location":"pages/astra/create-instance/#b-prerequisites","title":"B - Prerequisites","text":"<ul> <li>You should have an Astra account. If you don't have one yet, keep reading and we'll show you how to create it.</li> </ul>"},{"location":"pages/astra/create-instance/#c-procedure","title":"C - Procedure","text":"<p>\u2705 Step 1: Click the <code>Create Account</code> button to login or register.</p> <p>You can use your <code>Github</code>, <code>Google</code> accounts or register with an <code>email</code>. Make sure to chose a password with a minimum of 8 characters, containing upper and lowercase letters, and at least one number and special character.</p> <p>If you already have an Astra account, you can skip this step. Locate the \"Create Database\" button, as shown in the next step, and read on.</p> <p></p> <p>\u2705 Step 2: Complete the creation form</p> <p>If you are creating a new account, you will be brought to the DB-creation form directly.</p> <p>Otherwise, get to the databases dashboard (by clicking on \"Databases\" in the left-hand navigation bar, expanding it if necessary), and click the \"Create Database\" button on the right.</p> <p></p> <p>Take a moment to fill the form:</p> <ul> <li>\u2139\ufe0f Fields Description</li> </ul> Field Description database name It does not need to be unique, is not used to initialize a connection, and is only a label (keep it between 2 and 50 characters). It is recommended to have a database for each of your applications. The free tier is limited to 5 databases. keyspace It is a logical grouping of your tables (keep it between 2 and 48 characters). Prefer lower case or <code>snake_case</code>, and avoid spaces. Cloud Provider Choose whatever you like. Click a cloud provider logo, pick an Area in the list and finally pick a region. We recommend choosing a region that is closest to you to reduce latency. In free tier, there is very little difference. <p>If all fields are filled properly, clicking the \"Create Database\" button will start the process. It should take a couple of minutes for your database to become <code>Active</code>.</p> <p>In the meantime, you will be brought to the \"Connect\" page of the database, that is being provisioned in the meantime. You can track the progression by looking at the status label at the top, next to the database's name.</p> <p>\u2705 Step 3: Obtain a Database Token</p> <p>While the database is created, you can generate and download a Token to later access it from your applications. The automatically-generated token has a \"reasonable\" set of permissions (limited to this database), but you can also generate a custom token to better suit your needs.</p> <p></p> <p>To generate the token click on the \"Generate Token\" button. The new token can (and should!) be copied elsewhere with the clipboard-icon button and/or downloaded in JSON format for safe storage - it will not be shown anymore once you leave the dialog.</p> <p></p> <p>\u2705 Step 4: Ready</p> <p>In a couple of minutes, the database will switch to <code>Active</code>. You can now interact with it, for example by downloading a Secure Connect Bundle) and start running applications that access it.</p>"},{"location":"pages/astra/create-token/","title":"\u2023 Create Token","text":"<p>Reference Documentation and resources</p> <p><ol> <li> Astra Docs - The Astra token creation procedure <li> Youtube Video - Walk through token creation <li> Youtube Video - More about token and roles in Astra"},{"location":"pages/astra/create-token/#a-overview","title":"A - Overview","text":"<p>As stated in the Create Account page, the security token is associated to one and only one organization and only one role.</p> <pre><code>  graph TD\n    USER(Users) --&gt;|n...m|ORG(Organizations)\n    ORG --&gt;|0..n|DB(Dabatases)\n    ORG --&gt;|0..n|TOKEN(Tokens)\n    ORG --&gt;|0..n|STR(Streaming Tenants)\n    TOKEN--&gt;|1:1|ROLE(role)\n    ROLE--&gt;|1..n|PERMISSIONS(permissions)</code></pre> <p>There are a set of predefined roles within an organization which are associated with some default permissions. The full list of permissions and roles is available in the Astra Documentation.</p> <p> Figure 1: Default Roles <p> Figure 2: Permissions for a selected role (here, \"Database Administrator\") </p> <p></p> <p>It is possible to manually create custom roles and tune the corresponding permissions in a fine-grained fashion (<code>Settings / Role Management</code>), to later create tokens based on them. For example, each time a database is created, it comes with an autogenerated brand-new token, backed by an ad-hoc custom role essentially scoped to that database only.</p> <p> Figure 3: Custom Roles screen </p>"},{"location":"pages/astra/create-token/#b-prerequisites","title":"B - Prerequisites","text":"<p>To create a new token:</p> <ul> <li>You should have an Astra account</li> </ul>"},{"location":"pages/astra/create-token/#c-procedure","title":"C - Procedure","text":"<p>Note that a token, albeit with a fixed set of permissions, is generated automatically for you as a database is created. In many cases, however, you need to manually issue tokens, and here is explained how to do that.</p> <p>1\ufe0f\u20e3 First go to the Organization settings panel in one of the following ways:</p> Settings page <p>On the bottom-right corner of the Astra UI, in the navigation bar, click on \"Settings\" next to the cog icon. (The navigation bar might be collapsed to the left). Then, select the \"Token management\" entry in the Settings menu.</p> <p></p> From a database <p>Click on the \"...\" next to a database in the main DB dashboard, then select \"Generate a Token\".</p> <p></p> From the Connect tab <p>On the Connect tab of your database, click on the \"create a custom token\" link in the Quickstart section.</p> <p></p> <p>2\ufe0f\u20e3 Pick the desired role for the token in the drop-down list and click \"Generate\".</p> <p></p> <p>3\ufe0f\u20e3 A new token is generated for you. Make sure to copy/download the values before leaving the page, since the secrets will not be shown anymore. You can copy the individual secrets with the button next to the text fields, or directly download the whole token as a file and store it safely.</p> <p></p> Anatomy of a Token <p>The Token is in fact three separate strings: a Client ID, a Client Secret and the token proper. You will need some of these strings to access the database, depending on the type of access you plan. Although the Client ID, strictly speaking, is not a secret, you should regard this whole object as a secret and make sure not to share it inadvertently (e.g. committing it to a Git repository) as it grants access to your databases.</p> <p></p> <p>4\ufe0f\u20e3 The token will not expire, unless you decide to revoke (i.e. delete) it, for example in case it is compromised. To do so, in the \"Token Management\" page, click on the \"...\" menu next to the token you want to delete.</p> <p></p>"},{"location":"pages/astra/create-topic/","title":"\u2023 Create Topic","text":"\ud83d\udcd6 Reference Documentation and resources <ol> <li>\ud83d\udcd6  Astra Docs - Reference documentation <li>\ud83c\udfa5 Youtube Video - Astra Streaming demo <li>\ud83c\udfa5 Pulsar Documentation - Getting Started <ul> <li>Apache Pulsar documentation</li> </ul>"},{"location":"pages/astra/create-topic/#a-overview","title":"A - Overview","text":"<p><code>ASTRA STREAMING</code> is the simplest way to use the Apache Pulsar messaging/streaming service with zero operations - just push the button and get your messages flowing. No credit card required, $25.00 USD credit every month, and all of thethe strength and features of Apache Pulsar managed for you in the cloud.</p> <p>This page explains how to create a new tenant in Astra Streaming, a new namespace in the tenant (if desired) and a new topic in the namespace. Also instructions are given to retrieve the connection parameters to later connect to the topic and start messaging from your application.</p>"},{"location":"pages/astra/create-topic/#b-prerequisites","title":"B - Prerequisites","text":"<ul> <li>You should have an Astra account.</li> <li>Have a <code>tenant_name</code>, optionally a <code>namespace</code> (if not using \"default\"), and a <code>topic_name</code> ready to create the topic.</li> </ul>"},{"location":"pages/astra/create-topic/#c-procedure","title":"C - Procedure","text":"<p>Make sure you are logged in to your Astra account before proceeding.</p> <p>\u2705 Step 1: Create a tenant</p> <p>Go to your Astra console, click the \"Create Stream\" button next to the Streaming section.</p> <p>Set up a new Tenant (remember Pulsar has a multi-tenant architecture): you have to find a globally unique name for it. Pick the provider and region (try to have it close to you for reduced latency) and finally hit \"Create Tenant\".</p> <p>You'll shortly see the dashboard for your newly-created Tenant.</p> <p>\u2705 Step 2: Create a namespace</p> <p>A <code>default</code> namespace is created for you with the tenant and you can use it as is. However, you may want to create a separate namespace to host your topic(s).</p> <p>Go to the \"Namespaces\" tab of your Tenant dashboard and click on the \"Create namespace\" button on the right. Choose a name and hit \"Create\". You should see it listed among the available namespaces in a moment.</p> <p>\u2705 Step 3: Create a topic</p> <p>Switch to the \"Topics\" tab and click the \"Add Topic\" button next to the namespace that you want to use.</p> <p>Choose a topic name, review and/or modify the topic settings (such as <code>persistent=yes, partitioned=no</code>), and click \"Save\".</p> <p>It takes no more than a couple of minutes to create your new topic. It will then be ready to receive and dispatch messages.</p> <p>\ud83d\udc41\ufe0f Walkthrough for topic creation</p> <p></p> <p>\u2705 Step 4: retrieve the Broker URL</p> <p>All that is left is to make sure you have the connection parameters needed to reach the topic programmatically. If you click the \"Connect\" tab you will see a list of \"Tenant Details\", along with links to look at code examples in various languages.</p> <p>There are several ways to connect to the topic. If you plan to use the Pulsar drivers from your application, the important bits are the \"Broker Service URL\" and the \"Streaming Token\" secret.</p> <p>The \"Broker Service URL\" is shown right in the \"Connect\" tab and looks like <code>pulsar+ssl://pulsar-[...].streaming.datastax.com:6651</code>. You can click on the clipboard icon to copy it.</p> <p>\u2705 Step 5: Manage secrets and retrieve the Streaming Token</p> <p>You will also need a Token, a long secret string providing authentication info when the driver will connect to the topic. The token must be treated as a secret, which means do not post it publicly and do not check it in to version control.</p> <p>Note: Streaming Tokens are completely separate from Astra DB Tokens.</p> <p>Navigate to the \"Token Manager\" by clicking on the link in the \"Tenant Details\" list: there you will be able to create, copy and revoke streaming tokens for your tenant.</p> <p>Note that a default token has already been created for you, so you don't necessarily need to create a new token. Click on the clipboard icon to copy it.</p> <p>The token is a long random-looking string, such as <code>eyJhbGci [...] cpNpX_qN68Q</code> (about 500 chars long).</p> <p>\ud83d\udc41\ufe0f Screenshot for the connection parameters</p> <p></p>"},{"location":"pages/astra/download-scb/","title":"\u2023 Secure Connect Bundle","text":"\ud83d\udcd6 Reference Documentation and resources <ol> <li>\ud83d\udcd6  Astra Docs - Download Cloud Secure Bundle <li>\ud83c\udfa5 Youtube Video - Walk through secure"},{"location":"pages/astra/download-scb/#a-overview","title":"A - Overview","text":"<p>To initialize a secured 2-way TLS connection between clients and Astra x509 certificates are needed. The strong authentication is key for maximum security and still benefits from robust driver features (health-check, load-balancing, fail-over). Under the hood the protocol SNI over TCP is used to contact each node independently.</p> <p>The configuration and required certificates are provided to the user through a zip file called the secure connect bundle which can be downloaded for each DATABASE REGION. This means that a database deployed across multiple regions will have one secure connect bundle per region. (1 region = 1 underlying Apache Cassandra\u2122 datacenter)</p> <p></p>"},{"location":"pages/astra/download-scb/#b-prerequisites","title":"B - Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> </ul>"},{"location":"pages/astra/download-scb/#c-procedure","title":"C - Procedure","text":"<p>\u2705 Step 1 : Go to your database's Connect Quick Start</p> <p>Once you sign in and land on your Astra Home, reach the Quick Start page for the database whose Secure Connect Bundle you want to obtain. You can do so either through the database list in the left-panel navigation bar, or from the Databases overview in the main panel:</p> From the navigation bar <p>The right-hand navigation bar lists your most commonly-used databases under the \"Databases\" heading. Click on the desired database.</p> <p></p> <p>(Note: the side navigation bar might be collapsed. Click on the \"DS\" logo at the top to expand it.)</p> <p>The main panel will show the database-specific dashboard. Locate the \"Connect\" button on the top right and click on it.</p> <p></p> From the overall database dashboard <p>Alternatively, click on the \"Databases\" entry in the left-hand navigation bar to get to the main databases dashboard.</p> <p></p> <p>(Note: the side navigation bar might be collapsed. Click on the \"DS\" logo at the top to expand it.)</p> <p>Locate the desired database in the list in the main panel and click on the corresponding \"Connect\" button in the table.</p> <p></p> <p>\u2705 Step 2 : Download the bundle ZIP</p> <p>The \"Quick Start\" section features a \"Get Bundle\" button. Click on it to bring up the download-bundle dialog.</p> <p></p> <p>Your database might be multi-region (remember there is a separate bundle for each DB region). In the dialog, choose the desired region for which you need the bundle: a download URL is now generated for you. You now have several options to download the file:</p> <ol> <li>get the file directly with the \"Download Secure Bundle\" button;</li> <li>copy the generated URL to the bundle, by clicking on the \"clipboard\" icon, and use it wherever you want (within a few minutes, before the link expires);</li> <li>directly copy a ready-made <code>cURL</code> command to paste in a console and have the downloaded bundle zipfile there;</li> <li>similar to the previous case, but using the <code>wget</code> console utility.</li> </ol> <p></p>"},{"location":"pages/astra/download-scb/#remarks","title":"Remarks","text":"<ul> <li> <p>If you download the file directly, be aware that most browsers will give you the option to open the zip file directly. Do not do that, save it locally instead: the bundle zipfile has to be passed   to the drivers as is!</p> </li> <li> <p>The link to the bundle zipfile will expire a few minutes after it is generated. If you wait too long,   you might end up with a faulty bundle. As a check, make sure the zipfile you downloaded is around 12-13 KB in size.</p> </li> </ul>"},{"location":"pages/astra/faq/","title":"\u2023 FAQ","text":""},{"location":"pages/astra/faq/#questions-list","title":"Questions List","text":"<ul> <li>Where should I find a database identifier ?</li> <li>Where should I find a database region name ?</li> <li>How do I create a keyspace or a namespace ?</li> <li>How to open the Web CQL Console?</li> </ul>"},{"location":"pages/astra/faq/#where-should-i-find-a-database-identifier","title":"Where should I find a database identifier ?","text":"<p>The database <code>id</code> is a unique identifier (<code>GUID</code>) for your database. You can find it on the main dashboard of Astra DB, reachable by clicking \"Databases\" on the left-side navigation bar. Copy it to your clipboard by clicking on the small \ud83d\udccb icon.</p> <p></p> <p>(Note: the side navigation bar might be collapsed. Click on the \"DS\" logo at the top to expand it.)</p> <p>Remember that, unlike the database <code>id</code>, the database name is not necessarily unique in an organization. That is, with reference to the above image, one could have more than one <code>multics</code> databases, each with a different <code>id</code>.</p>"},{"location":"pages/astra/faq/#where-should-i-find-a-database-region-name","title":"Where should I find a database region name ?","text":"<p>A database can span one or more regions. Each region will have a \"Datacenter ID\" and a \"Region\". The \"Region\" is the one used in the API endpoints.</p> <p>Reach the dashboard specific to the database by either:</p> <ul> <li>clicking on the DB name in the left navigation bar,</li> <li>clicking on the DB name in the overall \"Databases\" list (reachable by clicking \"Databases\" in the navigation bar).</li> </ul> <p>The \"Overview\" page for the database lists all regions in a table. In the example below, you see two regions, identified by <code>eu-central-1</code> and <code>us-east-1</code>.</p> <p></p> <p>Should you need the ID of a certain Datacenter, simply click on the clipboard icon next to the ID to copy it.</p>"},{"location":"pages/astra/faq/#how-do-i-create-a-namespace-or-a-keyspace","title":"How do I create a namespace or a keyspace ?","text":"<p>In Astra DB, \"namespace\" and \"keyspace\" mean exactly the same thing, i.e. mainly a logical grouping of tables. There are two ways to create them.</p>"},{"location":"pages/astra/faq/#at-db-creation-time","title":"At DB-creation time","text":"<p>When creating a new database, you automatically create a keyspace in it:</p> <p></p>"},{"location":"pages/astra/faq/#add-a-keyspace-to-an-existing-database","title":"Add a keyspace to an existing database","text":"<p>From the database's dashboard, find the \"Add Keyspace\" button in the \"Keyspaces\" section of the dashboard and click on it.</p> <p></p> <p>You can access your database dashboard by clicking its name either in the navigation bar on the left or on the overall \"Databases\" main panel.</p> <p>Keep in mind that in order to add a keyspace, the database must be in \"Active\" state - resume it first if necessary.</p> <p></p> <p>The database will switch to <code>Maintenance</code> mode for a few seconds, but no fear: all running applications are still able to access other keyspaces in the database.</p>"},{"location":"pages/astra/faq/#how-to-open-the-web-cql-console","title":"How to open the Web CQL Console?","text":"<p>To access the CQL Console for a certain database, go to the dashboard for the database (clicking on the DB name on the left-hand navigation bar) and simply select the \"CQL Console\" tab in the main panel.</p> <p>An in-browser Web-based console to exchange CQL commands with the database will be available in few seconds, already connected to your database.</p> <p></p> <p>Note: if your database spans multiple regions, your will have the possibility to choose a region for the connection. Each choice of a region will completely reset the console.</p>"},{"location":"pages/astra/multi-regions/","title":"\u2023 Multi Regions","text":"\ud83d\udcd6 Reference Documentation and resources <ol> <li>\ud83d\udcd6  Astra Docs - Reference documentation <li>\ud83c\udfa5 Youtube Video - Walk through instance creation"},{"location":"pages/astra/multi-regions/#a-overview","title":"A - Overview","text":"<p><code>AstraDB</code> allows you to replicate data across multiple regions to maintain data availability for multi-region application architectures. Configuring multiple regions can also satisfy data locality requirements and save money.</p> <p></p>"},{"location":"pages/astra/multi-regions/#eventual-consistency","title":"\ud83d\udd04 Eventual Consistency","text":"<p>Apache Cassandra\u00ae and DataStax Astra DB follow the eventual consistency model. As a result, data written to one datacenter/region may not be immediately accessible in other datacenters/regions in the same database cluster. It normally only takes a few minutes to fully replicate the data. However, it could take longer, and possibly span one or more days. There are several contributing factors to the latter scenario; such as the workload volume, the number of regions, the process that runs data repair operations, and network resources.</p>"},{"location":"pages/astra/multi-regions/#data-sovereignty","title":"\u2696\ufe0f Data sovereignty","text":"<p>Astra DB serverless replicates all data in the database to all of a database\u2019s regions. By contrast, multiple keyspaces in Apache Cassandra\u00ae and DataStax Enterprise (DSE) allow a database to replicate some tables to a subset of regions. To achieve the same behavior as Cassandra or DSE, create a separate Astra DB instance that adheres to the necessary region restrictions. The database client will need to add a separate connection for the additional database and send queries to the appropriate connection depending on the table being queried.</p>"},{"location":"pages/astra/multi-regions/#limitations","title":"\u26a0\ufe0f Limitations","text":"<ul> <li>Lightweight transactions only work for a single-region datacenter.</li> <li>If your original region is disconnected, schema changes are suspended and repairs do not run. If any regions are disconnected, the writes to those regions will not be forwarded.</li> <li>While adding a new region, you cannot drop a table or keyspace and you cannot truncate a table.</li> <li>If any region is not online, you cannot truncate a table.</li> </ul>"},{"location":"pages/astra/multi-regions/#b-prerequisites","title":"B - Prerequisites","text":"<ul> <li> <p>You should have an Astra account</p> </li> <li> <p>You should have a CREDIT CARD in the system AND/OR have MORE THAN 25$ in Astra Credits.</p> </li> </ul> <p></p>"},{"location":"pages/astra/multi-regions/#c-create-a-new-region","title":"C - Create a new Region","text":"<p>\u2705 Step 1: Click the <code>Add Region</code> Button</p> <ul> <li>Select the database to show the Dashboard and select <code>Add Region.</code></li> </ul> <p></p> <p>\u2705 Step 2: Select your region</p> <ul> <li>Select your desired region from the dropdown menu.</li> </ul> <p></p> <ul> <li>Your selected region and the costs appear below the dropdown menu. You can add only a single region at a time.</li> </ul> <p></p> <p>\u2705 Step 3: Validate your region</p> <ul> <li> <p>Select Add Region to add the region to your database.</p> </li> <li> <p>The database with switch to Maintenance status. Do not worry, the existing regions will remain active and available for operations. There is no downtime.</p> </li> </ul> <p></p> <p>After you add the new region, your new region will show up in the list of regions on your database Dashboard.</p> <p></p> <p>After the initialization, you will get:</p> <p></p>"},{"location":"pages/astra/multi-regions/#d-delete-a-new-region","title":"D - Delete a new Region","text":"<p>\u2705 Step 1: Select Region to delete</p> <ul> <li>From your database Dashboard, select the overflow menu for the database that you want to delete and select Delete. You will notice that you CANNOT delete the original main region.</li> </ul> <p></p> <p>\u2705 Step 2: Validate your action</p> <ul> <li>Removing a region is not reversible so proceed with caution. A pop-up will ask you to validate this operation by entering the <code>delete</code> word.</li> </ul> <p></p> <ul> <li>The database will switch to Maintenance mode. After a few seconds, you will see the status of the deleted regions change from <code>Active</code> to <code>Offline</code>.</li> </ul> <p></p> <ul> <li>Finally the region will not be visible in the Regions list.</li> </ul> <p></p>"},{"location":"pages/astra/resume-db/","title":"\u2023 Resume a database","text":""},{"location":"pages/astra/resume-db/#a-overview","title":"A - Overview","text":"<p>In the free tier (serverless), after <code>48 hours</code> of inactivity, your database will be hibernated and the status will change to Hibernated. From there it needs to be resumed, there are multiple ways to do it.</p>"},{"location":"pages/astra/resume-db/#b-prerequisites","title":"B - Prerequisites","text":"<ul> <li>You should have an Astra account</li> </ul>"},{"location":"pages/astra/resume-db/#c-procedure","title":"C - Procedure","text":"<p>\u2705 Option 1: Resume with button in the User interface</p> <ul> <li>Access the database by clicking its name in the menu on the left.</li> </ul> <p></p> <ul> <li>Once the database is selected, on any tab you will get the <code>Resume Database</code> button available at top.</li> </ul> <p></p> <p>\u2705 Option 2: Resume with the CLI</p> <p>Assuming you have the Astra CLi installed and setup.</p> <pre><code>astra db resume &lt;my_db&gt;\n</code></pre> <p>\u2705 Option 3: Resume with a first request to the database</p> <p>Invoking and Stargate endpoints associated with your database will also trigger resuming. You would have to replace the <code>dbId</code>, <code>dbRegion</code> and <code>token</code> below with values for your environment.</p> <pre><code>curl --location \\\n--request GET 'https://{dbId}-{dbRegion}.apps.astra.datastax.com/api/rest/v2/schemas/keyspaces/' \\\n--header 'X-Cassandra-Token: {token}'\n</code></pre> <p>You will get a <code>503</code> error with the following payload.</p> <pre><code>{\n\"message\": \"Resuming your database, please try again shortly.\"\n}\n</code></pre> <ul> <li>In the user interface the status changes to <code>resuming...</code></li> </ul> <p></p> <ul> <li>After a few seconds the database will be active.</li> </ul> <p></p>"},{"location":"pages/data/","title":"Home","text":""},{"location":"pages/data/#load-and-export","title":"\ud83d\udce5 Load and Export","text":"<p>In this section are listed third party tools that will help you import or export data from your databases. They are designed for bulk operations.</p> <p> </p>"},{"location":"pages/data/#browse","title":"\ud83d\udd0d Browse","text":"<p>In this section are listed third party tools that will help you browse your data. You will find listed keyspaces, tables and will be able to edit the values.</p> <p> </p>"},{"location":"pages/data/#data-modelling","title":"\ud83d\udccb Data Modelling","text":""},{"location":"pages/data/explore/cqlsh/","title":"\u2023 Cqlsh","text":"\ud83d\udcd6 Reference Documentations and resources <ol> <li>\ud83d\udcd6  Astra Docs - Reference documentation <li>\ud83d\udcd6  Cql Tool Docs - Reference Documentation"},{"location":"pages/data/explore/cqlsh/#a-overview","title":"A - Overview","text":"<p>CqlSH is a command-line interface for interacting with Cassandra using CQL (the Cassandra Query Language). It is shipped with every Cassandra package, and can be found in the bin/ directory alongside the cassandra executable. cqlsh is implemented with the Python native protocol driver, and connects to the single specified node.</p> <p>You can setup the software by providing options in the command line and/OR provide the settings in a file called <code>cqlshrc</code> located in <code>~/.cassandra</code></p> <pre><code>&gt; cqlsh --help\nUsage: cqlsh [options] [host [port]]\n\nCQL Shell\n\nOptions:\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n  -C, --color           Always use color output\n  --no-color            Never use color output\n  --browser=BROWSER     The browser to use to display CQL help, where BROWSER\n                        can be:\n                        - one of the supported browsers in\n                        https://docs.python.org/2/library/webbrowser.html.\n                        - browser path followed by %s, example: /usr/bin\n                        /google-chrome-stable %s\n  --ssl                 Use SSL\n  -u USERNAME, --username=USERNAME\n                        Authenticate as user.\n  -p PASSWORD, --password=PASSWORD\n                        Authenticate using password.\n  -k KEYSPACE, --keyspace=KEYSPACE\n                        Authenticate to the given keyspace.\n  -b SECURE_CONNECT_BUNDLE, --secure-connect-bundle=SECURE_CONNECT_BUNDLE\n                        Connect using secure connect bundle. If this option is\n                        specified host, port settings are ignored\n  -f FILE, --file=FILE  Execute commands from FILE, then exit\n  --debug               Show additional debugging information\n  --coverage            Collect coverage data\n  --encoding=ENCODING   Specify a non-default encoding for output. (Default:\n                        utf-8)\n  --cqlshrc=CQLSHRC     Specify an alternative cqlshrc file location.\n  --cqlversion=CQLVERSION\n                        Specify a particular CQL version, by default the\n                        highest version supported by the server will be used.\n                        Examples: \"3.0.3\", \"3.1.0\"\n  --protocol-version=PROTOCOL_VERSION\n                        Specify a specific protocol version; otherwise the\n                        client will default and downgrade as necessary.\n                        Mutually exclusive with --dse-protocol-version.\n  -e EXECUTE, --execute=EXECUTE\n                        Execute the statement and quit.\n  --connect-timeout=CONNECT_TIMEOUT\n                        Specify the connection timeout in seconds (default: 5\n                        seconds).\n  --request-timeout=REQUEST_TIMEOUT\n                        Specify the default request timeout in seconds\n                        (default: 10 seconds).\n  --consistency-level=CONSISTENCY_LEVEL\n                        Specify the initial consistency level.\n  --serial-consistency-level=SERIAL_CONSISTENCY_LEVEL\n                        Specify the initial serial consistency level.\n  -t, --tty             Force tty mode (command prompt).\n  --no-file-io          Disable cqlsh commands that perform file I/O.\n  --disable-history     Disable saving of history\n\nConnects to 127.0.0.1:9042 by default. These defaults can be changed by\nsetting $CQLSH_HOST and/or $CQLSH_PORT. When a host (and optional port number)\nare given on the command line, they take precedence over any defaults.\n</code></pre>"},{"location":"pages/data/explore/cqlsh/#b-prerequisites","title":"B - Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should download the Cqlsh Version for Astra DB</li> <li>You should NOT use a WINDOWS machine, as of today <code>cqlsh</code> is not supported on Windows</li> </ul>"},{"location":"pages/data/explore/cqlsh/#c-installation","title":"C - Installation","text":"<p>\u2705 Step 1: Download and extract the archive</p> <ul> <li>To download the archive you can go on the download page, check the box and download the file:</li> </ul> <p></p> <ul> <li>You can also use the command line:</li> </ul> <pre><code>wget https://downloads.datastax.com/enterprise/cqlsh-astra.tar.gz \\\n          &amp;&amp; tar xvzf cqlsh-astra.tar.gz \\\n          &amp;&amp; rm -f cqlsh-astra.tar.gz\n</code></pre> <ul> <li>The archive should look like:</li> </ul> <p></p> <p>\u2705 Step 2: Start <code>cqlsh</code> providing parameters in the command line:</p> <ul> <li>From the directory where you extracted the CQLSH tarball, run the <code>cqlsh</code> script from the command line:</li> </ul> <pre><code>$ cd /cqlsh-astra/bin\n\n$ ./cqlsh -u ${CLIENT_ID} -p ${CLIENT_SECRET} -b ${PATH_TO_SECURE_BUNDLE.zip}\n</code></pre> <ul> <li><code>-u</code> (username) - Client ID as provided in the token generation page</li> <li><code>-p</code> (password) - Client secret as provided in the token generation page</li> <li><code>-b</code> (bundle) - location of the secure connect bundle that you downloaded for your database.</li> </ul> <p>\u2705 Step 3: Start <code>Cqlsh</code> providing parameters in <code>cqlshrc</code></p> <p>Configure the cqlshrc file If you do not want to pass the secure connect bundle on the command line every time, set up the location in your <code>cqlshrc</code> file in <code>~/.cassandra</code></p> <pre><code>[authentication]\nusername = ${CLIENT_ID}\npassword = ${CLIENT_SECRET}\n\n[connection]\nsecure_connect_bundle = ${PATH_TO_SECURE_BUNDLE.zip}\n</code></pre>"},{"location":"pages/data/explore/cqlsh/#d-tips-and-tricks","title":"D - Tips and tricks","text":"<ul> <li> <p>If is a good idea to add <code>cqlsh</code> in your path to be able to use from everywhere</p> </li> <li> <p>If you want to work with multiple DB use some alias with the parameters</p> </li> </ul> <pre><code>alias cqlsh_db1='cqlsh -u user -p password -b secure-connect-db1.zip'\nalias cqlsh_db2='cqlsh --cqlshrc_db2'\n</code></pre>"},{"location":"pages/data/explore/datagrip/","title":"DataGrip","text":""},{"location":"pages/data/explore/datagrip/#overview","title":"Overview","text":"<ul> <li>\u2139\ufe0f Astra Docs - Reference documentation</li> <li>\u2139\ufe0f Instructions on Sebastian Estevez's blog post</li> <li>\u2139\ufe0f Datagrip reference documentation</li> </ul> <p>DataGrip is a database management environment for developers. It is designed to query, create, and manage databases. Databases can work locally, on a server, or in the cloud. Supports MySQL, PostgreSQL, Microsoft SQL Server, Oracle, and more. If you have a JDBC driver, add it to DataGrip, connect to your DBMS, and start working.</p>"},{"location":"pages/data/explore/datagrip/#prerequisites","title":"Prerequisites","text":"<ul> <li>Create an Astra Database</li> <li>Create an Astra Token</li> <li>Download your secure connect bundle ZIP</li> <li>Download and install DataGrip</li> </ul>"},{"location":"pages/data/explore/datagrip/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"pages/data/explore/datagrip/#step-1-download-jdbc-driver","title":"Step 1: Download JDBC Driver","text":"<p>Download the JDBC driver from the DataStax website:</p> <ol> <li>Go to downloads.datastax.com/#odbc-jdbc-drivers.</li> <li>Select Simba JDBC Driver for Apache Cassandra.</li> <li>Select JDBC 4.2.</li> <li>Read the license terms and accept it (click the checkbox).</li> <li>Hit the blue Download button.</li> <li>Once the download completes, unzip the downloaded file.</li> </ol> <p></p>"},{"location":"pages/data/explore/datagrip/#step-2-download-settingszip","title":"Step 2:  Download <code>Settings.zip</code>","text":"<ul> <li>Download the settings.zip locally</li> </ul> <p>If you are already a DataGrip user, back up your existing settings because downloading <code>settings.zip</code> might override your existing settings.</p>"},{"location":"pages/data/explore/datagrip/#step-3-import-the-settingszip-into-datagrip","title":"Step 3:  Import the settings.zip into DataGrip","text":"<ul> <li> <p>Selecting <code>File</code> \u2192 <code>Manage IDE Settings</code> \u2192 <code>Import Settings</code> in DataGrip.</p> </li> <li> <p>From the directory menu, select the <code>settings.zip</code> file from the directory where it is stored.</p> </li> <li> <p>Select Import and Restart.</p> </li> </ul> <p>You will see a new database connection type called Astra: Simba Cassandra JDBC 4.2 driver shown.</p> <p></p> <ul> <li>Go to the Advanced Settings to confirm the VM home path is set to Default. VM home path is set to a value named Default.</li> </ul> <p></p>"},{"location":"pages/data/explore/datagrip/#step-4-establish-the-connection","title":"Step 4:  Establish the connection","text":"<p>When you create your connection, the URL will look like this: <code>jdbc:cassandra://;AuthMech=&lt;2&gt;;UID=token;PWD=&lt;ApplicationToken&gt;;SecureConnectionBundlePath=&lt;PATH TO YOUR SECURE CONNECT BUNDLE&gt;;TunableConsistency=&lt;6&gt;</code></p> <p></p> <p>URL in the screenshot shows the format described in the previous sentence.</p> <ul> <li>AuthMech: Specifies whether the driver connects to a Cassandra or Astra DB database and whether the driver authenticates the connection.</li> <li>ApplicationToken: Generated from Astra DB console.</li> <li>SecureConnectionBundlePath: Path to where your downloaded Secure Connect Bundle is located.</li> <li>TunableConsistency: Specifies Cassandra replica or the number of Cassandra replicas that must process a query for the query to be considered successful.</li> </ul>"},{"location":"pages/data/explore/dbeaver/","title":"DBeaver","text":"<ul> <li>This article includes information that was originally written by Erick Ramirez on DataStax Community</li> </ul>"},{"location":"pages/data/explore/dbeaver/#overview","title":"Overview","text":"<p>DBeaver is a universal database management tool for everyone who needs to work with data in a professional way. With DBeaver you are able to manipulate with your data like in a regular spreadsheet, create analytical reports based on records from different data storages, export information in an appropriate format.</p> <ul> <li>\u2139\ufe0f Introduction to DBeaver</li> <li>\ud83d\udce5 DBeaver Download Link</li> </ul>"},{"location":"pages/data/explore/dbeaver/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> </ul> <p>This article assumes you have installed DBeaver Community Edition on your laptop or PC. It was written for version 21.2.0 on MacOS but it should also work for the Windows version.</p>"},{"location":"pages/data/explore/dbeaver/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"pages/data/explore/dbeaver/#step-1-jdbc-driver","title":"\u2705 Step 1:  JDBC Driver","text":"<p>Download the JDBC driver from the DataStax website:</p> <ol> <li>Go to https://downloads.datastax.com/#odbc-jdbc-drivers.</li> <li>Select Simba JDBC Driver for Apache Cassandra.</li> <li>Select JDBC 4.2.</li> <li>Read the license terms and accept it (click the checkbox).</li> <li>Hit the blue Download button.</li> <li>Once the download completes, unzip the downloaded file.</li> </ol>"},{"location":"pages/data/explore/dbeaver/#step-2-import-driver","title":"\u2705 Step 2:  Import Driver","text":"<ol> <li>Go to the Driver Manager.</li> <li>Click the New button.</li> <li>In the Libraries tab, click the Add File button.</li> <li>Locate the directory where you unzipped the driver download and add the <code>CassandraJDBC42.jar</code> file.</li> <li>Click the Find Class button which should identify the driver class as <code>com.simba.cassandra.jdbc42.Driver</code>.</li> <li> <p>In the Settings tab, set the following:</p> </li> <li> <p>Driver Name: <code>Astra DB</code></p> </li> <li>Driver Type: <code>Generic</code></li> <li> <p>Class Name: <code>com.simba.cassandra.jdbc42.Driver</code> </p> </li> <li> <p>Click the OK button to save the driver</p> </li> </ol> <p>At this point, you should see Astra DB as one of the drivers on the list:</p> <p> </p>"},{"location":"pages/data/explore/dbeaver/#step-3-create-new-connection","title":"\u2705 Step 3:  Create New Connection","text":"<p>Connect to your Astra DB in DBeaver:</p> <ol> <li>Open the New Database Connection dialog box.</li> <li>Select Astra DB from the list of drivers.</li> <li>In the Main tab, set the JDBC URL to:    <code>jdbc:cassandra://;AuthMech=2;TunableConsistency=6;SecureConnectionBundlePath=/path/to/secure-connect-dbeaver.zip</code> Note That you will need to specify the full path to your secure bundle.</li> <li>In the Username field, enter the string <code>token</code></li> <li> <p>In the Password field, paste the value of the token you created in the Prerequisites section above. The token looks like <code>AstraCS:AbC...XYz:123...edf0</code>.    </p> </li> <li> <p>Click on the Connection details button</p> </li> <li>In Connection name field, give your DB connection a name: </li> <li>Click the Finish button</li> <li>Click on the Test Connection button to confirm that the driver configuration is working:</li> </ol> <p> </p>"},{"location":"pages/data/explore/dbeaver/#step-4-final-test","title":"\u2705 Step 4:  Final Test","text":"<p>Connect to your Astra DB. If the connection was successful, you should be able to explore the keyspaces and tables in your DB on the left-hand side of the UI.</p> <p>Here's an example output:</p> <p></p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/data/explore/dbschema/","title":"DbSchema","text":"\ud83d\udcd6 Reference Documentations and resources <ol> <li>\ud83d\udcd6 Astra Docs - Reference documentation <li>DBSchema Tutorials </li> </li> </ol>"},{"location":"pages/data/explore/dbschema/#overview","title":"Overview","text":"<p>DbSchema is a universal database designer for out-of-the-box schema management and documentation, sharing the schema in the team, and deploying on different databases. Visual tools can help developers, database administrators, and decision-makers to query, explore and manage the data.</p> <ul> <li>\u2139\ufe0f Introduction to DBSchema</li> <li>\ud83d\udce5 DBSchema Installation</li> </ul> <p>DBSchema uses the Simba JDBC driver to connect to Cassandra as the storage backend. The Java driver itself supports connections to Astra DB natively.</p>"},{"location":"pages/data/explore/dbschema/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul> <p>This article assumes you have installed the latest version of DBSchema on your laptop or PC.</p>"},{"location":"pages/data/explore/dbschema/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"pages/data/explore/dbschema/#step-1-jdbc-driver","title":"\u2705 Step 1:  JDBC Driver","text":"<p>Download the JDBC driver from the DataStax website:</p> <ol> <li>Go to https://downloads.datastax.com/#odbc-jdbc-drivers.</li> <li>Select Simba JDBC Driver for Apache Cassandra.</li> <li>Select JDBC 4.2.</li> <li>Read the license terms and accept it (click the checkbox).</li> <li>Hit the blue Download button.</li> <li>Once the download completes, unzip the downloaded file.</li> </ol>"},{"location":"pages/data/explore/dbschema/#step-2-establish-the-connection","title":"\u2705 Step 2:  Establish the Connection","text":"<ol> <li>Open DB Schema</li> <li>Select Connect to the Database</li> <li> <p>Select Start </p> </li> <li> <p>In the Choose your database menu, select Cassandra.</p> </li> <li> <p>Select Next. </p> </li> <li> <p>Select JDBC Driver edit option. </p> </li> <li> <p>In the JDBC Driver Manager, select New.</p> </li> <li> <p>In the Add RDBMS window, enter Astra and select OK </p> </li> <li> <p>Select OK in the confirmation message. </p> </li> <li> <p>Upload the Simba JDBC Driver.</p> </li> <li> <p>Select Open </p> </li> <li> <p>Once you upload the Simba JDBC Driver, you will see Astra in the Choose your Database window. Select Next. </p> </li> <li> <p>In the Astra Connection Dialog, add JDBC URL as     <pre><code>jdbc:cassandra://;AuthMech=&lt;2&gt;;UID=token;PWD=&lt;ApplicationToken&gt;;SecureConnectionBundlePath=&lt;PATH TO YOUR SECURE CONNECT BUNDLE&gt;;TunableConsistency=&lt;6&gt;\n</code></pre>     with the following variables:</p> <ul> <li>AuthMech: Specifies whether the driver connects to a Cassandra or Astra DB database and whether the driver authenticates the connection.</li> <li>ApplicationToken: Generated from Astra DB console. See Manage application tokens.</li> <li>SecureConnectionBundlePath: Path to where your downloaded Secure Connect Bundle is located. See Get secure connect bundle.</li> <li>TunableConsistency: Specifies Cassandra replica or the number of Cassandra replicas that must process a query for the query to be considered successful.</li> </ul> </li> <li> <p>Select Connect </p> </li> <li> <p>In the Select Schemas/Catalogs, select the keyspace to which you want to connect.</p> </li> <li>Select OK. </li> </ol>"},{"location":"pages/data/explore/dbschema/#step-3-final-test","title":"\u2705 Step 3:  Final Test","text":"<p>Now that your connection is working, you can create tables, introspect your keyspaces, view your data in the DBSchema GUI, and more.</p> <p>To learn more about DBSchema, see Quick start with DBSchema</p> <p>\ud83c\udfe0 Back to HOME </p>"},{"location":"pages/data/explore/mindsdb/","title":"MindsDB","text":"<ul> <li>This article was originally written by Steven Matison on DataStax JIRA</li> </ul>"},{"location":"pages/data/explore/mindsdb/#overview","title":"Overview","text":"<p>This page will go into details about what I had to do to build the project, modify the <code>cassandra.py</code> and <code>scylla_ds.py</code>, and get mindsdb GUI connected to Astra.</p> <ul> <li>Source Repo: GitHub - mindsdb/mindsdb</li> <li>My Fork: ds-steven-matison/mindsdb</li> <li>Docs: https://docs.mindsdb.com/</li> </ul>"},{"location":"pages/data/explore/mindsdb/#process","title":"Process","text":""},{"location":"pages/data/explore/mindsdb/#files-changed","title":"Files Changed","text":"<pre><code>/root/mindsdb/lib64/python3.6/site-packages/mindsdb_datasources/datasources/scylla_ds.py\n</code></pre> <ul> <li>Path here is correct. \u201clib64\u201d not part of repo, so I put scylla_ds.py in repo so you can see source code here: github diff</li> </ul> <pre><code>/root/mindsdb/lib64/python3.6/site-packages/mindsdb_datasources/cassandra.py\n</code></pre> <ul> <li>Changes diff in repo here: github diff</li> </ul>"},{"location":"pages/data/explore/mindsdb/#git-status","title":"Git Status","text":"<pre><code>Untracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\nLICENSE.txt\n    MindsDB.egg-info/\n    bin/\n    config.json\n    include/\n    lib/\n    lib64\n    mindsdb/integrations/cassandra/cassandra.py.bk\n    mindsdb/integrations/cassandra/tmp.py\n    pip-selfcheck.json\n    share/\n</code></pre>"},{"location":"pages/data/explore/mindsdb/#terminal-history","title":"Terminal History","text":"<pre><code>  503  python -v\n  504  python -version\n  505  ls\n  506  python3 -v\n  507  python3 -m venv mindsdb\n  508  source mindsdb/bin/activate\n  509  pip3 install mindsdb\n  510  pip3 install Cython\n  511  pip3 install mindsdb\n  512  pip3 install sentencepiece\n  513  pip3 freeze\n  514  pip install --upgrade pip\n  515  pip3 install sentencepiece\n  516  pip3 install mindsdb\n  517  pip3 freeze\n  518  python3 -m mindsdb\n  533  pip3 install mindsdb\n  548  pip3 install cassandra-driver\n  549  python3 -c 'import cassandra; print (cassandra.__version__)'\n570  python3 mindsdb_cassandra.py\n  571  nano mindsdb_cassandra.py\n  572  python3 mindsdb_cassandra.py\n  573  python3 -m mindsdb --api=mysql --config=config.json\n  574  pip3 uninstall mindsdb\n  577  git clone https://github.com/ds-steven-matison/mindsdb.git\n  578  cd mindsdb/mindsdb/integrations/cassandra/\n  579  ls\n  580  nano cassandra.py\n  581  cp cassandra.py cassandra.py.bk\n  582  nano cassandra.py\n  588  pip3 install -r requirements.txt\n  592  pip3 install cassandra-driver\n  636  cp secure-connect-mindsdb.zip /tmp\n  637  chmod 755 /tmp/secure-connect-mindsdb.zip\n  654  pip3 freeze\n  658  pip3 install cassandra-driver\n  659  python3 -c 'import cassandra; print (cassandra.__version__)'\n662  nano /root/mindsdb/lib64/python3.6/site-packages/mindsdb_datasources/cassandra.py\n  669  nano ./mindsdb/lib/python3.6/site-packages/cassandra/cluster.py\n  670  nano /root/mindsdb/lib64/python3.6/site-packages/mindsdb_datasources/datasources/scylla_ds.py\n  672  python3 -m venv mindsdb\n  673  source mindsdb/bin/activate\n  674  cd mindsdb &amp;&amp; pip3 install -r requirements.txt\n  675  pip install --upgrade pip\n  676  pip3 install --upgrade pip\n  677  pip3 install -r requirements.txt\n  678  python setup.py develop\n  683  mkdir /storage\n  695  install mindsdb_native[cassandra]\n696  pip3 install mindsdb-sdk\n  721  nano config.json\n  722  python3 -m mindsdb --config=config.json\n</code></pre>"},{"location":"pages/data/explore/netflix-data-explorer/","title":"Netflix Data Explorer","text":"\ud83d\udcd6 Reference Documentations and resources <ol> <li>\ud83d\udcd6 Netlix Blog - Introduction of the tool by Netflix <li>Github Repository - Core project  <li>Github Repository - Fork for Astra  </li> </li> </li> </ol>"},{"location":"pages/data/explore/netflix-data-explorer/#overview","title":"Overview","text":"<p>The Data Explorer by netflix is a web-based tools that will help you navigate and edit your data. It supports both Cassandra and Dynomite but here we will focus on Astra. There a few killer features</p>"},{"location":"pages/data/explore/netflix-data-explorer/#multi-cluster-access","title":"Multi Cluster Access","text":"<p>Multi-cluster access provides easy access to all of the clusters in your environment. The cluster selector in the top nav allows you to switch to any of your discovered clusters quickly.</p> <p> </p>"},{"location":"pages/data/explore/netflix-data-explorer/#explore-your-data","title":"Explore your data","text":"<p>The Explore view provides a simple way to explore your data quickly. You can query by partition and clustering keys, insert and edit records, and easily export the results or download them as CQL statements.</p> <p> </p>"},{"location":"pages/data/explore/netflix-data-explorer/#schema-designer","title":"Schema Designer","text":"<p>Creating a new Keyspace and Table by hand can be error-prone</p> <p>Our schema designer UI streamlines creating a new Table with improved validation and enforcement of best practices.</p> <p> </p>"},{"location":"pages/data/explore/netflix-data-explorer/#query-ide","title":"Query IDE","text":"<p>The Query Mode provides a powerful IDE-like experience for writing free-form CQL queries.</p> <p></p>"},{"location":"pages/data/explore/netflix-data-explorer/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> </ul>"},{"location":"pages/data/explore/netflix-data-explorer/#procedure","title":"Procedure","text":""},{"location":"pages/data/explore/netflix-data-explorer/#1-run-locally","title":"1 Run Locally","text":"<p>Prerequisites: You need <code>node</code>, <code>npm</code> and <code>yarn</code></p> <ul> <li>Install Yarn on MAC</li> </ul> <pre><code>brew install yarn\n</code></pre> <ul> <li>Clone the repository</li> </ul> <pre><code>git clone https://github.com/DataStax-Examples/nf-data-explorer.git\ncd nf-data-explorer\n</code></pre> <ul> <li>Install the dependencies (expect a 2min build it will download quite some packages)</li> </ul> <pre><code>yarn &amp;&amp; yarn build\n</code></pre> <ul> <li>Start the applications</li> </ul> <pre><code>yarn start\n</code></pre> <ul> <li>Import your secure connect bundle (see Prerequisite section above)</li> </ul> <p></p>"},{"location":"pages/data/explore/netflix-data-explorer/#2-execute-with-gitpod","title":"2 Execute with Gitpod","text":"<ul> <li>Click the button</li> </ul> <ul> <li>Open the application</li> </ul> <ul> <li>Import your secure connect bundle (see Prerequisite section above)</li> </ul> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/data/explore/presto/","title":"Presto","text":""},{"location":"pages/data/explore/presto/#overview","title":"Overview","text":"<p>Presto is a distributed SQL query engine for big data analytics. Presto can query data from over 30 different data sources, including Cassandra, MongoDB, MySQL, PostgresSQL, and Redis. Common Presto use cases include:</p> <ul> <li>interactive data analytics,</li> <li>SQL-based analytics over object storage systems,</li> <li>data access and analytics across multiple data sources with query federation,</li> <li>batch ETL processing across disparate systems.</li> </ul> <p>In this tutorial, we show how to use Presto to explore and query data in Astra DB with SQL. The overall architecture of this solution is depicted below. Presto CLI Client sends SQL queries to Presto Server. Presto Server retrieves data from Astra DB via CQL Proxy, computes the query results and returns them to the client.</p> <p></p>"},{"location":"pages/data/explore/presto/#prerequisites","title":"Prerequisites","text":"<ul> <li>Create an Astra Database</li> <li>Create an Astra Token</li> </ul>"},{"location":"pages/data/explore/presto/#setup-astra-db","title":"Setup Astra DB","text":"<p>\u2705 1. Sign in</p> <p>Connect to your Astra account and create a new Astra database or select an existing one. Add a new keyspace with name <code>banking_db</code> or use an existing one.</p> <p>\u2705 2. Create the following tables using the CQL Console</p> <pre><code>USE banking_db;\n</code></pre> <pre><code>CREATE TABLE customer (\nid UUID,\nname TEXT,\nemail TEXT,\nPRIMARY KEY (id)\n);\nCREATE TABLE accounts_by_customer (\ncustomer_id UUID,\naccount_number TEXT,\naccount_type TEXT,\naccount_balance DECIMAL,\ncustomer_name TEXT STATIC,\nPRIMARY KEY ((customer_id), account_number)\n);\n</code></pre> <p>\u2705 3. Insert the rows using the CQL Console</p> <pre><code>INSERT INTO customer (id,name,email) VALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'Alice','alice@example.org');\nINSERT INTO customer (id,name,email) VALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'Bob','bob@example.org');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'A-101','Checking',100.01,'Alice');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'A-102','Savings',200.02,'Alice');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'B-101','Checking',300.03,'Bob');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'B-102','Savings',400.04,'Bob');\n</code></pre>"},{"location":"pages/data/explore/presto/#deploy-cql-proxy","title":"Deploy CQL Proxy","text":"<p>\u2705 4. Installation</p> <p>Follow the instructions to deploy a CQL Proxy as close to a Presto Server as possible, preferrably deploying both components on the same server. The simplest way to start <code>cql-proxy</code> is to use an <code>&lt;astra-token&gt;</code> and <code>&lt;astra-database-id&gt;</code>:</p> <pre><code>./cql-proxy \\\n--astra-token &lt;astra-token&gt; \\\n--astra-database-id &lt;astra-database-id&gt;\n</code></pre> <p>An example command with a sample, invalid token and database id:</p> <pre><code>./cql-proxy \\\n--astra-token AstraCS:NoBhcuwCrIhZxqzjEMCSuGos:8a85142b47a588472a1f3b1314e2141f098785895411dee9db11f2a7ade457ce \\\n--astra-database-id e5e4e925-289a-8231-83fd-25918093257b\n</code></pre>"},{"location":"pages/data/explore/presto/#setup-presto-server","title":"Setup Presto Server","text":"<p>\u2705 5. Presto intallation</p> <p>Follow the instructions to download, install and configure a Presto Server or use an existing deployment. The minimal configuration requirements for a local single-machine deployment are:</p> <ul> <li>Node properties in file <code>etc/node.properties</code></li> </ul> <pre><code>node.environment=production\nnode.id=ffffffff-ffff-ffff-ffff-ffffffffffff\nnode.data-dir=/var/presto/data\n</code></pre> <ul> <li>JVM config in file <code>etc/jvm.config</code></li> </ul> <pre><code>-server\n-Xmx16G\n-XX:+UseG1GC\n-XX:G1HeapRegionSize=32M\n-XX:+UseGCOverheadLimit\n-XX:+ExplicitGCInvokesConcurrent\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:+ExitOnOutOfMemoryError\n-Djdk.attach.allowAttachSelf=true\n</code></pre> <ul> <li>Config properties in file <code>etc/config.properties</code></li> </ul> <pre><code>coordinator=true\nnode-scheduler.include-coordinator=true\nhttp-server.http.port=8080\nquery.max-memory=5GB\nquery.max-memory-per-node=1GB\nquery.max-total-memory-per-node=2GB\ndiscovery-server.enabled=true\ndiscovery.uri=http://localhost:8080\n</code></pre> <ul> <li>Catalog properties in file <code>etc/catalog/cassandra.properties</code></li> </ul> <pre><code>connector.name=cassandra\ncassandra.contact-points=localhost\ncassandra.consistency-level=QUORUM\n</code></pre> <p>The above configuration uses the Cassandra connector to interact with <code>cql-proxy</code>.</p> <p>\u2705 6. Start the Presto Server:</p> <pre><code>bin/launcher run\n</code></pre> <p>Wait for message <code>======== SERVER STARTED ========</code> to confirm a successful start.</p>"},{"location":"pages/data/explore/presto/#sql-queries-with-presto-client","title":"SQL Queries with Presto Client","text":"<p>In this section you will execute SQL Queries against Astra DB using Presto CLI Client.</p> <p>\u2705 7. Install Presto Client</p> <p>Follow the instructions to download and install a CLI Presto Client.</p> <p>\u2705 8. Start the CLI Presto Client:</p> <pre><code>./presto --server http://localhost:8080 --catalog cassandra\n</code></pre> <p>The <code>server</code> option specifies the HTTP(S) address and port of the Presto coordinator, and the <code>catalog</code> option sets the default catalog.</p> <p>\u2705 9. Execute the SQL query to find the total number of customers:</p> <pre><code>SELECT COUNT(*) AS customer_count\nFROM banking_db.customer;\n</code></pre> <p>Output:</p> <pre><code> customer_count\n----------------\n              2\n(1 row)\n</code></pre> <p>\u2705 10. Execute the SQL query to find emails of customers with account balances of <code>300.00</code> or higher:</p> <pre><code>SELECT DISTINCT email AS customer_email\nFROM banking_db.customer\nINNER JOIN banking_db.accounts_by_customer\nON (id = customer_id)\nWHERE account_balance &gt;= 300.00;\n</code></pre> <p>Output:</p> <pre><code> customer_email\n-----------------\n bob@example.org\n(1 row)\n</code></pre> <p>\u2705 11. Execute the SQL query to find customers and sums of their account balances:</p> <pre><code>SELECT id AS customer_id,\nname AS customer_name,\nemail AS customer_email,\nSUM ( CAST (\nCOALESCE(account_balance,0) AS DECIMAL(12,2)\n) ) AS customer_funds\nFROM banking_db.customer\nLEFT OUTER JOIN banking_db.accounts_by_customer\nON (id = customer_id)\nGROUP BY id, name, email;\n</code></pre> <p>Output:</p> <pre><code>             customer_id              | customer_name |  customer_email   | customer_funds\n--------------------------------------+---------------+-------------------+----------------\n 8d6c1271-16b6-479d-8ea9-546c37381ab3 | Alice         | alice@example.org | 300.03\n 0e5d9e8c-2e3b-4576-8515-58b491cb859e | Bob           | bob@example.org   | 700.07\n(2 rows)\n</code></pre>"},{"location":"pages/data/explore/tableau/","title":"Tableau","text":""},{"location":"pages/data/explore/tableau/#overview","title":"Overview","text":"<p>Tableau is a visual analytics platform for modern business intelligence. Tableau can be used to retrieve, explore, analyze and visualize data stored in Astra DB. The Tableau Platform features several products, inculding:</p> <ul> <li>Tableau Desktop,</li> <li>Tableau Prep,</li> <li>Tableau Cloud.</li> </ul> <p>In this tutorial, we show how to use Tableau Desktop to connect and query data in Astra DB. We use Simba JDBC Driver for Apache Cassandra\u00ae to connect Tableau Desktop and Astra DB .</p>"},{"location":"pages/data/explore/tableau/#prerequisites","title":"Prerequisites","text":"<ul> <li>Create an Astra Database</li> <li>Create an Astra Token</li> <li>Download Secure Connect Bundle</li> </ul>"},{"location":"pages/data/explore/tableau/#setup-astra-db","title":"Setup Astra DB","text":"<p>\u2705 1. Sign in</p> <p>Connect to your Astra account and create a new Astra database or select an existing one. Add a new keyspace with name <code>banking_db</code> or use an existing one.</p> <p>\u2705 2. Create the following tables using the CQL Console</p> <pre><code>USE banking_db;\n</code></pre> <pre><code>CREATE TABLE customer (\nid UUID,\nname TEXT,\nemail TEXT,\nPRIMARY KEY (id)\n);\nCREATE TABLE accounts_by_customer (\ncustomer_id UUID,\naccount_number TEXT,\naccount_type TEXT,\naccount_balance DECIMAL,\ncustomer_name TEXT STATIC,\nPRIMARY KEY ((customer_id), account_number)\n);\n</code></pre> <p>\u2705 3. Insert the rows using the CQL Console</p> <pre><code>INSERT INTO customer (id,name,email) VALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'Alice','alice@example.org');\nINSERT INTO customer (id,name,email) VALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'Bob','bob@example.org');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'A-101','Checking',100.01,'Alice');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'A-102','Savings',200.02,'Alice');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'B-101','Checking',300.03,'Bob');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'B-102','Savings',400.04,'Bob');\n</code></pre>"},{"location":"pages/data/explore/tableau/#setup-tableau-desktop","title":"Setup Tableau Desktop","text":"<p>\u2705 4. Install Tableau Desktop</p> <p>Use an existing deployment of Tableau Desktop or follow the instructions to download, install and register a new instance of Tableau Desktop.</p>"},{"location":"pages/data/explore/tableau/#install-simba-jdbc-driver-for-apache-cassandra","title":"Install Simba JDBC Driver for Apache Cassandra","text":"<p>\u2705 5. Download JDBC Driver</p> <p>Go to https://downloads.datastax.com/#odbc-jdbc-drivers and download the latest version of Simba JDBC Driver for Apache Cassandra.</p> <p>\u2705 6. Install JDBC Driver</p> <p>Extract the JDBC Driver <code>.zip</code> archive and move the resulting <code>.jar</code> file to:</p> <ul> <li><code>/Users/[user]/Library/Tableau/Drivers</code> on macOS</li> <li><code>C:\\Program Files\\Tableau\\Drivers</code> on Windows</li> </ul>"},{"location":"pages/data/explore/tableau/#connect-to-astra-db-from-tableau-desktop","title":"Connect to Astra DB from Tableau Desktop","text":"<p>\u2705 7. Restart Tableau Desktop</p> <p>Start or restart Tableau Desktop for the JDBC Driver installation to take effect.</p> <p>\u2705 8. Setup a connection to Astra DB</p> <ul> <li>Select Other Databases (JDBC) under Connect</li> <li>Fill out the dialog box with the connection information:<ul> <li>URL = <code>jdbc:cassandra://;AuthMech=2;UID=token;PWD=&lt;ApplicationToken&gt;;SecureConnectionBundlePath=&lt;SecureConnectBundle&gt;;TunableConsistency=1</code>, where<ul> <li>AuthMech specifies whether the driver connects to a Cassandra or Astra DB database, and whether the driver authenticates the connection. It should be set to <code>2</code> to connect to an Astra database, and authenticate the connection using a user name, password, and secure connection bundle.</li> <li>UID and PWD specify user name and password credentials. They should be set to literal <code>token</code> and the actual application token value. See how to generate an application token if you do not have one already.</li> <li>SecureConnectionBundlePath specifies the full path and name of the secure connection bundle associated with your Astra database. On Windows, the path should still be written using forward-slashes and not escape spaces in any particular way, as in: <code>c:/Users/Joan Reed/my-bundle.zip</code>. See how to download a secure connect bundle for your database.</li> <li>TunableConsistency specifies the consistency level for requests to the database. The supported values are <code>0</code> for <code>ANY</code>, <code>1</code> for <code>ONE</code>, <code>2</code> for <code>TWO</code>, <code>3</code> for <code>THREE</code>, <code>4</code> for <code>QUORUM</code>, <code>5</code> for <code>ALL</code>, <code>6</code> for <code>LOCAL_QUORUM</code>, <code>7</code> for <code>EACH_QUORUM</code>, and <code>10</code> for <code>LOCAL_ONE</code>. Set it to <code>6</code> for this example.</li> </ul> </li> <li>Dialect = <code>SQL92</code></li> <li>Username = <code>&lt;Client ID&gt;</code>, where a client id value is generated with your application token.</li> <li>Password = <code>&lt;Client Secret&gt;</code>, where a client secret is generated with your application token. </li> </ul> </li> <li>Click the Sign In button to establish a connection.</li> </ul> <p></p> <p>\u2705 9. Create a data source from the banking database</p> <ul> <li>Select <code>cassandra</code> under Database.</li> <li>Select <code>banking_db</code> under Schema.</li> <li>Drag and drop tables <code>customer</code> and <code>accounts_by_customer</code> into the main area and establish the relationship between the tables.</li> </ul> <p></p> <p>\u2705 10. Create a new sheet with simple visualization</p> <p>Add up all account balances per customer and visualize the results: </p> <ul> <li>Click Sheet 1 at the bottom left corner.</li> <li>Drag and drop Name to Columns.</li> <li>Drag and drop Account Balance to Rows.</li> <li>Customize coloring and formatting settings as needed. </li> </ul> <p></p>"},{"location":"pages/data/explore/tableplus/","title":"TablePlus","text":"<ul> <li>This article includes information that was originally written by Erick Ramirez on DataStax Community</li> </ul>"},{"location":"pages/data/explore/tableplus/#overview","title":"Overview","text":"<p>TablePlus is a modern, native tool with elegant UI that allows you to simultaneously manage multiple databases such as MySQL, PostgreSQL, SQLite, Microsoft SQL Server and more.</p> <ul> <li>\u2139\ufe0f Introduction to TablePlus</li> <li>\ud83d\udce5 TablePlus Download Link</li> </ul>"},{"location":"pages/data/explore/tableplus/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul> <p>This article assumes you have a running installation of Tableplus on your laptop or PC. It was written for the MacOS version but it should also work for the Windows version.</p>"},{"location":"pages/data/explore/tableplus/#installation-and-setup","title":"Installation and Setup","text":"<p>Note</p> <p>For simplicity, the secure connect bundle has been placed in <code>/path/to/scb</code></p>"},{"location":"pages/data/explore/tableplus/#step-1-db-information","title":"\u2705 Step 1: DB Information","text":"<p>On your laptop or PC where Tableplus is installed, unpack your secure bundle. For example:</p> <pre><code>$ cd /path/to/scb\n$ unzip secure-connect-getvaxxed.zip\n</code></pre> <p>Here is an example file listing after unpacking the bundle:</p> <pre><code>/\n  path/\n    to/\n      scb/\n        ca.crt\n        cert\n        cert.pfx\n        config.json\n        cqlshrc\n        identity.jks\n        key\n        trustStore.jks\n</code></pre> <p>Obtain information about your database from the config.json file. Here is an example:</p> <pre><code>{\n\"host\": \"&lt;YOUR_ENDPOINT&gt;.db.astra.datastax.com\",\n  \"port\": 98765,\n  \"cql_port\": 34567,\n  \"keyspace\": \"&lt;KEYSPACE_NAME&gt;\",\n  \"localDC\": \"us-west-2\",\n  \"caCertLocation\": \"./ca.crt\",\n  \"keyLocation\": \"./key\",\n  \"certLocation\": \"./cert\",\n  ...\n}\n</code></pre> <p>We will use this information to configure Astra DB as the data source in Tableplus.</p>"},{"location":"pages/data/explore/tableplus/#step-2-new-connection","title":"\u2705 Step 2: New Connection","text":"<ol> <li> <p>In Tableplus, create a new connection and select Cassandra as the target database.</p> </li> <li> <p>In the Host and Port fields, use the <code>host</code> and <code>cql_port</code> values in the <code>config.json</code> above.</p> </li> <li> <p>In the User and Password fields, use the client ID and client secret from the token you created in the Prerequisites section of this article.</p> </li> <li> <p>In the Keyspace field, use the <code>keyspace</code> values in the <code>config.json</code> above.</p> </li> <li> <p>Choose <code>SSL VERIFY NONE</code> for the SSL mode.</p> </li> <li> <p>For SSL keys, select the secure bundle files:</p> </li> </ol> <p>Secure Bundle Files</p> <ul> <li><code>key</code> for Private Key (leave the password blank when prompted)</li> <li><code>cert</code> for Cert</li> <li><code>ca.crt</code> for Trusted Cert</li> </ul> <p>Here's an example of what the Cassandra Connection dialog box should look like:</p> <p> </p>"},{"location":"pages/data/explore/tableplus/#step-3-final-test","title":"\u2705 Step 3: Final Test","text":"<p>Connect to your Astra DB. If the connection was successful, you should be able to see all the tables on the left-hand side of the UI.</p> <p>Here's an example output:</p> <p></p>"},{"location":"pages/data/explore/trino/","title":"Trino","text":""},{"location":"pages/data/explore/trino/#overview","title":"Overview","text":"<p>Trino is a distributed SQL query engine for big data analytics. Trino can query data from over 30 different data sources, including Cassandra, MongoDB, MySQL, PostgresSQL, and Redis. Common Trino use cases include:</p> <ul> <li>interactive data analytics,</li> <li>SQL-based analytics over object storage systems,</li> <li>data access and analytics across multiple data sources with query federation,</li> <li>batch ETL processing across disparate systems.</li> </ul> <p>In this tutorial, we show how to use Trino to explore and query data in Astra DB with SQL. The overall architecture of this solution is depicted below. Trino CLI Client sends SQL queries to Trino Server. Trino Server retrieves data from Astra DB via CQL Proxy, computes the query results and returns them to the client.</p> <p></p>"},{"location":"pages/data/explore/trino/#prerequisites","title":"Prerequisites","text":"<ul> <li>Create an Astra Database</li> <li>Create an Astra Token</li> </ul>"},{"location":"pages/data/explore/trino/#setup-astra-db","title":"Setup Astra DB","text":"<p>\u2705 1. Sign in</p> <p>Connect to your Astra account and create a new Astra database or select an existing one. Add a new keyspace with name <code>banking_db</code> or use an existing one.</p> <p>\u2705 2. Create the following tables using the CQL Console</p> <pre><code>USE banking_db;\n</code></pre> <pre><code>CREATE TABLE customer (\nid UUID,\nname TEXT,\nemail TEXT,\nPRIMARY KEY (id)\n);\nCREATE TABLE accounts_by_customer (\ncustomer_id UUID,\naccount_number TEXT,\naccount_type TEXT,\naccount_balance DECIMAL,\ncustomer_name TEXT STATIC,\nPRIMARY KEY ((customer_id), account_number)\n);\n</code></pre> <p>\u2705 3. Insert the rows using the CQL Console</p> <pre><code>INSERT INTO customer (id,name,email) VALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'Alice','alice@example.org');\nINSERT INTO customer (id,name,email) VALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'Bob','bob@example.org');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'A-101','Checking',100.01,'Alice');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (8d6c1271-16b6-479d-8ea9-546c37381ab3,'A-102','Savings',200.02,'Alice');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'B-101','Checking',300.03,'Bob');\nINSERT INTO accounts_by_customer (customer_id,account_number,account_type,account_balance,customer_name)\nVALUES (0e5d9e8c-2e3b-4576-8515-58b491cb859e,'B-102','Savings',400.04,'Bob');\n</code></pre>"},{"location":"pages/data/explore/trino/#deploy-cql-proxy","title":"Deploy CQL Proxy","text":"<p>\u2705 4. Installation</p> <p>Follow the instructions to deploy a CQL Proxy as close to a Trino Server as possible, preferrably deploying both components on the same server. The simplest way to start <code>cql-proxy</code> is to use an <code>&lt;astra-token&gt;</code> and <code>&lt;astra-database-id&gt;</code>:</p> <pre><code>./cql-proxy \\\n--astra-token &lt;astra-token&gt; \\\n--astra-database-id &lt;astra-database-id&gt;\n</code></pre> <p>An example command with a sample, invalid token and database id:</p> <pre><code>./cql-proxy \\\n--astra-token AstraCS:NoBhcuwCrIhZxqzjEMCSuGos:8a85142b47a588472a1f3b1314e2141f098785895411dee9db11f2a7ade457ce \\\n--astra-database-id e5e4e925-289a-8231-83fd-25918093257b\n</code></pre>"},{"location":"pages/data/explore/trino/#setup-trino-server","title":"Setup Trino Server","text":"<p>\u2705 5. Trino intallation</p> <p>Follow the instructions to download, install and configure a Trino Server or use an existing deployment. The minimal configuration requirements for a local single-machine deployment are:</p> <ul> <li>Node properties in file <code>etc/node.properties</code></li> </ul> <pre><code>node.environment=production\nnode.id=ffffffff-ffff-ffff-ffff-ffffffffffff\nnode.data-dir=/var/trino/data\n</code></pre> <ul> <li>JVM config in file <code>etc/jvm.config</code></li> </ul> <pre><code>-server\n-Xmx16G\n-XX:-UseBiasedLocking\n-XX:+UseG1GC\n-XX:G1HeapRegionSize=32M\n-XX:+ExplicitGCInvokesConcurrent\n-XX:+ExitOnOutOfMemoryError\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:-OmitStackTraceInFastThrow\n-XX:ReservedCodeCacheSize=512M\n-XX:PerMethodRecompilationCutoff=10000\n-XX:PerBytecodeRecompilationCutoff=10000\n-Djdk.attach.allowAttachSelf=true\n-Djdk.nio.maxCachedBufferSize=2000000\n</code></pre> <ul> <li>Config properties in file <code>etc/config.properties</code></li> </ul> <pre><code>coordinator=true\nnode-scheduler.include-coordinator=true\nhttp-server.http.port=8080\nquery.max-memory=5GB\nquery.max-memory-per-node=1GB\ndiscovery.uri=http://localhost:8080\n</code></pre> <ul> <li>Catalog properties in file <code>etc/catalog/cassandra.properties</code></li> </ul> <pre><code>connector.name=cassandra\ncassandra.contact-points=localhost\ncassandra.consistency-level=QUORUM\n</code></pre> <p>The above configuration uses the Cassandra connector to interact with <code>cql-proxy</code>.</p> <p>\u2705 6. Start the Trino Server:</p> <pre><code>bin/launcher run\n</code></pre> <p>Wait for message <code>======== SERVER STARTED ========</code> to confirm a successful start.</p>"},{"location":"pages/data/explore/trino/#sql-queries-with-trino-client","title":"SQL Queries with Trino Client","text":"<p>In this section you will execute SQL Queries against Astra DB using Trino CLI Client.</p> <p>\u2705 7. Install Trino Client</p> <p>Follow the instructions to download and install a CLI Trino Client.</p> <p>\u2705 8. Start the CLI Trino Client:</p> <pre><code>./trino --server http://localhost:8080 --catalog cassandra\n</code></pre> <p>The <code>server</code> option specifies the HTTP(S) address and port of the Trino coordinator, and the <code>catalog</code> option sets the default catalog.</p> <p>\u2705 9. Insert a new customer into table <code>customer</code>:</p> <pre><code>INSERT INTO banking_db.customer (id,name,email)\nVALUES (uuid(),'Luis','luis@example.org');\n</code></pre> <p>\u2705 10. Execute the SQL query to find the total number of customers:</p> <pre><code>SELECT COUNT(*) AS customer_count\nFROM banking_db.customer;\n</code></pre> <p>Output:</p> <pre><code> customer_count\n----------------\n              3\n(1 row)\n</code></pre> <p>\u2705 11. Execute the SQL query to find emails of customers with account balances of <code>300.00</code> or higher:</p> <pre><code>SELECT DISTINCT email AS customer_email\nFROM banking_db.customer\nINNER JOIN banking_db.accounts_by_customer\nON (id = customer_id)\nWHERE account_balance &gt;= 300.00;\n</code></pre> <p>Output:</p> <pre><code> customer_email\n-----------------\n bob@example.org\n(1 row)\n</code></pre> <p>\u2705 12. Execute the SQL query to find customers and sums of their account balances:</p> <pre><code>SELECT id AS customer_id,\nname AS customer_name,\nemail AS customer_email,\nSUM ( CAST (\nCOALESCE(account_balance,0) AS DECIMAL(12,2)\n) ) AS customer_funds\nFROM banking_db.customer\nLEFT OUTER JOIN banking_db.accounts_by_customer\nON (id = customer_id)\nGROUP BY id, name, email;\n</code></pre> <p>Output:</p> <pre><code>             customer_id              | customer_name |  customer_email   | customer_funds\n--------------------------------------+---------------+-------------------+----------------\n 0e5d9e8c-2e3b-4576-8515-58b491cb859e | Bob           | bob@example.org   |         700.07\n c628dca6-a8a6-4f37-ac29-44975af069fb | Luis          | luis@example.org  |           0.00\n 8d6c1271-16b6-479d-8ea9-546c37381ab3 | Alice         | alice@example.org |         300.03\n(3 rows)\n</code></pre>"},{"location":"pages/data/load/astra-data-loader/","title":"Astra Data Loader","text":"\ud83d\udcd6 Reference Documentations and Resources <ol> <li>\ud83d\udcd6  Data Loader - Astra Reference documentation <li>\ud83c\udfa5 Youtube Video - Walk through data loader usage </li> </li> </ol>"},{"location":"pages/data/load/astra-data-loader/#overview","title":"Overview","text":"<p>Astra DB conveniently has its own data loader built in to the user interface. Use this DataStax Astra DB Data Loader to load your own data into your database or try one of our sample datasets.</p>"},{"location":"pages/data/load/astra-data-loader/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> </ul>"},{"location":"pages/data/load/astra-data-loader/#procedure","title":"Procedure","text":""},{"location":"pages/data/load/astra-data-loader/#step-1-from-your-astra-db-dashboard-select-load-data-for-the-database-where-you-want-to-load-data","title":"\u2705 Step 1 : From your Astra DB Dashboard, select Load Data for the database where you want to load data.","text":"<p>The Astra DB Data Loader launches.</p> <p></p>"},{"location":"pages/data/load/astra-data-loader/#step-2-load-your-data-using-one-of-the-options","title":"\u2705 Step 2 : Load your data using one of the options:","text":""},{"location":"pages/data/load/astra-data-loader/#upload-your-dataset","title":"Upload your dataset","text":"<p>Drag and drop your own <code>.csv</code> file into the Astra DB Data Loader.</p> <p> <code>CSV</code> files must be less than <code>40 MB</code>. You will see a status bar to show how much data has uploaded. Ensure the column names in your .csv do not include spaces. Underscores are accepted. For example, <code>ShoeSize</code>, <code>ShirtColor</code>, <code>Shoe_Size</code>, and <code>Shirt_Color</code> are accepted column names.</p>"},{"location":"pages/data/load/astra-data-loader/#load-example-dataset","title":"Load example dataset","text":"<p>Select one of the two examples given to use as a sample dataset.</p>"},{"location":"pages/data/load/astra-data-loader/#load-dynamodb-from-s3","title":"Load DynamoDB from S3","text":"<ul> <li>First, export your DynamoDB data to S3 as described here. Then in AWS console, grant read access to the following ARN: <code>arn:aws:iam::445559476293:role/astra-loader</code> Your bucket policy should use:</li> </ul> <pre><code>{\n\"Statement\": [\n{\n\"Action\": [\"s3:ListBucket\", \"s3:GetBucketLocation\"],\n\"Principal\": { \"AWS\": \"arn:aws:iam::445559476293:role/astra-loader\" },\n\"Effect\": \"Allow\",\n\"Resource\": \"arn:aws:s3:::YOUR_BUCKET_NAME\"\n},\n{\n\"Effect\": \"Allow\",\n\"Principal\": { \"AWS\": \"arn:aws:iam::445559476293:role/astra-loader\" },\n\"Action\": [\"s3:GetObject\"],\n\"Resource\": \"arn:aws:s3:::YOUR_BUCKET_NAME/*\"\n}\n]\n}\n</code></pre> <p>This bucket policy allows Astra DB automation to pull data from your identified shared S3 bucket, and load the data into Astra DB. You can remove the permission after the data load finishes.</p> <p>In the Option 3 prompts, enter your S3 Bucket name, and enter the Key value. To find the Key, navigate in AWS console to the S3 subdirectory that contains your exported DynamoDB data. Look for the Key on its Properties tab. Here\u2019s a sample screen with the Key shown near the lower-left corner:</p> <p></p> <p>S3 Properties with Key value for exported DynamoDB data file. Once you configure your option, select Next.</p>"},{"location":"pages/data/load/astra-data-loader/#import-procedure","title":"Import Procedure","text":"<ul> <li>Give your table for this dataset a name. Your dataset will be included in the Data Preview and Types.</li> </ul> <ul> <li>Select the data type for each column.</li> </ul> <p> The Astra DB Data Loader automatically selects data types for your dataset. If needed, you can change this to your own selection.</p> <ul> <li>Select your partition key and clustering column for your data.</li> </ul> <p></p> <ul> <li> <p>Select Next.</p> </li> <li> <p>Select your database from the dropdown menu.</p> </li> <li> <p>Select your keyspace from the available keyspaces.</p> </li> </ul> <p></p> <ul> <li>Select Next.</li> </ul> <p>You will see a confirmation that your data is being imported. Within a few minutes, your dataset will begin uploading to your database.</p> <p>You will receive an email when the job has started and when the dataset has been loaded.</p>"},{"location":"pages/data/load/dsbulk/","title":"\u2023 DSBulk","text":"\ud83d\udcd6 Reference Documentations and resources <ol> <li>\ud83d\udcd6  DSBulks Docs - Reference documentation <li>\ud83d\udcd6  DataStax Docs - Reference Documentation"},{"location":"pages/data/load/dsbulk/#a-overview","title":"A - Overview","text":""},{"location":"pages/data/load/dsbulk/#what-is-dsbulk","title":"\ud83d\udcd8 What is DSBulk ?","text":"<p>The DataStax Bulk Loader tool (DSBulk) is a unified tool for loading into and unloading from Cassandra-compatible storage engines, such as OSS Apache Cassandra\u00ae, DataStax Astra and DataStax Enterprise (DSE).</p> <p>Out of the box, DSBulk provides the ability to:</p> <ul> <li>Load (import) large amounts of data into the database efficiently and reliably;</li> <li>Unload (export) large amounts of data from the database efficiently and reliably;</li> <li>Count elements in a database table: how many rows in total, how many rows per replica and per token range, and how many rows in the top N largest partitions.</li> </ul> <pre><code># Load data\ndsbulk load &lt;options&gt;\n\n# Unload data\ndsbulk unload &lt;options&gt;\n\n# Count rows\ndsbulk count &lt;options&gt;\n</code></pre> <p>Currently, CSV and Json formats are supported for both loading and unloading data.</p>"},{"location":"pages/data/load/dsbulk/#datastax-bulk-loader-with-astra","title":"\ud83d\udcd8 DataStax Bulk Loader with Astra","text":"<p>Use DataStax Bulk Loader <code>(dsbulk)</code> to load and unload data in CSV or JSON format with your DataStax Astra DB database efficiently and reliably.</p> <p>You can use <code>dsbulk</code> as a standalone tool to remotely connect to a cluster. The tool is not required to run locally on an instances, but can be used in this configuration.</p>"},{"location":"pages/data/load/dsbulk/#b-prerequisites","title":"B - Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul> <p>This article was written for DataStax Bulk Loader version <code>1.9.1</code>.</p> <p>Starting with version <code>1.9</code>, <code>dsbulk</code> can detect and respect server-side rate limiting. This is very useful when working with Astra DB, which by default has some throughput guardrails in place.</p>"},{"location":"pages/data/load/dsbulk/#c-installation","title":"C - Installation","text":"<p>\u2705 Step 1 : Download the archive and unzip locally</p> <pre><code>curl -OL https://downloads.datastax.com/dsbulk/dsbulk-1.9.1.tar.gz \\\n&amp;&amp; tar xvzf dsbulk-1.9.1.tar.gz \\\n&amp;&amp; rm -f dsbulk-1.9.1.tar.gz\n</code></pre> <p>it will take a few seconds (file is about 30M)...</p> <pre><code>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n 49 30.0M   49 14.8M    0     0   343k      0  0:01:29  0:00:44  0:00:45  244k\n</code></pre>"},{"location":"pages/data/load/dsbulk/#d-usage","title":"D - Usage","text":""},{"location":"pages/data/load/dsbulk/#load-data","title":"\ud83d\udcd8 Load Data","text":"<ul> <li>Given a table</li> </ul> <pre><code>CREATE TABLE better_reads.book_by_id (\nid text PRIMARY KEY,\nauthor_id list&lt;text&gt;,\nauthor_names list&lt;text&gt;,\nbook_description text,\nbook_name text,\ncover_ids list&lt;text&gt;,\npublished_date date\n)\n</code></pre> <ul> <li>A sample CSV could be:</li> </ul> <pre><code>id|author_id|author_names|book_description|book_name|cover_ids|published_date\n1234|[\"id1\",\"id2\",\"id3\"]|[\"name1\",\"name2\",\"name3\"]|this is a dsecription|Book name|[\"cover1\",\"cover2\"]|2022-02-02\n</code></pre> <ul> <li>Loaded with the following command:</li> </ul> <pre><code>dsbulk load \\\n-url book_by_id.csv \\\n-c csv \\\n-delim '|' \\\n-k better_reads \\\n-t book_by_id \\\n--schema.allowMissingFields true \\\n-u clientId \\\n-p clientSecret \\\n-b secureBundle.zip\n</code></pre>"},{"location":"pages/data/load/dsbulk/#export-data","title":"\ud83d\udcd8 Export Data","text":"<ul> <li>Unloaded the same table with the following command:</li> </ul> <pre><code>dsbulk unload \\\n-k better_reads \\\n-t book_by_id \\\n-c csv \\\n-u clientId \\\n-p clientSecret \\\n-b secureBundle.zip \\\n&gt; book_by_id_export.csv\n</code></pre>"},{"location":"pages/data/load/dsbulk/#count-table-records","title":"\ud83d\udcd8 Count Table Records","text":"<ul> <li>Counted the rows in the table with the following command:</li> </ul> <pre><code>dsbulk count \\\n-k better_reads \\\n-t book_by_id \\\n-u clientId \\\n-p clientSecret \\\n-b secureBundle.zip\n</code></pre> <ul> <li>Produces the following output:</li> </ul> <pre><code>Operation directory: /local/dsbulk-1.9.1/logs/COUNT_20220223-213637-046128\n  total | failed | rows/s |  p50ms |  p99ms | p999ms\n143,475 |      0 | 87,509 | 155.34 | 511.71 | 511.71\nOperation COUNT_20220223-213637-046128 completed successfully in 1 second.\n143475\n</code></pre>"},{"location":"pages/data/load/nosqlbench/","title":"NoSQLBench","text":""},{"location":"pages/data/load/nosqlbench/#overview","title":"Overview","text":"<ul> <li>\u2139\ufe0f NoSQLBench documentation</li> <li>\u2139\ufe0f Astra Docs on NoSQLBench</li> </ul>"},{"location":"pages/data/load/nosqlbench/#what-is-nosqlbench","title":"What is NoSQLBench ?","text":"<p>NoSQLBench is a powerful, state-of-the-art tool for emulating real application workloads and direct them to actual target data stores for reliable, reproducible benchmarking.</p> <p>NoSQLBench is extremely customizable, yet comes with many pre-defined workloads, ready for several types of distributed, NoSQL data systems. One of the target databases is Cassandra/Astra DB, supported out-of-the-box by NoSQLBench and complemented by some ready-made realistic workloads for benchmarking.</p> <p>At the heart of NoSQLBench are a few principles:</p> <ul> <li>ease-of-use, meaning that one can start using it without learning all layers of customizability;</li> <li>modularity in the design: building a new driver is comparatively easy;</li> <li>workloads are reproducible down to the individual statement (no \"actual randomness\" involved);</li> <li>reliable performance timing, i.e. care is taken on the client side to avoid unexpected JVM pauses.</li> </ul>"},{"location":"pages/data/load/nosqlbench/#nosqlbench-and-astra-db","title":"NoSQLBench and Astra DB","text":"<p>NoSQLBench uses the (CQL-based) Cassandra Java Drivers, which means that it supports Astra DB natively with its drivers. The only care is in providing access to an Astra DB instance, which is done via command-line parameters.</p> <p>The only care is that, while running a benchmark against a generic Cassandra installation usually entails creation of a keyspace if it does not exist, when benchmarking Astra DB you should make sure the keyspace exists already (the keyspace name can be passed as a command-line parameter when launching NoSQLBench).</p>"},{"location":"pages/data/load/nosqlbench/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul>"},{"location":"pages/data/load/nosqlbench/#installation","title":"Installation","text":"<p>The following installation instructions are taken from the official NoSQLBench documentation. Please refer to it for more details and updates.</p>"},{"location":"pages/data/load/nosqlbench/#step-1-download-the-binaries","title":"Step 1 : Download the binaries","text":"<p>Go to the releases page and download the latest version. The suggested option is to download the Linux binary (<code>nb</code>), but as an alternative the <code>nb.jar</code> version can also be used: here we assume the Linux binary is used, please see the NoSQLBench documentation for more on using the JAR.</p>"},{"location":"pages/data/load/nosqlbench/#step-2-make-executable-and-put-in-search-path","title":"Step 2 : Make executable and put in search path","text":"<p>Once the file is downloaded, make it executable with <code>chmod +x nb</code> and put it (or make a symlink) somewhere in your system's search path, such as <code>/home/${USER}/.local/bin/</code>.</p> <p>As a quick test, try the command <code>nb --version</code>.</p>"},{"location":"pages/data/load/nosqlbench/#usage","title":"Usage","text":""},{"location":"pages/data/load/nosqlbench/#command","title":"Command","text":"<p>If you already use NoSQLBench... then all you need to know is that invocations should include the following parameters to locate an Astra DB instance and authenticate to it:</p> <pre><code>nb \\\n[...]                                              \\\nusername=CLIENT_ID                                 \\\npassword=CLIENT_SECRET                             \\\nsecureconnectbundle=/PATH/TO/SECURE-CONNECT-DB.zip \\\nkeyspace=KEYSPACE_NAME                             \\\n[...]\n</code></pre> <p>In the above, you should pass your Client ID and Client Secret as found in the Astra DB Token, and the path to the Secure Bundle zipfile you obtained earlier (see Prerequisites). Please prepend <code>./</code> to the bundle path if it is a relative path.</p> <p>You may want to specify a keyspace, as seen in the sample command quoted here, because, as Astra DB does not support the <code>CREATE KEYSPACE</code> CQL command, it would be your responsibility to match the keyspace used in the benchmark with the name of an existing one. Please inspect the contents of your workload <code>yaml</code> file more closely for more details on the keyspace name used by default.</p>"},{"location":"pages/data/load/nosqlbench/#quick-start","title":"Quick-start","text":"<p>There is a comprehensive Getting Started page on NoSQLBench documentation, so here only a couple of sample full commands will be given. Please consult the full documentation for more options and configurations.</p> <p>Some of the ready-made workloads included with NoSQLBench are specific for benchmarking realistic usage patterns of Cassandra/Astra DB. A quick way to get started is to launch those workloads with the \"workload scenario\" syntax (where the 'scenario' specifies that you are targeting an Astra DB instance).</p> <p>\"cql-keyvalue\" workload</p> <p>The following will run the \"cql-keyvalue\" workload, specifically its \"astra\" scenario, on an Astra DB instance:</p> <pre><code>nb cql-keyvalue astra                                \\\nusername=CLIENT_ID                                 \\\npassword=CLIENT_SECRET                             \\\nsecureconnectbundle=/PATH/TO/SECURE-CONNECT-DB.zip \\\nkeyspace=KEYSPACE_NAME\n</code></pre> <p>Alternatively, if you are using the <code>jar</code> version of the tool,</p> <pre><code>java -jar nb.jar cql-keyvalue astra                  \\\nusername=CLIENT_ID                                 \\\npassword=CLIENT_SECRET                             \\\nsecureconnectbundle=/PATH/TO/SECURE-CONNECT-DB.zip \\\nkeyspace=KEYSPACE_NAME\n</code></pre> <p>This workload emulates usage of Astra DB/Cassandra as a simple key-value store, and does so by alternating \"random\" reads and writes to a single table. A preliminar \"rampup\" phase is run, consisting only of writes, and then the \"main\" phase takes place (this structure is a rather universal features of these benchmarks).</p> <p>(Note: most likely you may want to add further options, such as <code>cyclerate</code>, <code>rampup-cycles</code>, <code>main-cycles</code> or <code>--progress console</code>. See the NoSQLBench docs and inspect the workload <code>yaml</code> for more).</p> <p>The above command, as things progress, will produce an output similar to:</p> <pre><code>cqlkeyvalue_astra_schema: 100.00%/Stopped (details: min=0 cycle=1 max=1) (last report)\ncqlkeyvalue_astra_rampup: 15.60%/Running (details: min=0 cycle=234 max=1500)\ncqlkeyvalue_astra_rampup: 32.40%/Running (details: min=0 cycle=486 max=1500)\n[...]\ncqlkeyvalue_astra_main: 96.67%/Running (details: min=0 cycle=1450 max=1500)\ncqlkeyvalue_astra_main: 100.00%/Running (details: min=0 cycle=1500 max=1500) (last report)\n</code></pre> <p>followed by a final summary - reflected also in files in the <code>logs/</code> directory, similar to:</p> <pre><code>-- Gauges ----------------------------------------------------------------------\ncqlkeyvalue_astra_main.cycles.config.burstrate\n             value = 55.00000000000001\n\n[...]\n\ncqlkeyvalue_astra_schema.tokenfiller\n             count = 57086\n         mean rate = 941.29 calls/second\n     1-minute rate = 940.67 calls/second\n     5-minute rate = 939.91 calls/second\n    15-minute rate = 939.71 calls/second\n</code></pre> <p>You may want to check that at this point a new table has been created, if it did not exist yet, in the keyspace.</p> <p>\"cql-iot\" workload</p> <p>Similar to the above for the \"cql-iot\" workload, aimed at emulating time-series-based reads and writes for a hypothetical IoT system:</p> <pre><code>nb cql-iot astra                                     \\\nusername=CLIENT_ID                                 \\\npassword=CLIENT_SECRET                             \\\nsecureconnectbundle=/PATH/TO/SECURE-CONNECT-DB.zip \\\nkeyspace=KEYSPACE_NAME\n</code></pre> <p>Other workloads</p> <p>You can inspect all available workloads with:</p> <pre><code>nb --list-scenarios\n</code></pre> <p>and look for <code>astra</code> in the output example scenario invocations there.</p> <p>Moreover, you can design your own workload.</p>"},{"location":"pages/develop/","title":"List","text":"<p>Dear Developers, so you have a running database ... now what ? In this page we provide you with the minimum amount of code needed to use Astra with the language or framework of your choice.</p>"},{"location":"pages/develop/#pick-an-api","title":"\ud83d\udee0\ufe0f Pick an API","text":"<p>Astra offers different Apis and interfaces. The choice of one against another will be driven by your use cases.</p> <p> </p>"},{"location":"pages/develop/#pick-a-language","title":"\ud83d\udee0\ufe0f Pick a language","text":"<p>Click the tile and learn how to interact with each language-specific interface exposed in Astra.</p> <p> </p> <p> </p>"},{"location":"pages/develop/#pick-a-framework","title":"\ud83d\udee0\ufe0f Pick a framework","text":""},{"location":"pages/develop/api/document/","title":"\u2022 Document","text":""},{"location":"pages/develop/api/document/#1-overview","title":"1. Overview","text":"<p>The Document API is an HTTP REST API and part of the open source Stargate.io. The idea is to provide an abstraction on top of Apache Cassandra\u2122 to allow document-oriented access patterns.</p> <p></p> <ul> <li> <p>A <code>namespace</code> (replacement for keyspace) will hold multiple <code>collections</code> (not tables) to store <code>Documents</code></p> </li> <li> <p>You interact with the database through <code>JSON documents</code> and no validation (sometimes called <code>_schemaless_</code> but a better term would be validationless).</p> </li> <li> <p>Each documents has a unique identifier within the collection. Each insert is an upsert.</p> </li> <li> <p>You can query on any field (thanks to out of the box support for the secondary index <code>SAI</code>)</p> </li> </ul> <pre><code>  graph LR\n    DB(Database) --&gt;|1...n|NS(Namespaces)\n    NS --&gt;|1..n|COL(Collections)\n    COL --&gt;|1..n|DOC(Documents)\n    DOC --&gt;|1..49 Nested docs|DOC</code></pre> How is the data stored in Cassandra? <p>The JSON documents are stored using an internal data model. The table schema is generic as is each collection. The algorithm used to transform the document is called document shredding. The schema is optimized for searches but also to limit tombstones on edits and deletes.</p> <pre><code>create table &lt;collection_name&gt; (\nkey       text,\np0        text,\n...\np[N]       text,\nbool_value boolean,\ntxt_value  text,\ndbl_value  double,\nleaf       text\n)\n</code></pre> <p>A JSON like <code>{\"a\": { \"b\": 1 }, \"c\": 2}</code> will be stored like</p> key p0 p1 dbl*value {docid} <code>a</code> <code>b</code> <code>1</code> {docid} <code>c</code> _null* <code>2</code> <p>This also works with arrays <code>{\"a\": { \"b\": 1 }, \"c\": [{\"d\": 2}]}</code></p> key p0 p1 p2 dbl_value {docid} <code>a</code> <code>b</code> null <code>1</code> {docid} <code>c</code> <code>[0]</code> <code>d</code> <code>2</code> <p>Known Limitations</p> <ul> <li> <p>As of today there is no aggregation or sorting available in the Document Api.</p> </li> <li> <p>Queries are paged with a pagesize of <code>3</code> records by default and you can increase up to a maximum of <code>20</code> records. Otherwise, the payload would be too large.</p> </li> </ul>"},{"location":"pages/develop/api/document/#2-prerequesites","title":"2. Prerequesites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul>"},{"location":"pages/develop/api/document/#3-browse-api-with-swagger","title":"3. Browse Api with Swagger","text":""},{"location":"pages/develop/api/document/#31-provide-database-details","title":"3.1 Provide Database Details","text":"Astra DB Setup  \u00a0Authentication token\u00a0*  \u00a0Database identifier\u00a0* (Where find it ?)  \u00a0Database Region\u00a0* (Where find it ?) Pick your region (GCP) asia-south1 (GCP) europe-west1 (GCP) europe-west2  (GCP) northamerica-northeast1 (GCP) southamerica-east1 (GCP) us-central1 (GCP) us-east1 (GCP) us-east4 (GCP) us-west1 (AWS) ap-southeast-1 (AWS) eu-central-1 (AWS) eu-west-1 (AWS) us-east-1 (AWS) us-east-2 (AWS) us-west-2 (Azure) northeurope (Azure) westeurope (Azure) eastus (Azure) eastus2 (Azure) southcentralus (Azure) westus2 (Azure) canadacentral (Azure) brazilsouth (Azure) centralindia (Azure) australiaeast"},{"location":"pages/develop/api/document/#32-use-swagger","title":"3.2 Use Swagger","text":"<p>The swagger client below will have fields pre-populated with your database details.</p>"},{"location":"pages/develop/api/document/#4-browse-api-with-postman","title":"4. Browse Api with Postman","text":""},{"location":"pages/develop/api/document/#41-installation","title":"4.1 Installation","text":"<ul> <li> <p>Install Postman to import the sample collections that we have provided.</p> </li> <li> <p>You can also import the collection in Hoppscotch.io not to install anything.</p> </li> </ul> <p> \u00a0Postman Collection </p>"},{"location":"pages/develop/api/document/#42-postman-setup","title":"4.2 Postman Setup","text":"<ul> <li>Import the configuration File <code>Astra_Document_Api_Configuration.json</code> in postman. In the menu locate <code>File &gt; Import</code> and drag the file in the box.</li> </ul> <p> \u00a0Postman Configuration </p> <p></p> <ul> <li>Edit the values for your db:</li> </ul> Parameter Name parameter value Description token <code>AstraCS:....</code> When you generate a new token it is the third field. Make sure you add enough privileges to use the APis, Database Administrator is a good choice to develop db <code>00000000-0000-0000-0000-00000000000</code> Unique identifier of your DB, you find on the main dashboard region <code>us-east1</code> region name, you find on the datanase dashboard namespace <code>demo</code> Namespaces are the same as keyspaces. They are created with the database or added from the database dashboard: How to create a keyspace] collection <code>person</code> Collection name (like table) to store one type of documents. <ul> <li>this is what it is looks like</li> </ul> <p></p> <ul> <li>Import the Document Api Collection <code>Astra_Document_Api.json</code> in postman. Same as before <code>File &gt; Menu</code></li> </ul> <p></p> <ul> <li>That's it! You have now access to a few dozens operations for <code>namespace</code>, <code>collections</code> and <code>documents</code></li> </ul> <p></p>"},{"location":"pages/develop/api/document/#43-working-with-the-postman-workspace","title":"4.3 Working with the Postman Workspace","text":"<p>Alternatively, you can access the collections for Document API in the Postman workspace below.</p> <p></p>"},{"location":"pages/develop/api/document/#5-api-sandbox-with-curl","title":"5. Api Sandbox with Curl","text":"<p>Provide the parameters asked at the beginning and see a first set of commands in action.</p>"},{"location":"pages/develop/api/document/#6-extra-resources","title":"6. Extra Resources","text":"<p>Reference Documentation</p> <p><ol> <li>Document API reference Blogpost <li>Design Improvements in 2021 <li>QuickStart"},{"location":"pages/develop/api/graphql/","title":"\u2022 graphQL","text":""},{"location":"pages/develop/api/graphql/#overview","title":"Overview","text":"<p>GraphQL is a query language for APIs and a runtime for fulfilling those queries with existing data. Stargate.io provides a graphQL interface which allows you to easily modify and query your table data using GraphQL types, mutations, and queries.</p> <p>Stargate GraphQL API supports two modes of interaction:</p> <ul> <li> <p>schema-first which allows you to create idiomatic GraphQL types, mutations, and queries in a manner familiar to GraphQL developers. The schema is deployed and can be updated by deploying a new schema without recreating the tables and columns directly.</p> </li> <li> <p>cql-first which translates CQL tables into GraphQL types, mutations, and queries. The GraphQL schema is automatically generated from the keyspace, tables, and columns defined, but no customization is allowed.</p> </li> </ul>"},{"location":"pages/develop/api/graphql/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul>"},{"location":"pages/develop/api/graphql/#exploring-the-graphql-api-with-the-graphql-playground","title":"Exploring the GraphQL API with the GraphQL playground","text":"<p>A simple way to get started with GraphQL is to use the built-in GraphQL playground. The playground allows you to create new schema and interact with the GraphQL APIs. The server paths are structured to provide access to creating and querying your schemas, as well as querying and modifying your data. </p> <p>\u2705 Open the GraphQL Playground</p> <p>Open the playground from the Connect tab in the APIs section.</p> <p></p> <p>Remember to add your token to the HTTP HEADERS at the bottom of the screen.</p> <p></p> <p>\u2705 Creating a keyspace :</p> <p>Before you can start using the GraphQL API, you must first create a keyspace and at least one table in your database. If you are connecting to a database with an existing schema, you can skip this step.</p> <p>For this example, we will use a keyspace called <code>library</code>:</p> <p></p> <p>\u2705 Creating a Table :</p> <p>There are three Stargate GraphQL API endpoints, one for creating schema in cql-first, one for deploying a schema in the schema-first, and the third for querying or mutating a keyspace.</p> <p>Schema</p> <p> <code>https://$ASTRA_CLUSTER_ID-$ASTRA_REGION.apps.astra.datastax.com:8080/api/graphql-schema</code></p> <p>Admin</p> <p> <code>https://$ASTRA_CLUSTER_ID-$ASTRA_REGION.apps.astra.datastax.com:8080/api/graphql-admin</code></p> <p>Querying</p> <p> <code>https://$ASTRA_CLUSTER_ID-$ASTRA_REGION.apps.astra.datastax.com:8080/api/graphql/{keyspace}</code></p> <ul> <li>In the <code>graphql-schema</code> endpoint, use this query to create a new table</li> </ul> <pre><code>mutation {\n  books: createTable(\n    keyspaceName:\"library\",\n    tableName:\"books\",\n    partitionKeys: [ # The keys required to access your data\n      { name: \"title\", type: {basic: TEXT} }\n    ]\n    values: [ # The values associated with the keys\n      { name: \"author\", type: {basic: TEXT} }\n    ]\n  )\n  authors: createTable(\n    keyspaceName:\"library\",\n    tableName:\"authors\",\n    partitionKeys: [\n      { name: \"name\", type: {basic: TEXT} }\n    ]\n    clusteringKeys: [ # Secondary key used to access values within the partition\n      { name: \"title\", type: {basic: TEXT}, order: \"ASC\" }\n    ]\n  )\n}\n</code></pre> <p>You should see the following confirmation once the command executes.</p> <p></p> <p>\u2705 Inserting Data :</p> <p>Any of the created APIs can be used to interact with the GraphQL data, to write or read data.</p> <p>First, let\u2019s navigate to your new keyspace <code>library</code> inside the playground. Switch to <code>graphql</code> tab and pick the url <code>/graphql/library</code>.</p> <ul> <li>Use this query</li> </ul> <pre><code>mutation insert2Books {\n  moby: insertbooks(value: {title:\"Moby Dick\", author:\"Herman Melville\"}) {\n    value {\n      title\n    }\n  }\n  catch22: insertbooks(value: {title:\"Catch-22\", author:\"Joseph Heller\"}) {\n    value {\n      title\n    }\n  }\n}\n</code></pre> <ul> <li>Don't forget to update the header again with your token details</li> </ul> <pre><code>{\n  \"x-cassandra-token\":\"your token\"\n}\n</code></pre> <ul> <li>You should see that two books have been added to the table.</li> </ul> <p></p> <p>\u2705 Querying Data :</p> <p>To query the data, switch to the <code>graphql/library</code> endpoint and execute the following</p> <pre><code>query oneBook {\n    books (value: {title:\"Moby Dick\"}) {\n      values {\n        title\n        author\n      }\n    }\n}\n</code></pre> <p>The query results will look like the following </p> <p></p>"},{"location":"pages/develop/api/graphql/#using-postman-with-graphql","title":"Using Postman with GraphQL","text":"<p>Postman is a widely-used collaboration platform for API development and testing. Using this third-party tool, you can easily test APIs with environments generated for your test platforms and imported testing collections of API queries.</p> <p>A Postman collection is available for Astra using the GraphQL API. </p> <p></p>"},{"location":"pages/develop/api/graphql/#extra-resources","title":"Extra Resources","text":"<ul> <li>Developing with GraphQL</li> <li>Introduction to GraphQL Workshop</li> </ul>"},{"location":"pages/develop/api/grpc/","title":"\u2022 gRPC","text":""},{"location":"pages/develop/api/grpc/#1-what-is-grpc","title":"1. What is gRPC ?","text":""},{"location":"pages/develop/api/grpc/#11-overview","title":"1.1 Overview","text":"<p>gRPC is a modern open source high performance Remote Procedure Call (RPC) framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services.</p> <p>One of the primary benefits of using gRPC is for documentation; you can use your service configuration and API interface definition files to generate reference documentation for your API.</p>"},{"location":"pages/develop/api/grpc/#12-what-you-need-to-know","title":"1.2 What you need to know","text":"<ul> <li> <p>gRPC underlying protocol is HTTP/2. It always blocking, asynchronous and reactive communications.</p> </li> <li> <p>Payloads are serialized in binary format call protocol buffers.</p> </li> <li> <p>Associated with protocol buffers the interfaces are define with <code>.proto</code> definitions files. From those definitions both server and clients are generated (stubbs).</p> </li> </ul> <p>Apache Cassandra is a NoSQL Distributed database built for performance. This fits very well use cases where this technology shines : when the performance requirements are demanding.</p>"},{"location":"pages/develop/api/grpc/#2-how-is-it-exposed-in-astra","title":"2. How is it exposed in Astra ?","text":"<p>The stargate team considers that gRPC could become the future of drivers for Apache Cassandra as describe in the following blogpost.</p> <p>As a consequence a grpc API layer is available within Stargate. Stargate is deployed within Astra and this is how Astra can provides a gRPC Api.</p> <p></p>"},{"location":"pages/develop/api/grpc/#3-getting-started","title":"3. Getting Started","text":""},{"location":"pages/develop/api/grpc/#31-prerequisites","title":"3.1 Prerequisites","text":"<ul> <li>Create an Astra Database</li> <li>Create an Astra Token</li> </ul>"},{"location":"pages/develop/api/grpc/#32-implementation","title":"3.2 Implementation","text":"<ul> <li> <p>Download to the <code>.proto</code> files. For Stargate they can be found here</p> </li> <li> <p>Generate stubs base on the proto files. In the case of Stargate gRPC apis datastax has  generated those stubs for a couple of languages already</p> <ul> <li>Java grpcClient</li> <li>Rust grpcClient</li> <li>Go grpcClient</li> <li>Node grpcClient</li> </ul> </li> <li> <p>To use those a complete documentation can be found on Stargate.io.</p> </li> <li> <p>A SDK has been implemented on top of those client to propose fluent Apis. Here are the different links</p> <ul> <li>Java SDK</li> <li>Python SDK</li> <li>JavaScript SDK</li> <li>Go SDK</li> </ul> </li> </ul>"},{"location":"pages/develop/api/grpc/#33-sample-codes","title":"3.3 Sample codes","text":"<p>To illustrate the usage of the grpc againt astra with and without the SDK look at the following code</p>"},{"location":"pages/develop/api/grpc/#code-with-grpc-client","title":"Code with gRPC client","text":"<pre><code>// Initialize Astra Client with token and database identifiers\ntry(AstraClient astraClient = AstraClient.builder()\n.withDatabaseId(ASTRA_DB_ID)\n.withDatabaseRegion(ASTRA_DB_REGION)\n.withToken(ASTRA_DB_TOKEN)\n.enableGrpc()\n.build()) {\n// Accessin the gRPC API\nApiGrpcClient cloudNativeClient = astraClient.apiStargateGrpc();\n// Reuse cql query\nString cqlQuery = \"SELECT data_center from system.local\";\n// Executing Query\nResultSetGrpc rs = cloudNativeClient.execute(cqlQuery);\n// Accessing reulst\nString datacenterName = rs.one().getString(\"data_center\");\nSystem.out.println(\"You are connected to '%s'\".formatted(datacenterName));\n// Validating the test\nAssertions.assertNotNull(datacenterName);\n}\n</code></pre>"},{"location":"pages/develop/api/grpc/#code-with-grpc-sdk","title":"Code with gRPC SDK","text":"<pre><code>// Open Grpc communicatino \nManagedChannel channel = ManagedChannelBuilder\n.forAddress(ASTRA_DB_ID + \"-\" + ASTRA_DB_REGION + \".apps.astra.datastax.com\", 443)\n.useTransportSecurity()\n.build();\n// use Grpc Stub generated from .proto as a client\nStargateGrpc.StargateBlockingStub cloudNativeClient = StargateGrpc\n.newBlockingStub(channel)\n.withCallCredentials(new StargateBearerToken(ASTRA_DB_TOKEN))\n.withDeadlineAfter(5, TimeUnit.SECONDS);\n// create Query\nString cqlQuery = \"SELECT data_center from system.local\";\n// Execute the Query\nResponse res = cloudNativeClient.executeQuery(QueryOuterClass\n.Query.newBuilder().setCql(cqlQuery).build());\n// Accessing Row result\nQueryOuterClass.Row row = res.getResultSet().getRowsList().get(0);\n// Access the single value\nString datacenterName = row.getValues(0).getString();\nSystem.out.println(\"You are connected to '%s'\".formatted(datacenterName));\n// Validating the test\nAssertions.assertNotNull(datacenterName);\n</code></pre>"},{"location":"pages/develop/api/rest/","title":"\u2022 REST","text":""},{"location":"pages/develop/api/rest/#overview","title":"Overview","text":"<p>Stargate is a data gateway (Proxy) on top of Apache Cassandra which exposes new interfaces to simplify integration in your applications. It is a way to create stateless components and ease the integration through one of four different HTTP Apis (rest, doc, graphQL, gRPC). In this chapter we will cover integration with <code>REST Apis</code> also called <code>DATA</code> in the swagger specifications.</p> <p>To know more regarding this interface specially you can have a look to dedicated section of the wiki or reference Stargate Rest Api Quick Start Guide.</p> <p>\u26a0\ufe0f We recommend using version <code>V2</code> (with V2 in the URL) as it covers more features and V1 will be deprecated eventually.</p>"},{"location":"pages/develop/api/rest/#design","title":"Design","text":""},{"location":"pages/develop/api/rest/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul>"},{"location":"pages/develop/api/rest/#operations","title":"Operations","text":"<ul> <li>List keyspaces</li> </ul> <pre><code>private static void listKeyspaces(CloseableHttpClient httpClient, String apiRestEndpoint)\nthrows Exception {\n// Build Request\nHttpGet listKeyspacesReq = new HttpGet(apiRestEndpoint + \"/v2/schemas/keyspaces\");\nlistKeyspacesReq.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(listKeyspacesReq)) {\nif (200 == res.getCode()) {\nlogger.info(\"[OK] Keyspaces list retrieved\");\nlogger.info(\"Returned message: {}\", EntityUtils.toString(res.getEntity()));\n}\n}\n}\n</code></pre> <ul> <li>Create a Table</li> </ul> <p>Query used is <code>createTableJson</code> here:</p> <pre><code>{\n\"name\": \"users\",\n\"columnDefinitions\": [\n{\n\"name\": \"firstname\",\n\"typeDefinition\": \"text\"\n},\n{\n\"name\": \"lastname\",\n\"typeDefinition\": \"text\"\n},\n{\n\"name\": \"email\",\n\"typeDefinition\": \"text\"\n},\n{\n\"name\": \"color\",\n\"typeDefinition\": \"text\"\n}\n],\n\"primaryKey\": {\n\"partitionKey\": [\"firstname\"],\n\"clusteringKey\": [\"lastname\"]\n},\n\"tableOptions\": {\n\"defaultTimeToLive\": 0,\n\"clusteringExpression\": [{ \"column\": \"lastname\", \"order\": \"ASC\" }]\n}\n}\n</code></pre> <p>Create Table code</p> <pre><code>private static void createTable(CloseableHttpClient httpClient, String apiRestEndpoint)\nthrows Exception {\nHttpPost createTableReq = new HttpPost(apiRestEndpoint\n+ \"/v2/schemas/keyspaces/\" + ASTRA_DB_KEYSPACE + \"/tables\");\ncreateTableReq.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\nString createTableJson = \"{...JSON.....}\";\ncreateTableReq.setEntity(new StringEntity(createTableJson, ContentType.APPLICATION_JSON));\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(createTableReq)) {\nif (201 == res.getCode()) {\nlogger.info(\"[OK] Table Created (if needed)\");\nlogger.info(\"Returned message: {}\", EntityUtils.toString(res.getEntity()));\n}\n}\n}\n</code></pre> <ul> <li>Insert a Row</li> </ul> <p></p> <pre><code>private static void insertRow(CloseableHttpClient httpClient, String apiRestEndpoint)\nthrows Exception {\nHttpPost insertCedrick = new HttpPost(apiRestEndpoint + \"/v2/keyspaces/\"\n+ ASTRA_DB_KEYSPACE + \"/users\" );\ninsertCedrick.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\ninsertCedrick.setEntity(new StringEntity(\"{\"\n+ \" \\\"firstname\\\": \\\"Cedrick\\\",\"\n+ \" \\\"lastname\\\" : \\\"Lunven\\\",\"\n+ \" \\\"email\\\"    : \\\"c.lunven@gmail.com\\\",\"\n+ \" \\\"color\\\"    : \\\"blue\\\" }\", ContentType.APPLICATION_JSON));\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(insertCedrick)) {\nif (201 == res.getCode()) {\nlogger.info(\"[OK] Row inserted\");\nlogger.info(\"Returned message: {}\", EntityUtils.toString(res.getEntity()));\n}\n}\n}\n</code></pre> <ul> <li>Retrieve a row</li> </ul> <p></p> <pre><code>private static void retrieveRow(CloseableHttpClient httpClient, String apiRestEndpoint)\nthrows Exception {\n// Build Request\nHttpGet rowReq = new HttpGet(apiRestEndpoint + \"/v2/keyspaces/\"\n+ ASTRA_DB_KEYSPACE + \"/users/Cedrick/Lunven\" );\nrowReq.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(rowReq)) {\nif (200 == res.getCode()) {\nString payload =  EntityUtils.toString(res.getEntity());\nlogger.info(\"[OK] Row retrieved\");\nlogger.info(\"Row retrieved : {}\", payload);\n}\n}\n}\n</code></pre> <p></p>"},{"location":"pages/develop/api/rest/#using-postman-with-rest","title":"Using Postman with REST","text":"<p>Postman is a widely-used collaboration platform for API development and testing. Using this third-party tool, you can easily test APIs with environments generated for your test platforms and imported testing collections of API queries.</p> <p>A Postman collection is available for Astra using the REST API. </p> <p></p>"},{"location":"pages/develop/frameworks/django/","title":"\u2022 Django","text":"<p>Django web framework. Ridiculously fast, fully loaded, reassuringly secure, exceedingly scalable, incredibly versatile. </p> <p>With Django, you can take web applications from concept to launch in a matter of hours. Django takes care of much of the hassle of web development, so you can focus on writing your app without needing to reinvent the wheel. It\u2019s free and open source.</p> <p>For more information, visit Django's website at djangoproject.com/.</p>"},{"location":"pages/develop/frameworks/django/#overview","title":"Overview","text":"<p>This guide describes how you can use Astra DB for your Django applications in a manner that is as idiomatic as possible within the Django way of doing things. The practices outlined here, in most cases, even make it possible to migrate an existing Django application to using Astra DB with minimal changes.</p> <p>RDBMS-based applications and Astra DB</p> <p>For more complex applications that fully leverage the capabilities of a relational database, such as foreign keys, adjustments of the data model would be needed according to the fundamental approach to data modeling in Astra DB (i.e. in Cassandra).</p> <p>In this page we adopt and suggest usage of the <code>django-cassandra-engine</code> Python package, which essentially provides Django object models on a Cassandra backend. Notice, however, that the package is not as feature-rich as its RDBMS counterpart, which in certain cases might require you to do a bit more of manual plumbing.</p>"},{"location":"pages/develop/frameworks/django/#reference-application","title":"Reference application","text":"<p>This page comes with a fully-working sample application as a companion repository, ready to be cloned and launched provided you go through its setup steps. All you need is an Astra DB instance and a corresponding database token. Refer to the README on the repository for more details, including a full setup guide, or click the button below to get a copy of the application:</p> <p></p> <p>The reference application (\"partyfinder\") is a very simple vanilla Django website to browse, create and delete \"parties\" happening in given cities at specific dates. Additionally, to illustrate the use of advanced Cassandra-specific features (namely, LWTs), a sort of \"count-me-in\" feature is also implemented to keep a consistent count of who will be attending a given party.</p>"},{"location":"pages/develop/frameworks/django/#astra-db-usage-in-django","title":"Astra DB usage in Django","text":"<p>With the Cassandra package for Django, you can switch between databases mostly in a seamless way: development still follows the \"object-mapper\" philosophy of defining models for the entities in the database and, so to speak, let the django engine figure the rest out by itself.</p> <p>A difference is that, instead of the native <code>django.db.models.Model</code>, you have to subclass <code>django_cassandra_engine.models.DjangoCassandraModel</code>; correspondingly, to comply with the underlying CQL data types available for columns, the fields in a model are drawn from the <code>cassandra.cqlengine.columns</code> package. Moreover, when creating a model for Cassandra, special syntax make it possible to specify which part of the primary key is in the clustering columns. The following example comes from the reference application:</p> <pre><code>import uuid\nfrom django.utils import timezone\nfrom cassandra.cqlengine import columns\nfrom django_cassandra_engine.models import DjangoCassandraModel\n# A model for this app\nclass Party(DjangoCassandraModel):\ncity = columns.Text(\nprimary_key=True,\n)\nid = columns.UUID(\nprimary_key=True,\nclustering_order='asc', # (allowed: 'asc' , 'desc', lowercase)\ndefault=uuid.uuid4,\n)\nname = columns.Text()\npeople = columns.Integer(default=0)\ndate = columns.DateTime(default=timezone.now)\nclass Meta:\nget_pk_field='id'\n</code></pre>"},{"location":"pages/develop/frameworks/django/#pitfalls-of-using-models","title":"Pitfalls of using Models","text":"<p>With object mappers, and the available Cassandra models, you can handle most of an application's needs. Still, a word of caution about usage of models is in order.</p> <p>Models, if used casually, may encourage the wrong read pattern on a Cassandra table: models implement methods such as <code>.all()</code>, which in general map to the dreaded \"allow filtering\" clause in terms of queries to Cassandra, and are generally to be avoided in production. Another example is that the model's <code>.filter(...)</code> method might be given filtering conditions that do not map to the sensible query patterns the table is designed for, thereby hidering performance or resulting in query timeouts. In short: do not let the model fool you, you still have to play by Cassandra's rules.</p> <p>Inadvertently querying a table the wrong way</p> <p>The table for <code>Party</code> objects above ends up having <code>PRIMARY KEY (( city ), id)</code>. This means that to get a given party one should do something like\"</p> <pre><code>parties = Party.objects.filter(city=city, id=id)\n</code></pre> <p>It is worth noting that if you omit the city, the following line would raise no error:</p> <pre><code>parties = Party.objects.filter(id=id)\n</code></pre> <p>and (assuming global uniqueness of the IDs) would even appear to work as fine, but the underlying CQL query would be a performance killer on a production application.</p> <p>There is another reason to be wary of models: some of the advanced techniques to use Cassandra simply don't fit into the models philosophy. For these, you need to access the underlying <code>Session</code> object and directly run CQL code on it. Luckily, there is a way to do so, and it is exemplified in the sample application (keep reading to see how to do it).</p>"},{"location":"pages/develop/frameworks/django/#implications-of-cassandra-data-models","title":"Implications of Cassandra data models","text":"<p>The proper road to a successful Cassandra (or Astra DB)-backed application starts from designing the right data model. But it is also possible to migrate existing Django applications: in most cases, as observed above, a one-to-one reformulation of the models would do the trick.</p> <p>However, the no-relations, no-joins, no-foreign-keys nature of the NoSQL database at hand means that if the existing application makes use of these things, a bit of work is warranted to go back to data-modeling-related issues.</p> <p>In other words, if models in your pre-existing, relational-based application contain RDBMS-related specifications such as:</p> <pre><code>from django.db import models\nfrom whatever import AnotherModel\nclass MyEntity(models.Model):\nfkField = models.ForeignKey(AnotherModel, on_delete=models.CASCADE)\n# etc, etc ...\n</code></pre> <p>you have to consider more structural changes, such as moving the burden of joins or cascading deletes to the application itself or - even better - rethink your tables (and models) in a way that works without these costly operations. You can find good tutorials and hands-on learning resources on data modeling with Cassandra here and here.</p>"},{"location":"pages/develop/frameworks/django/#beyond-models","title":"Beyond models","text":"<p>In some cases the best approach is to bypass the \"model layer\" altogether and directly execute CQL code on your Session object, taking care of manually handling the results in case of \"read\" queries.</p> <p>For example, the Session is needed to use Batches, LWTs and work with TTL.</p> <p>In the application example we have a feature that allows users to increment/decrement a <code>people</code> field for a party. However, we don't want these operations to succeed if the number seen by users on their browsers does not match the stored value anymore (think race conditions and concurrent access to the application: we certainly don't want risking this counter to go below zero!).</p> <p>A possible (if perhaps not optimal, performance-wise) solution to this problem is offered by using Lightweight Transactions. Essentially we want to run the CQL equivalent of \"update column <code>people</code> of that row, but only if the current value is so-and-so. Report back whether the update succeeded.\" This is achieved, in the appropriate view function, by the following code, which retrieves the database session and runs \"raw CQL\" on it:</p> <pre><code>from django.db import connection\n# ... ...\ndef change_party_people(request, city, id, prev_value, delta):\ndelta_num = int(delta)\ncursor = connection.cursor()\nchange_applied = cursor.execute(\n'UPDATE party SET people = %s WHERE city=%s AND id=%s IF people = %s',\n(\ndelta_num + prev_value,\ncity,\nuuid.UUID(id),  # must respect Cassandra type system\nprev_value,\n),\n).one()['[applied]']\nif not change_applied:\nlwt_message = '?LWT_FAILED=1'\nelse:\nlwt_message = ''\n# etc, etc ...\n</code></pre>"},{"location":"pages/develop/frameworks/django/#configuration-and-db-access-in-django","title":"Configuration and DB access in Django","text":"<p>Now let's look at how to configure a Django application to use Astra DB and how the access parameters and secrets are passed to it.</p>"},{"location":"pages/develop/frameworks/django/#settingspy","title":"settings.py","text":"<p>The general project-level settings are given in <code>parties/parties/settings.py</code>. In that file, you should first add the <code>\"django_cassandra_engine\"</code> item to the <code>INSTALLED_APPS</code> so that it comes first in the list.</p> <p>Second, you should replace the definition of the storage engine (sqlite3 by default on newly-created applications). That is, replace the following</p> <pre><code>DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR / 'db.sqlite3',\n    }\n}\n</code></pre> <p>with something like</p> <pre><code>DATABASES = {\n'default': {\n'ENGINE': 'django_cassandra_engine',\n'NAME': KEYSPACE_NAME\n'OPTIONS': {\n'connection': {\n'auth_provider': PlainTextAuthProvider(\nAUTH_USERNAME,\nAUTH_PASSWORD,\n),\n'cloud': {\n'secure_connect_bundle': SECURE_BUNDLE_PATH,\n},\n}\n}\n}\n}\n</code></pre> <p>Note that you should add the line <code>from cassandra.auth import PlainTextAuthProvider</code> earlier in the file.</p> <p>In the above database connection settings, there are four variables that should be set in a secure and portable manner (e.g. through use of a <code>.env</code> file as shown in the application example, or otherwise): they are</p> <ul> <li><code>KEYSPACE_NAME</code>, the name of the keyspace in your Astra DB instance. Note that you don't have to create the tables yourself. Tables are created based on model definitions when you issue Django's <code>sync_cassandra</code> command before running the application the first time (see instructions on the sample application's readme);</li> <li><code>AUTH_USERNAME</code> and <code>AUTH_PASSWORD</code>: these may be either the \"clientID/clientSecret\" pair from your database token, or alternatively the literal <code>\"token\"</code> and the token string starting with <code>AstraCS:...</code>.</li> <li><code>SECURE_BUNDLE_PATH</code>, the full path to the Secure connect bundle for your database. This can be downloaded manually or, as described in the application's readme, through use of Astra CLI along with the rest of the above setup.</li> </ul> <p>Third, you may consider adding the line <code>CASSANDRA_FALLBACK_ORDER_BY_PYTHON = True</code>. This means that, when a model's <code>order_by()</code> directive cannot be mapped to CQL according to the table's clustering, the model can fall back to in-code sorting. Although this may be non-optimal in general (especially for large result sets), it can still be a safe and useful choice if you know that the amount of data involved is small.</p>"},{"location":"pages/develop/frameworks/django/#dependencies-and-cassandra-drivers","title":"Dependencies and Cassandra drivers","text":"<p>Two dependencies are needed for a Django application backed by Astra DB:</p> <ul> <li><code>Django</code></li> <li><code>django-cassandra-engine</code></li> </ul> <p>(The other package found in the sample app's <code>requirements.txt</code>, <code>python-dotenv</code>, serves the purpose of reading secrets from a <code>.env</code> file in the Django app's <code>settings.py</code>.)</p> <p>It should be noted that current versions of the Cassandra engine for Django automatically installs ScyllaDB's version of the Cassandra drivers, i.e. package <code>scylla-driver</code>. These are a drop-in replacement for the package by DataStax (<code>cassandra-driver</code>), meaning that:</p> <ol> <li>both are imported with statements such as <code>from cassandra.cluster import Cluster</code> and the like;</li> <li>it is unwise to install both at once as that would introduce namespace collisions.</li> </ol> <p>If you prefer to work with the driver package by DataStax, the application would work just fine indeed: to do so, one can simply uninstall the drivers by Scylla (<code>pip uninstall scylla-driver</code>), and then install the desired drivers (<code>pip install cassandra-driver</code>). Not even a line of code should then be changed.</p> <p>Note: at the time of writing (January 2023), the differences between the two drivers are little and mostly confined to additional support for Scylla-specific database architecture. As such, there would be no implications on the functionality, nor the performance, of applications based on Astra DB.</p>"},{"location":"pages/develop/frameworks/django/#caveats-and-troubleshooting","title":"Caveats and Troubleshooting","text":"<p>In this section we collect a handy list of warnings and things to keep in mind when using Astra DB with Django, whether by migration or when designing an app from scratch.</p> <ul> <li> <p>In Cassandra models, there is no <code>max_length</code> parameter for text fields, corresponding to the absence of such a property for the CQL <code>TEXT</code> data type.</p> </li> <li> <p>Likewise, you should not add the <code>editable=False</code> parameter for primary-key columns when defining models.</p> </li> <li> <p>For a model class subclassing <code>DjangoCassandraModel</code> with a multi-column primary key (regardless of the partition/clustering distinction) one must provide a <code>get_pk_field</code> attribute through a <code>Meta</code> class: in this way the Django engine would be able to resolve queries such as <code>&lt;Model class&gt;.objects.get(pk=...)</code>. You can see an example of this in the model quoted earlier. Failure to comply with this requirement would make the application fail to start with an informative error. If you are using the model in a sensible way (from a Cassandra perspective), you can pay little attention to this since you should not, as a matter of fact, be triggering such a query anywhere in your code, implicitly or explicitly.</p> </li> <li> <p>The <code>django-cassandra-engine</code> package does support most of the features of its native, RDBMS counterpart; however, in some cases, a little more manual plumbing might be in order. In particular, the native models support fields of type <code>FileField</code>, which pairs with the form field of the same name  and handles upload of files by storing the actual file content on disk and a path to it on DB. The Cassandra engine has no such facility, requiring you to manually handle what happens once the endpoint has received file uploads via a form POST (you can still use the form field, though). A similar consideration holds for the more specific <code>ImageField</code> model field.</p> </li> <li> <p>Once the application is ready and the DB has been synchronized with it (using <code>./manage.py sync_cassandra</code> or equivalent command), you will still see warnings about a number of \"unapplied migrations\". You can ignore these warnings (incidentally, the <code>migrate</code> command is not even supported by the Cassandra engine, being supplanted by <code>sync_cassandra</code>).</p> </li> <li> <p>If you change the model and try to run the application, or forget to run the <code>sync_cassandra</code> management operation altogether, changes are you will see the application crash with no messages or with just a unhelpful <code>Segmentation fault (core dumped)</code> message. In this case, please make sure that (1) your database is not in \"Hibernated\" state, (2) you have launched a sync operation after all changes to any model.</p> </li> <li> <p>If you use a model's <code>filter(...)</code> method but with a filtering condition (a <code>WHERE</code> clause) that is not a good match to the structure of your database table, the application will most likely function, but possibly exhibit bad performance. It is your responsibility to make sure that usage of models does not sweep violations of data modeling best practices under the rug.</p> </li> <li> <p>As remarked above, if you request objects to be sorted in a way that is not compliant with the structure of your table, you can still enable a fallback behaviour whereby the rows are sorted post-retrieval in Python code (you do this through <code>CASSANDRA_FALLBACK_ORDER_BY_PYTHON</code> in <code>settings.py</code>, but you should do this only if there are few rows involved). Don't be alarmed if you still see something like the following in the application logs (the warning would be a true exception if you hadn't enabled the fallback):</p> </li> </ul> <pre><code>UserWarning: .order_by() with column \"-date\" failed!\nFalling back to ordering in python.\nException was:\nCan't order on 'date', can only order on (clustered) primary keys\n</code></pre>"},{"location":"pages/develop/frameworks/django/#references","title":"References","text":"<ul> <li>Django homepage, djangoproject.com;</li> <li><code>django-cassandra-engine</code> documentation, r4fek.github.io/django-cassandra-engine;</li> <li>The sample application referenced throughout this page, \"partyfinder\";</li> <li>Another Django application using Cassandra from DataStax' Sample App Gallery: a simple standard blog engine.</li> </ul>"},{"location":"pages/develop/frameworks/fastapi/","title":"\u2022 FastAPI","text":"<p>FastAPI framework, high performance, easy to learn, fast to code, ready for production. FastAPI is a modern, fast web framework for building APIs with Python 3.6+ based on standard Python type hints. FastAPI strives to minimize boilerplate and maximize performance.</p> <p>To get more information regarding the framework visit the reference website fastapi.tiangolo.com.</p>"},{"location":"pages/develop/frameworks/fastapi/#1-overview","title":"1. Overview","text":"<p>This guide, and the accompanying sample code, highlight the practices and the patterns to best integrate FastAPI with Astra DB to use the latter as backing storage.</p> <p>Two important choices are made in the following:</p> <ul> <li>Astra DB is accessed with the Python driver;</li> <li>no Object Mappers are used, just plain simple CQL statements.</li> </ul>"},{"location":"pages/develop/frameworks/fastapi/#2-fastapi-and-astra-db","title":"2. FastAPI and Astra DB","text":"<p>The goal is to provide access to one or more tables stored in Astra DB to the FastAPI endpoint functions, so that the API can write data to them and read from them. This should be done keeping in mind the best practices for using the Cassandra drivers, and in as flexible and concise way as possible.</p>"},{"location":"pages/develop/frameworks/fastapi/#session","title":"Session","text":"<p>Virtually every endpoint needs access to the database. On the other hand, the driver's <code>cassandra.cluster.Session</code> is a stateful, resource-intensive object that should be created once and re-used throughout the life cycle of the Python process.</p> <p>For this reason (file <code>storage/db_connect.py</code> in the sample app) there is a <code>get_session()</code> function that keeps a globally-cached session object and returns it any time it is called, in a singleton fashion. On its first invocation, of course, the session is created in the idiomatic way, looking for the necessary connection parameters from a <code>.env</code> file. This file contains secrets, so it should never be checked in to version control.</p> <p>Note. If the application runs on regular Cassandra (as opposed to Astra DB), this is the only part of the code that would change: the parameters for instantiating the <code>Cluster</code> and the <code>Session</code> would differ slightly.</p> <p>Since it is a good practice to explicitly free resources once we're done, in this module there's also a shutdown hook that takes care of cleanup by closing the session and shutting down the <code>Cluster</code> object. (which for a FastAPI application that runs indefinitely is a bit of a moot point, but still illustrates the point).</p>"},{"location":"pages/develop/frameworks/fastapi/#endpoint-dependencies","title":"Endpoint dependencies","text":"<p>Next comes the task of making the session object available to the function endpoints: these will need to retrieve rows and/or write them, after all.</p> <p>Taking advantage of FastAPI's advanced dependency injection facilities, one can add a <code>Depends</code> parameter to the endpoint functions, which will be automatically resolved when the function gets executed. This makes the session available to the function:</p> <pre><code>@app.get('/animal/{genus}')\nasync def get_animals(genus, session=Depends(g_get_session)):\n# etc, etc ...\n</code></pre> <p>The argument of <code>Depends</code> is a function itself, more precisely an async generator, which must <code>yield</code> the session object. For this reason there is a thin wrapper function that, in practice, promotes the ordinary function <code>get_session</code> to a generator with the desired signature:</p> <pre><code>async def g_get_session():\nyield get_session()\n</code></pre> <p>At this point, FastAPI takes care of the wiring. What is still missing is the business logic itself, i.e. what happens within the endpoint functions.</p>"},{"location":"pages/develop/frameworks/fastapi/#prepared-statements","title":"Prepared statements","text":"<p>It is a good practice to keep the code in the endpoint function short and not to embed much logic into it, except for the handling of the request-response cycle itself.</p> <p>For this reason, each endpoint function in turn invokes a function in the <code>storage/db_io.py</code> module, which is where the actual database operations are executed.</p> <p>In this module another important observation is in order: since it is expected that the API endpoints will be called many times, the corrsponding CQL statements are made into \"prepared statements\" once and then re-used over and over.</p> <p>To achieve that, the <code>db_io.py</code> module holds a cache of prepared statements, one per different type of database query. This cache (<code>prepared_cache</code>) is filled on the first invocation of each endpoint, but after that there is a sizable gain in performance and reduction of overhead for all subsequent calls.</p>"},{"location":"pages/develop/frameworks/fastapi/#streaming-a-large-response-from-db","title":"Streaming a large response from DB","text":"<p>In some cases, an API endpoint may return a large response (such as a GET returning a long list of items). It might be unwieldy, and suboptimal, to retrieve the full list at API level and then prepare a whole response string to return to the caller.</p> <p>Ideally, one would like to start sending out the response as the data keeps coming in (to the API) from the database. This is exactly what <code>StreamingResponse</code> makes possible.</p> <p>The Cassandra driver handles pagination of large result sets transparently: regardless of the grouping of rows into pages, at the Python-code level all you see is a homogeneous iterable over all rows. This means that one can simply make the corresponding data-retrieval function a generator almost with no changes in the code.</p> <p>Things get slightly more tricky on the other side, that is, between the endpoint function and the caller. Fortunately, FastAPI offers the <code>StreamingResponse</code> construct that makes it possible to \"consume\" a generator and return its components as a \"Chunked\" type of response. The client will still receive a full response (and will be able to start processing it once it is there in full), but never throughout the live of the request will there be \"the full thing\" on the API side.</p> <p>But beware: in this case, the endpoint function will need to manually construct \"pieces of a syntactically valid JSON\". In the sample app, this is achieved by a <code>format_streaming_response</code> function which takes care of the opening/closing square brackets for a list and of the correct placement of the commas. In practice, this function makes a generator over homogeneous items into a generator returning something like (row-by-row; note the commas):</p> <pre><code>1.     [\n2.     {\"a\": 1, \"b\": 100}\n3.     ,{\"a\": 2, \"b\": 200}\n4.     ,{\"a\": 3, \"b\": 300}\n5.     ,{\"a\": 4, \"b\": 400}\n6.     ]\n</code></pre>"},{"location":"pages/develop/frameworks/fastapi/#3-reference-application","title":"3. Reference application","text":"<p>You can clone the reference application coming with this page and run it in minutes, provided you have an Astra DB instance (click here to create one).</p> <p>The setup instructions are outlined below: for more details, refer to the repo's README.</p>"},{"location":"pages/develop/frameworks/fastapi/#setup","title":"Setup","text":"<p>An Astra DB instance, with corresponding Token and Secure connect bundle, are required to run this app: make sure you have them at your disposal.</p> <p>Once you cloned the repository, create the <code>.env</code> file with the required secrets and (preferrably in a Python virtual environment) install all dependencies with <code>pip install -r requirements.txt</code>.</p> <p>In order to populate the database (table creation and insertion of sample rows), you should run once the script <code>python storage/db_initialize.py</code>. You are now ready to run the API.</p>"},{"location":"pages/develop/frameworks/fastapi/#run-sample-app","title":"Run sample app","text":"<p>Running the API is as simple as <pre><code>uvicorn api:app\n</code></pre></p> <p>You can now issue requests to it. Look in the repo's README for example requests, testing all provided endpoints, as <code>curl</code> commands (of course you can use any tool you like, such as Postman, to achieve the same effect).</p> <p></p>"},{"location":"pages/develop/frameworks/flask/","title":"\u2022 Flask","text":"<p>Flask - Web development, one drop at a time. Flask is a lightweight WSGI web application framework. It is designed to make getting started quick and easy, with the ability to scale up to complex applications. It began as a simple wrapper around Werkzeug and Jinja and has become one of the most popular Python web application frameworks.</p> <p>To get more information regarding the framework visit the reference website flask.palletsprojects.com.</p>"},{"location":"pages/develop/frameworks/flask/#1-overview","title":"1. Overview","text":"<p>This guide, and the accompanying sample code, highlight the practices and the patterns to best integrate Flask with Astra DB to use the latter as backing storage.</p> <p>Two important choices are made in the following:</p> <ul> <li>Astra DB is accessed with the Python driver;</li> <li>no Object Mappers are used, just plain simple CQL statements.</li> </ul>"},{"location":"pages/develop/frameworks/flask/#2-flask-and-astra-db","title":"2. Flask and Astra DB","text":"<p>The goal is to provide access to one or more tables stored in Astra DB to the Flask endpoint functions, so that the API can write data to them and read from them. This should be done keeping in mind the best practices for using the Cassandra drivers, and in as flexible and concise way as possible.</p>"},{"location":"pages/develop/frameworks/flask/#session","title":"Session","text":"<p>Virtually every endpoint needs access to the database. On the other hand, the driver's <code>cassandra.cluster.Session</code> is a stateful, resource-intensive object that should be created once and re-used throughout the life cycle of the Python process.</p> <p>For this reason (file <code>storage/db_connect.py</code> in the sample app) there is a <code>get_session()</code> function that keeps a globally-cached session object and returns it any time it is called, in a singleton fashion. On its first invocation, of course, the session is created in the idiomatic way, looking for the necessary connection parameters from a <code>.env</code> file. This file contains secrets, so it should never be checked in to version control.</p> <p>Note. If the application runs on regular Cassandra (as opposed to Astra DB), this is the only part of the code that would change: the parameters for instantiating the <code>Cluster</code> and the <code>Session</code> would differ slightly.</p> <p>Since it is a good practice to explicitly free resources once we're done, in this module there's also a shutdown hook that takes care of cleanup by closing the session and shutting down the <code>Cluster</code> object. (which for a Flask application that runs indefinitely is a bit of a moot point, but still illustrates the point).</p>"},{"location":"pages/develop/frameworks/flask/#endpoint-dependencies","title":"Endpoint dependencies","text":"<p>Next comes the task of making the session object available to the function endpoints: these will need to retrieve rows and/or write them, after all.</p> <p>Typically all API endpoints need to access the database: in this case, the easiest way is to use Flask's application-context <code>g</code> object and the <code>before_request</code> hook to make sure each request will find a reference to the session. Once the pre-request hook is set up with <pre><code>@app.before_request\ndef get_db_session():\ng.session = get_session()\n</code></pre> all endpoints will be able to read and use <code>g.session</code> as they need. Remember that <code>get_session()</code> does not create a new Cassandra <code>Session</code> object at each invocation!</p> <pre><code>@app.route('/animal/&lt;genus&gt;')\ndef get_animals(genus):\nanimals = retrieve_animals_by_genus(g.session, genus)\nreturn jsonify([animal.dict() for animal in animals])\n</code></pre>"},{"location":"pages/develop/frameworks/flask/#prepared-statements","title":"Prepared statements","text":"<p>It is a good practice to keep the code in the endpoint function short and not to embed much logic into it, except for the handling of the request-response cycle itself.</p> <p>For this reason, each endpoint function in turn invokes a function in the <code>storage/db_io.py</code> module, which is where the actual database operations are executed.</p> <p>In this module another important observation is in order: since it is expected that the API endpoints will be called many times, the corrsponding CQL statements are made into \"prepared statements\" once and then re-used over and over.</p> <p>To achieve that, the <code>db_io.py</code> module holds a cache of prepared statements, one per different type of database query. This cache (<code>prepared_cache</code>) is filled on the first invocation of each endpoint, but after that there is a sizable gain in performance and reduction of overhead for all subsequent calls.</p>"},{"location":"pages/develop/frameworks/flask/#streaming-a-large-response-from-db","title":"Streaming a large response from DB","text":"<p>In some cases, an API endpoint may return a large response (such as a GET returning a long list of items). It might be unwieldy, and suboptimal, to retrieve the full list at API level and then prepare a whole response string to return to the caller.</p> <p>Ideally, one would like to start sending out the response as the data keeps coming in (to the API) from the database. This is exactly what Flask's \"streaming responses\" make possible.</p> <p>The Cassandra driver handles pagination of large result sets transparently: regardless of the grouping of rows into pages, at the Python-code level all you see is a homogeneous iterable over all rows. This means that one can simply make the corresponding data-retrieval function a generator almost with no changes in the code.</p> <p>Things get slightly more tricky on the other side, that is, between the endpoint function and the caller. Fortunately, Flask endpoint functions may return a <code>(generator, headers)</code> pair and will construct, from this, a \"Chunked\" response which will be sent to the caller piecewise, as the generator gets consumed. The client will still receive a full response (and will be able to start processing it once it is there in full), but never throughout the live of the request will there be \"the full thing\" on the API side.</p> <p>But beware: in this case, the endpoint function will need to manually construct \"pieces of a syntactically valid JSON\". In the sample app, this is achieved by a <code>format_streaming_response</code> function which takes care of the opening/closing square brackets for a list and of the correct placement of the commas. In practice, this function makes a generator over homogeneous items into a generator returning something like (row-by-row; note the commas):</p> <pre><code>1.     [\n2.     {\"a\": 1, \"b\": 100}\n3.     ,{\"a\": 2, \"b\": 200}\n4.     ,{\"a\": 3, \"b\": 300}\n5.     ,{\"a\": 4, \"b\": 400}\n6.     ]\n</code></pre>"},{"location":"pages/develop/frameworks/flask/#pydantic-usage","title":"Pydantic usage","text":"<p>The reference API uses Pydantic for validation and handling of request/response data types (this is not strictly necessary, but very handy). However, this requires some manual plumbing, as can be seen in the code in two ways:</p> <p>First, to validate/cast the POST request payload, a <code>animal = Animal(**request.get_json())</code> is wrapped in a try/except construct, in order to return a meaningful error (from Pydantic) and a status 422 (\"unprocessable entity\") if anything is off. Note: <code>request</code> is a Flask abstraction</p> <p>Moreover, when returning responses, one must explicitly <code>jsonify</code> not directly the Pydantic object, rather its <code>.dict()</code> representation. So, for example, <code>return jsonify(animal.dict())</code>. Note: <code>jsonify</code> is a Flask primitive, whole <code>.dict()</code> is a built-in method for Pydantic models.</p>"},{"location":"pages/develop/frameworks/flask/#3-reference-application","title":"3. Reference application","text":"<p>You can clone the reference application coming with this page and run it in minutes, provided you have an Astra DB instance (click here to create one).</p> <p>The setup instructions are outlined below: for more details, refer to the repo's README.</p>"},{"location":"pages/develop/frameworks/flask/#setup","title":"Setup","text":"<p>An Astra DB instance, with corresponding Token and Secure connect bundle, are required to run this app: make sure you have them at your disposal.</p> <p>Once you cloned the repository, create the <code>.env</code> file with the required secrets and (preferrably in a Python virtual environment) install all dependencies with <code>pip install -r requirements.txt</code>.</p> <p>In order to populate the database (table creation and insertion of sample rows), you should run once the script <code>python storage/db_initialize.py</code>. You are now ready to run the API.</p>"},{"location":"pages/develop/frameworks/flask/#run-sample-app","title":"Run sample app","text":"<p>Running the API is as simple as <pre><code>flask --app api run --reload\n</code></pre></p> <p>You can now issue requests to it. Look in the repo's README for example requests, testing all provided endpoints, as <code>curl</code> commands (of course you can use any tool you like, such as Postman, to achieve the same effect).</p> <p></p>"},{"location":"pages/develop/frameworks/lagom/","title":"Lagom","text":""},{"location":"pages/develop/frameworks/lagom/#overview","title":"Overview","text":""},{"location":"pages/develop/frameworks/lagom/#working-with-lagom","title":"Working with Lagom","text":"<p>Lagom is an open source framework for building out Reactive microservices.  Lagom essentially wires-up your services, freeing you from having to spend time writing lots of \"boiler-plate\" code.  To get more information regarding the framework visit its website @ lagomframework.com.</p>"},{"location":"pages/develop/frameworks/lagom/#prerequisites","title":"Prerequisites","text":""},{"location":"pages/develop/frameworks/lagom/#prerequisites-astra-db","title":"\ud83d\udce6. Prerequisites [ASTRA DB]","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul>"},{"location":"pages/develop/frameworks/lagom/#prerequisites-development-environment","title":"\ud83d\udce6. Prerequisites [Development Environment]","text":"<ul> <li> <p>You should install the Java Development Kit (JDK), of at least version 8: Use the reference documentation to install a Java Development Kit.</p> </li> <li> <p>Java 8</p> </li> <li>Java 11</li> <li>Java 17</li> </ul> <p>Validate your installation with:</p> <pre><code>java --version\n</code></pre> <ul> <li>You should install Apache Maven: Use the reference documentation and validate your installation with:</li> </ul> <pre><code>mvn -version\n</code></pre>"},{"location":"pages/develop/frameworks/lagom/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"pages/develop/frameworks/lagom/#building-a-sample-lagom-project","title":"Building a sample Lagom project","text":"<p>Create a new Maven project in your IDE which uses the <code>maven-archetype-lagom-java</code> archetype.  You can also do this from the command line:</p> <pre><code>mvn archetype:generate -DarchetypeGroupId=com.lightbend.lagom \\\n-DarchetypeArtifactId=maven-archetype-lagom-java -DarchetypeVersion=1.2.0\n</code></pre> <p>This will create a sample Lagom project with two services: Hello and Stream.  The project can be built and run with this command:</p> <pre><code>mvn lagom:runAll\n</code></pre> <p>Note that by default, Lagom will start using embedded Cassandra as its data store, running on <code>localhost:4000</code>.  Port 4000 was chosen (instead of 9042) so as not to collide with another instance of Cassandra running locally.</p>"},{"location":"pages/develop/frameworks/lagom/#using-with-apache-cassandra","title":"Using with Apache Cassandra","text":"<p>To get Lagom to connect to Cassandra (for local development) there are two places which need changes: Maven's <code>pom.xml</code> and the services' <code>application.conf</code> files.</p> <p>Inside the <code>pom.xml</code> file, locate the <code>lagom-maven-plugin</code> and make the following adjustments: <pre><code>&lt;plugin&gt;\n&lt;groupId&gt;com.lightbend.lagom&lt;/groupId&gt;\n&lt;artifactId&gt;lagom-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;${lagom.version}&lt;/version&gt;\n&lt;configuration&gt;\n&lt;unmanagedServices&gt;\n&lt;cas_native&gt;localhost:9042&lt;/cas_native&gt;\n&lt;/unmanagedServices&gt;                    &lt;cassandraEnabled&gt;false&lt;/cassandraEnabled&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre></p> <p>That these settings perform two functions: - Disables Lagom's embedded Cassandra, causing it not to start. - Informs Lagom designate Cassandra as an \"unmanaged\" service, and provides it with the contact point for the cluster/instance.</p> <p>If your local Cassandra does not use SSL or authentication, then you are finished.  But if your local Cassandra does have security enabled, you'll want to make these changes to each of your services' <code>application.conf</code> files: <pre><code>your-service.cassandra {\n    authentication {\n        username = \"yourUserName\"\n        password = \"yourPassword\"\n    }\n    ssl {\n        truststore.path = \"/Users/youruser/cassandra/truststore.jks\"\n        truststore.password = \"yourTrustStorePassword\"\n        keystore.path = \"/Users/youruser/cassandra/keystore.jks\"\n        keystore.password = \"yourKeyStorePassword\"\n    }\n    keyspace = your_service\n}\n\ncassandra-journal {\n    keyspace = ${your-service.cassandra.keyspace}\n    authentication = ${your-service.cassandra.authentication}\n    ssl = ${your-service.cassandra.ssl}\n}\n\ncassandra-snapshot-store {\n    keyspace = ${your-service.cassandra.keyspace}\n    authentication = ${your-service.cassandra.authentication}\n    ssl = ${your-service.cassandra.ssl}\n}\n\nlagom.persistence.read-side.cassandra {\n    keyspace = ${your-service.cassandra.keyspace}\n    authentication = ${your-service.cassandra.authentication}\n    ssl = ${your-service.cassandra.ssl}\n}\n</code></pre></p> <p>These settings will allow Lagom to connect to your local Cassandra with authentication and client-to-node SSL.  If you're only using auth, simply remove the config lines containing <code>ssl</code>.</p>"},{"location":"pages/develop/frameworks/lagom/#using-with-datastax-astra-db","title":"Using with DataStax Astra DB","text":"<p>For connecting to DataStax Astra DB, it is similar.  You will need to set both authentication and SSL to connect with Astra DB, as well as a few additional properties.</p> <p>The <code>pom.xml</code> is largely the same, except that you'll need to add your Astra host name here.  Note that in \"production mode,\" you should not need to modify this file.  But if you're connecting to an Astra DB cluster in \"development mode,\" you'll still need to disable embedded Cassandra and designate the Cassandra service as \"unmanaged\" with a contact point: <pre><code>&lt;configuration&gt;\n&lt;unmanagedServices&gt;\n&lt;cas_native&gt;https://ASTRA_DB_ID-ASTRA_DB_REGION.db.astra.datastax.com:29042&lt;/cas_native&gt;\n&lt;/unmanagedServices&gt;                    &lt;cassandraEnabled&gt;false&lt;/cassandraEnabled&gt;\n&lt;/configuration&gt;\n</code></pre></p> <p>The <code>application.conf</code> service files will require similar modifications: <pre><code>stream.cassandra {\n    contact-points = [\"ASTRA_DB_ID-ASTRA_DB_REGION.db.astra.datastax.com:29042\"]\n    authentication {\n        username = \"token\"\n        password = \"AstraCS:yourAstraT0ken\"\n    }\n    ssl {\n        truststore.path = \"/Users/youruser/astradb/trustStore.jks\"\n        truststore.password = \"yourTrustStorePassword\"\n        keystore.path = \"/Users/youruser/stackoverflow/identity.jks\"\n        keystore.password = \"Tte3jRy07ocEf6Z8h\"\n    }\n    session-provider = akka.persistence.cassandra.ConfigSessionProvider\n    keyspace = \"stream\"\n}\n\ncassandra-journal {\n    contact-points = ${stream.cassandra.contact-points}\n    keyspace = ${stream.cassandra.keyspace}\n    authentication = ${stream.cassandra.authentication}\n    ssl = ${stream.cassandra.ssl}\n    session-provider = ${stream.cassandra.session-provider}\n    keyspace-autocreate = false\n    tables-autocreate = true\n}\n\ncassandra-snapshot-store {\n    contact-points = ${stream.cassandra.contact-points}\n    keyspace = ${stream.cassandra.keyspace}\n    authentication = ${stream.cassandra.authentication}\n    ssl = ${stream.cassandra.ssl}\n    session-provider = ${stream.cassandra.session-provider}\n    keyspace-autocreate = false\n    tables-autocreate = true\n}\n\nlagom.persistence.read-side.cassandra {\n    contact-points = ${stream.cassandra.contact-points}\n    keyspace = ${stream.cassandra.keyspace}\n    authentication = ${stream.cassandra.authentication}\n    ssl = ${stream.cassandra.ssl}\n    session-provider = ${stream.cassandra.session-provider}\n    keyspace-autocreate = false\n    tables-autocreate = true\n}\n</code></pre></p> <p>Note the options for <code>keyspace-autocreate</code> and <code>tables-autocreate</code> are shown set here.  By default, these are both set to <code>true</code>.  However, Astra DB only permits keyspace creation to happen via the Astra Dashboard.  This means that:</p> <ul> <li>Keyspaces must be created before connecting a Lagom microservice to Astra DB.</li> <li>Lagom's attempts to create keyspaces will fail (due to a permissions error).</li> <li>Table creation should function appropriately, assuming the required keyspaces already exist.</li> </ul> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/develop/frameworks/micronaut/","title":"Micronaut","text":"<p>This guide was built based on the Micronaut Cassandra Guide </p>"},{"location":"pages/develop/frameworks/micronaut/#overview","title":"Overview","text":"<p>Micronaut is a modern, JVM-based, full stack Java framework designed for building modular, easily testable JVM applications with support for Java, Kotlin, and Groovy. Micronaut is developed by the creators of the Grails framework and takes inspiration from lessons learnt over the years building real-world applications from monoliths to microservices using Spring, Spring Boot and Grails. For more information refer to the user guide</p> <p>The micronaut-cassandra module includes support for integrating Micronaut services with Cassandra.</p>"},{"location":"pages/develop/frameworks/micronaut/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> <li>You should install `Java JDK 1.8+` and Apache Maven</li> </ul>"},{"location":"pages/develop/frameworks/micronaut/#configuration","title":"Configuration","text":"<p>You can find a working sample here</p>"},{"location":"pages/develop/frameworks/micronaut/#step-1-create-your-project","title":"\u2705 Step 1: Create your project","text":"<ul> <li>To create a micronaut project and CLI <code>mn</code> is provided. You can install it using <code>sdkman</code> as describe in the doc</li> </ul> <pre><code>#Download SDKMan\ncurl -s https://get.sdkman.io | bash\n\n#Setup SDKMan\nsource \"$HOME/.sdkman/bin/sdkman-init.sh\"\n#Download Micronaut\nsdk install micronaut\n</code></pre> <ul> <li>To generate a new project use <code>mn create-app</code> adding the feature cassandra</li> </ul> <pre><code>mn create-app astra-todo-micronaut --features cassandra\n</code></pre> <ul> <li>Notice that in your <code>pom.xml</code> you now have the following</li> </ul> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;io.micronaut.cassandra&lt;/groupId&gt;\n&lt;artifactId&gt;micronaut-cassandra&lt;/artifactId&gt;\n&lt;scope&gt;compile&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"pages/develop/frameworks/micronaut/#step-2-setup-your-project","title":"\u2705 Step 2: Setup your project","text":"<p>All configuration of your project will be defined in <code>application.yaml</code> in <code>src/main/resources</code>. The module is clever enough to load all properties as if it was the driver configuration file.</p> <p>You can defined multiple profiles and each profile will be identified with key <code>cassandra.${profile_name}</code>. There is a <code>default</code> profile. In the following sample file we provide 2 profiles one for local and one for Astra. There is no extra code needed, simply configuration.</p> <pre><code>cassandra:\ndefault:\nbasic:\nsession-keyspace: micronaut\ncontact-points:\n- \"localhost:9042\"\nload-balancing-policy:\nlocal-datacenter: datacenter1\nastra:\nbasic:\nrequest:\ntimeout: 5 seconds\nconsistency: LOCAL_QUORUM\npage-size: 5000\nsession-keyspace: micronaut\ncloud:\nsecure-connect-bundle: /Users/cedricklunven/Downloads/secure-connect-workshops.zip\nadvanced:\nauth-provider:\nclass: PlainTextAuthProvider\nusername: token\npassword: \"AstraCS:blahblahblah\"\nconnection:\ninit-query-timeout: 10 seconds\nset-keyspace-timeout: 10 seconds\ncontrol-connection.timeout: 10 seconds\n</code></pre>"},{"location":"pages/develop/frameworks/micronaut/#step-3-application-startup","title":"\u2705 Step 3: Application Startup","text":"<p>At startup you may want create the different tables needed for you application. In Astra you can only create keyspaces from the devops API or the user interface..</p> <p>To enable content at startup simple implement <code>ApplicationEventListener&lt;ServiceReadyEvent&gt;</code> as shown below</p> <pre><code>@Singleton\npublic class TodoApplicationStartup  implements ApplicationEventListener&lt;ServiceReadyEvent&gt; {\n/** Logger for the class. */\nprivate static final Logger LOGGER = LoggerFactory.getLogger(TodoApplicationStartup.class);\n@Property(name = \"todo.cassandra.create_schema\", defaultValue=\"false\")\nprivate boolean createTable;\n@Inject\nprivate CqlSession cqlSession;\n/** {@inheritDoc} */\n@Override\npublic void onApplicationEvent(final ServiceReadyEvent event) {\nLOGGER.info(\"Startup Initialization\");\nif (createTable) {\nTodoServiceCassandraCql.createTableTodo(cqlSession);\nLOGGER.info(\"+ Table TodoItems created if needed.\");\n}\nLOGGER.info(\"[OK]\");\n}\n}\n</code></pre>"},{"location":"pages/develop/frameworks/micronaut/#step-4-use-cassandra","title":"\u2705 Step 4: Use Cassandra","text":"<p>To use Cassandra you will reuse the <code>CqlSession</code> from the DataStax drivers. You can simply inject it where you needed as shown in this sample code</p> <pre><code>@Validated\n@Controller(\"/api/v1\")\npublic class TodoRestController {\n/** Logger for our Client. */\nprivate static final Logger LOGGER = LoggerFactory.getLogger(TodoRestController.class);\n/** CqlSession initialized from application.yaml */\n@Inject\nprivate CqlSession cqlSession;\n</code></pre> <p>Happy coding.</p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/develop/frameworks/quarkus/","title":"\u2022 Quarkus","text":"<p>Quarkus - Supersonic Subatomic Java is a modern Kubernetes-native Java framework tailored for GraalVM and HotSpot to create applications for a modern, cloud-native world. </p> <p>The goal is to make Java the leading platform in Kubernetes and serverless environments while offering developers a framework to address a wider range of distributed application architectures.</p> <p>Wth its reactive nature, it complements Apache Cassandra and together they are a great fit for responsive microservices.</p>"},{"location":"pages/develop/frameworks/quarkus/#1-overview","title":"1. Overview","text":"<p>quarkus.io is the central repoistory for everything Quarkus related.</p> <p>The Cassandra Quarkus extension renders cassandra a first class citizen on the platform.</p> <p>You can [use the Cassandra client guide for Quarkus] (https://quarkus.io/guides/cassandra) to get started on using Quarkus and Astra together.</p>"},{"location":"pages/develop/frameworks/quarkus/#2-create-a-data-model","title":"2. Create a Data Model","text":"<p>Create a Data model for the simple application using the following CQL statement in the Astra console.</p> <pre><code>CREATE TABLE k1.Fruit ( name text PRIMARY KEY, description text);\n</code></pre> <p>where <code>k1</code> is the keyspace.</p>"},{"location":"pages/develop/frameworks/quarkus/#3-try-it-out","title":"3. Try it out!","text":"<p>Start by cloning the repo.</p> <pre><code>git clone https://github.com/datastaxdevs/Cassandra-Quarkus-Demo\n</code></pre> <p>Version check.</p> <p>Check the Java version with the following command.</p> <pre><code>java -version\nopenjdk version \"11.0.14\" 2022-01-18\nOpenJDK Runtime Environment GraalVM CE 22.0.0.2 (build 11.0.14+9-jvmci-22.0-b05)\nOpenJDK 64-Bit Server VM GraalVM CE 22.0.0.2 (build 11.0.14+9-jvmci-22.0-b05, mixed mode, sharing)\n</code></pre> <p>Setup Astra credentials.</p> <p>Include the credentials from the Astra console in the file <code>src/main/resources/application.properties</code> as shown below by downloading and including the path of the security connect bundle and the username and secret for the database.</p> <pre><code>-#quarkus.cassandra.cloud.secure-connect-bundle=/path/to/secure-connect-bundle.zip\n+quarkus.cassandra.cloud.secure-connect-bundle=k1.zip\n\n # Authentication\n # See https://docs.datastax.com/en/developer/java-driver/latest/manual/core/authentication/\n-#quarkus.cassandra.auth.username=&lt;your username&gt;\n-#quarkus.cassandra.auth.password=&lt;your password&gt;\n+quarkus.cassandra.auth.username=user\n+quarkus.cassandra.auth.password=secret\n</code></pre> <p>Package the app as below.</p> <pre><code>mvn clean package\n</code></pre> <p>and run the application as below.</p> <pre><code>java -jar target/cassandra-quarkus-quickstart-1.0.1-runner.jar\n</code></pre> <p>Check if the REST endpoints are accessible as below.</p> <pre><code>curl http://localhost:8080/fruits\n</code></pre> <p>As we've no data (yet), we should get an empty list.</p> <p>Let's add an entry as indicated in the example.</p> <pre><code>curl --header \"Content-Type: application/json\" \\\n  --request POST \\          \n  --data '{\"name\":\"apple\",\"description\":\"red and tasty\"}' \\\n  http://localhost:8080/fruits\n</code></pre> <p>Let's check via the <code>curl</code> command as below</p> <pre><code>curl http://localhost:8080/fruits\n</code></pre> <p>and also in the Astra CQL console.</p> <pre><code>select * from k1.Fruit;\n\n name  | description\n-------+---------------\n apple | red and tasty\n\n(1 rows)\n</code></pre>"},{"location":"pages/develop/frameworks/quarkus/#4-next-steps-and-conclusions","title":"4. Next Steps and Conclusions","text":"<p>You can check out the object mapper details, metrics and health reports from the app as outlined in the user guide.</p> <p>You could even package it as a native app and realize the full power of the Quarkus platform.</p>"},{"location":"pages/develop/frameworks/quarkus/#5-more-resources","title":"5. More Resources!","text":"<ul> <li>A complete Todo Application with Quarkus</li> <li>[Workshop outlining a step-by-step approach to run the application] (https://github.com/datastaxdevs/workshop-intro-quarkus-cassandra)</li> <li>Recording of the workshop</li> </ul> <p>\ud83c\udfe0 Back to home</p>"},{"location":"pages/develop/frameworks/spring/","title":"Spring","text":"<p>Spring makes programming Java quicker, easier, and safer for everybody. Spring\u2019s focus on speed, simplicity, and productivity has made it the world's most popular Java framework. To get more information regarding the framework visit the reference website Spring.io.</p> <p><code>Spring-Data</code> is the module use to interact with Databases whereas <code>Spring Boot</code> is the runtime for microservices. In this page we detail how to setup both modules to interact with Astra.</p>"},{"location":"pages/develop/frameworks/spring/#1-overview","title":"1. Overview","text":""},{"location":"pages/develop/frameworks/spring/#11-modules-dependencies","title":"1.1 Modules dependencies","text":"<p>Spring is an ecosystem with dozens of modules. The component used to connect a Spring application to Astra (Cassandra) is Spring Data and especially Spring Data Cassandra. It relies on the DataStax native java cassandra drivers and only provides an abstraction with Spring concepts (templates, repository, Entities...)</p> <p>The stateful object <code>CqlSession</code> is instantiated and injected in spring <code>CassandraTemplate</code> (aka <code>CassandraOperations</code>). From there, it is used either directly or injected in different <code>CassandraRepository</code> (specialization of Spring Data <code>CrudRepository</code> for Apache Cassandra\u2122).</p> <p>The configuration of <code>spring-data-cassandra</code> in <code>Spring-Boot</code> applications is simplified with the usage of starters. One is associated to the standard web stack and called <code>spring-boot-starter-data-cassandra</code> and the other is named <code>spring-boot-starter-data-cassandra-reactive</code> for the reactive stack.</p> <p></p>"},{"location":"pages/develop/frameworks/spring/#12-compatibility-matrix","title":"1.2 Compatibility Matrix","text":"<p>In January 2019, the native Cassandra Drivers got an important, not backward compatible, upgrade. To get informations regarding Apache Cassandra\u2122 support here is the Cassandra compatibility matrix.</p> <p>Spring Data copes with the new generation of drivers starting with Spring data 3.x. Support of Astra was introduced in 2020 for all native versions (4.x and 3.x). This leads to the following table for minimal library versions for Astra Support:</p> Drivers Release Drivers Version Spring-Data Spring Boot <code>Unified 4.x</code> <code>4.6.0</code> <code>3.0.0.RELEASE</code> <code>2.3.0.RELEASE</code> <code>OSS 3.x</code> <code>3.8.0</code> Setup below table <code>2.2.13.RELEASE</code> <code>DSE 2.x</code> <code>2.3.0</code> <code>3.0.0.RELEASE</code> <code>2.3.0.RELEASE</code> <code>DSE 1.x</code> <code>1.9.0</code> Setup below table <code>2.2</code> <ul> <li>Setup Spring Data 2.2.x (and before) to work with Astra</li> </ul> <p>As stated in the matrix, even the latest Spring Data <code>2.2.13.RELEASE</code> rely on <code>cassandra-driver</code> version <code>3.7.2</code> that where not yet compatible to Astra. To work with Astra you  have to override the <code>cassandra-drivers</code> version as below.</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n&lt;artifactId&gt;spring-boot-starter-data-cassandra&lt;/artifactId&gt;\n&lt;version&gt;2.2.13.RELEASE&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.cassandra&lt;/groupId&gt;\n&lt;artifactId&gt;cassandra-driver-core&lt;/artifactId&gt;\n&lt;version&gt;3.11.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>You can find here a sample project that uses Spring Boot version as old as <code>1.5.4</code>.</p> <ul> <li>Setup Spring Data 2.2 (and before) to work with DataStax Enterprise (DSE)</li> </ul> <p>Before 4.x and the unified drivers you have to use <code>dse-java-driver-core</code> to have access to enterprise features but also the be elligible for the support. To enable it  you need to exclude <code>cassandra-driver-core</code> and import <code>dse-java-driver-core</code> as show below</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n&lt;artifactId&gt;spring-boot-starter-data-cassandra&lt;/artifactId&gt;\n&lt;version&gt;2.2.13.RELEASE&lt;/version&gt;\n&lt;exclusions&gt;\n&lt;exclusion&gt;\n&lt;groupId&gt;com.datastax.cassandra&lt;/groupId&gt;\n&lt;artifactId&gt;cassandra-driver-core&lt;/artifactId&gt;\n&lt;/exclusion&gt;\n&lt;/exclusions&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.dse&lt;/groupId&gt;\n&lt;artifactId&gt;dse-java-driver-core&lt;/artifactId&gt;\n&lt;version&gt;1.9.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"pages/develop/frameworks/spring/#13-rules-and-pitfalls","title":"1.3 Rules and Pitfalls","text":"<ul> <li>Define your own <code>CqlSession</code> bean (spring-data will find it !)</li> </ul> <p><code>Spring Data Cassandra</code> starters provide some dedicated keys in the configuration file <code>application.yaml</code> (<code>spring.data.cassandra.*</code>) but you do not get the complete list of options of the drivers. In the same way some super classes like <code>AbstractCassandraConfiguration</code> are provided where you can specify a few configuration properties but a limited set of keys are available.</p> <ul> <li>Do not use <code>findAll()</code></li> </ul> <p>It can be tempting to use this method to test new repositories as no parameter is required - but this is dangerous. The default paging mechanism is skipped and this method will retrieve every single record of the table. As such, it would perform a full scan of the cluster (pick data for each node) that (1) would be slow and (2) could lead to <code>OutOfMemoryException</code> as Cassandra Tables are expected to store billions of records.</p> <ul> <li>Do not use <code>@AllowFiltering</code></li> </ul> <p>This annotation (some for associated CQL Statement) is limited for the use cases where (1) you provide the partition key AND (2) you know your partition size is fairly small. In 99% of the cases the need of this annotation (or <code>ALLOW FILTERING</code> in the <code>CQL</code>) is a sign of a wrong data model: your primary key is invalid and you need another table to store the same data (or eventually to create a secondary index).</p> <ul> <li>Do not rely (only) on Spring Data to create your schema</li> </ul> <p>SDC provide a configuration key <code>spring.data.cassandra.schema-action: CREATE_IF_NOT_EXISTS</code> that proposes to create the Cassandra Tables based on your annotated beans. It is NOT a good idea. Indeed, it could lead to wrong data model (cf next point) but also it does not give access to fine grained properties like <code>COMPACTION</code> and <code>TTL</code> that might be different in development and production. Let a <code>Cassandra Administrator</code> reviews your DDL scripts and updates them for production.</p> <ul> <li>Data Model First, Entities second</li> </ul> <p>With the <code>JPA</code> (entity, repository) methodology, you are tempting to reuse the same entities and repositories to perform multiple queries against the same table. Most new requests will be not valid as you will not request using the primary key. You can be tempting to create a secondary index or use allow filtering; WRONG !. The good practice is to CREATE ANOTHER TABLE, ANOTHER ENTITY and ANOTHER REPOSITORY - and even if data stored is the same. With Cassandra 1 query = 1 table (mostly).</p> <ul> <li><code>CassandraRepository</code> probably cannot implement it all</li> </ul> <p>With real-life applications you might probably need to go back to the <code>CqlSession</code> and execute custom fine-grained queries (<code>Batches</code>, <code>TTL</code>, <code>LWT</code>...). The interfaces and <code>CassandraRepostiory</code> would not be enough. The class <code>SimpleCassandraRepository</code> is an abstract class (not interface0 you can inherit from that give you access to the <code>CqlSession</code> and execute your queries as you like, it is a good trade off.</p>"},{"location":"pages/develop/frameworks/spring/#2-astra-spring-boot-starter","title":"2. Astra Spring Boot Starter","text":""},{"location":"pages/develop/frameworks/spring/#21-introduction","title":"2.1 Introduction","text":"<p>The Astra Spring Boot Starter will configure both Astra SDK and Spring Data Cassandra to work with AstraDB. Configuration keys are provided in <code>application.yaml</code> like any spring applications with a dedicated prefix <code>astra.*</code>. The starter will initialize any beans you would need (<code>AstraClient</code>, <code>CqlSession</code>, <code>StargateClient</code>) to use every interfaces exposes by Astra. Not all are activated by default though, you want to initialize only what you need.</p> <p></p>"},{"location":"pages/develop/frameworks/spring/#22-project-setup","title":"2.2 Project Setup","text":""},{"location":"pages/develop/frameworks/spring/#prerequisites-astra","title":"Prerequisites [ASTRA]","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul>"},{"location":"pages/develop/frameworks/spring/#prerequisites-development-environment","title":"Prerequisites [Development Environment]","text":"<ul> <li>You should install Java Development Kit (JDK) 8: Use the reference documentation to install a Java Development Kit, Validate your installation with</li> </ul> <pre><code>java --version\n</code></pre> <ul> <li>You should install Apache Maven: Use the reference documentation and validate your installation with</li> </ul> <pre><code>mvn -version\n</code></pre>"},{"location":"pages/develop/frameworks/spring/#setup-project","title":"Setup Project","text":"<ul> <li>Create your project with Spring Initializr. Dependencies needed are <code>web</code> and <code>data-cassandra</code> but we did the work for you if you click the template link</li> </ul> Property Value Property Value groupId <code>com.datastax.tutorial</code> package <code>com.datastax.tutorial</code> artifactId <code>sdk-quickstart-spring</code> description Sample Spring App name <code>sdk-quickstart-spring</code> dependencies <code>Spring Web</code> and <code>Spring Data for Cassandra</code> packaging <code>JAR</code> Java Version <code>8</code> or <code>11</code> <ul> <li> <p>Import the application in your favorite IDE but do not start the application immediately.</p> </li> <li> <p>Add the latest version of starter as a dependency in <code>pom.xml</code>  of <code>astra-spring-boot-starter</code> in the project.</p> </li> </ul> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.astra&lt;/groupId&gt;\n&lt;artifactId&gt;astra-spring-boot-starter&lt;/artifactId&gt;\n&lt;version&gt;0.3.4&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"pages/develop/frameworks/spring/#23-code-and-configuration","title":"2.3 Code and Configuration","text":"<ul> <li>Change the main class with the following code, we are leveraging on the unique <code>AstraClient</code> to interact with multiple interfaces.</li> </ul> <pre><code>@RestController\n@SpringBootApplication\npublic class SdkQuickstartSpringApplication {\npublic static void main(String[] args) {\nSpringApplication.run(SdkQuickstartSpringApplication.class, args);\n}\n// Provided by the Starter\n@Autowired\nprivate AstraClient astraClient;\n// Spring Data using the CqlSession initialized by the starter\n@Autowired\nprivate CassandraTemplate cassandraTemplate;\n@GetMapping(\"/api/devops/organizationid\")\npublic String showOrganizationId() {\nreturn astraClient.apiDevopsOrganizations().organizationId();\n}\n@GetMapping(\"/api/spring-data/datacenter\")\npublic String showDatacenterNameWithSpringData() {\nreturn cassandraTemplate.getCqlOperations()\n.queryForObject(\"SELECT data_center FROM system.local\", String.class);\n}\n@GetMapping(\"/api/cql/datacenter\")\npublic String showDatacenterNameWithSpringData() {\nreturn astraClient.cqlSession()\n.execute(\"SELECT data_center FROM system.local\")\n.one().getString(\"data_center\");\n}\n}\n</code></pre> <p>Rename <code>src/main/resources/application.properties</code> to <code>src/main/resources/application.yaml</code>. This step eases the configuration with hierarchical keys. Populate <code>application.yaml</code> with the following content and replace the values with expected values (how to retrieve the values are explained in the Quickstart Astra</p> <pre><code>astra:\n# Allow usage of devops and Stargate apis\napi:\napplication-token: &lt;your_token&gt;\ndatabase-id: &lt;your_database_id&gt;\ndatabase-region: &lt;your_database_region&gt;\n# Connectivity to Cassandra\ncql:\nenabled: true\ndownload-scb:\nenabled: true\ndriver-config:\nbasic:\nsession-keyspace: &lt;your_keyspace&gt;\n</code></pre> <ul> <li>Start the application</li> </ul> <pre><code>mvn clean install spring-boot:run\n</code></pre> <ul> <li>Access the resources we created</li> <li>Get your Organization ID: <code>http://localhost:8080/api/devops/organizationid</code></li> <li>Get your Datacenter Name (Spring-data): <code>http://localhost:8080/api/spring-data/datacenter</code></li> <li>Get your Datacenter Name (cql): <code>http://localhost:8080/api/cql/datacenter</code></li> </ul> <p></p>"},{"location":"pages/develop/frameworks/spring/#3-spring-data-cassandra","title":"3. Spring Data Cassandra","text":""},{"location":"pages/develop/frameworks/spring/#31-project-setup","title":"3.1 Project Setup","text":""},{"location":"pages/develop/frameworks/spring/#prerequisites-astra_1","title":"Prerequisites [ASTRA]","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Have downloaded your Cloud Secure Bundle</li> </ul>"},{"location":"pages/develop/frameworks/spring/#prerequisites-development-environment_1","title":"Prerequisites [Development Environment]","text":"<ul> <li>You should install Java Development Kit (JDK) 8: Use the reference documentation to install a Java Development Kit, Validate your installation with</li> </ul> <pre><code>java --version\n</code></pre> <ul> <li>You should install Apache Maven: Use the reference documentation and validate your installation with</li> </ul> <pre><code>mvn -version\n</code></pre>"},{"location":"pages/develop/frameworks/spring/#setup-project_1","title":"Setup Project","text":"<ul> <li>Create a Spring Boot application from the initializer and add the <code>spring-boot-starter-data-cassandra</code></li> </ul> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n&lt;artifactId&gt;spring-boot-starter-data-cassandra&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"pages/develop/frameworks/spring/#32-code-and-configuration","title":"3.2 Code and Configuration","text":"<ul> <li>Setup the configuration file <code>application.yaml</code></li> </ul> <pre><code>spring.data.cassandra:\nkeyspace-name: myks\nusername: myClientId\npassword: myClientSecret\nschema-action: CREATE_IF_NOT_EXISTS # for dev purpose\nrequest:\ntimeout: 10s\nconnection:\nconnect-timeout: 10s\ninit-query-timeout: 10s\ndatastax.astra:\n# You must download it before\nsecure-connect-bundle: /tmp/secure-connect-bundle.zip\n</code></pre> <ul> <li>Create a dedicated configuration bean to parse <code>datastax.astra</code></li> </ul> <pre><code>@ConfigurationProperties(prefix = \"datastax.astra\")\npublic class DataStaxAstraProperties {\nprivate File secureConnectBundle;\n// Getter and Setter omitted\n}\n</code></pre> <ul> <li>Define a bean of <code>CqlSessionBuilderCustomizer</code> to add this <code>CloudSecureBundle</code></li> </ul> <pre><code>@SpringBootApplication\n@EnableConfigurationProperties(DataStaxAstraProperties.class)\npublic class SpringDataCassandraApplication {\npublic static void main(String[] args) {\nSpringApplication.run(SpringDataCassandraApplication.class, args);\n}\n@Bean\npublic CqlSessionBuilderCustomizer sessionBuilderCustomizer(DataStaxAstraProperties astraProperties) {\nPath bundle = astraProperties.getSecureConnectBundle().toPath();\nreturn builder -&gt; builder.withCloudSecureConnectBundle(bundle);\n}\n}\n</code></pre>"},{"location":"pages/develop/languages/csharp/","title":"\u2022 CSharp","text":""},{"location":"pages/develop/languages/csharp/#1-overview","title":"1. Overview","text":"<p>Astra provides multiple services such as; Database and Streaming, with multiple Apis and interfaces. There are different frameworks and tools to connect to Astra depending on the Api interface you choose.</p> <p>Pick the interface in the table below to get relevant instructions. In most cases, you will download a working sample. There are standalone examples designed to be as simple as possible. Please note that a Software developement KIT (SDK) is also available for you to reduce the amount of boilerplate code needed to get started. More information is here.</p>"},{"location":"pages/develop/languages/csharp/#2-interfaces-list","title":"2. Interfaces List","text":"Component Interface Description Astra DB Main connection to Cassandra Astra DB CQL exposes as stateless rest resources Astra DB Use Cassandra as a Document DB Astra DB Create tables and use generated CRUD Astra DB CQL exposes through serialized protobuf Astra Streaming Create Producer, Consumers, Subscriptions.. Astra Streaming Administrate your Pulsar cluster Astra Core Manage Databases Astra Core Manage users and roles Astra Core Manage Streaming"},{"location":"pages/develop/languages/csharp/#3-cql","title":"3. CQL","text":""},{"location":"pages/develop/languages/csharp/#31-cassandra-drivers","title":"3.1 Cassandra Drivers","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#32-astra-sdk","title":"3.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#4-stargate-rest-api","title":"4. Stargate REST Api","text":""},{"location":"pages/develop/languages/csharp/#41-axios","title":"4.1 Axios","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#42-astra-sdk","title":"4.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#5-stargate-document-api","title":"5. Stargate Document Api","text":""},{"location":"pages/develop/languages/csharp/#51-axios","title":"5.1 Axios","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#52-astra-sdk","title":"5.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#6-stargate-graphql","title":"6 Stargate GraphQL","text":""},{"location":"pages/develop/languages/csharp/#61-cql-first","title":"6.1 CQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#62-graphql-first","title":"6.2 GraphQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#7-stargate-grpc","title":"7. Stargate gRPC","text":""},{"location":"pages/develop/languages/csharp/#71-stargate-client","title":"7.1 Stargate Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#72-astra-sdk","title":"7.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#8-pulsar-client","title":"8. Pulsar Client","text":""},{"location":"pages/develop/languages/csharp/#81-pulsar-client","title":"8.1 Pulsar Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#82-astra-sdk","title":"8.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/csharp/#9-pulsar-admin","title":"9. Pulsar Admin","text":""},{"location":"pages/develop/languages/csharp/#10-devops-api-database","title":"10 Devops API Database","text":""},{"location":"pages/develop/languages/csharp/#11-devops-api-organization","title":"11 Devops API Organization","text":""},{"location":"pages/develop/languages/csharp/#12-devops-api-streaming","title":"12 Devops API Streaming","text":""},{"location":"pages/develop/languages/go/","title":"\u2022 GoLang","text":""},{"location":"pages/develop/languages/go/#1-overview","title":"1. Overview","text":"<p>Astra provides multiple services such as; Database and Streaming, with multiple Apis and interfaces. There are different frameworks and tools to connect to Astra depending on the Api interface you choose.</p> <p>Pick the interface below to get relevant instructions. In most cases, you will download a working sample. There are standalone examples designed to be as simple as possible. </p> <p>If you have issues or requests about these code samples, please open a ticket under Awesome-Astra.</p> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <ul> <li>You should have an Astra account</li> <li>You should Have an Astra Token with \"Database Administrator\" permissions</li> <li>You should Install the Astra CLI</li> </ul> <p>You will need to have a recent (1.17+) version of Go.  Visit the official download page, and select the appropriate version for your machine architecture.  To verify that Go is installed, run the following command:</p> <pre><code>go version\n</code></pre> <p>You want to have a go version of at least 1.17.</p>"},{"location":"pages/develop/languages/go/#2-interfaces-list","title":"2. Interfaces List","text":"<p>"},{"location":"pages/develop/languages/go/#3-cql","title":"3. CQL","text":""},{"location":"pages/develop/languages/go/#31-the-gocql-astra-driver","title":"3.1 The gocql-astra driver","text":"<p>\u2139\ufe0f Overview</p> <p>These instructions are aimed at helping people connect to Astra DB programmatically using the custom Astra Gocql driver.  </p> <p>Basic driver instructions Basic instructions can be found at the home page for gocql-astra. You can use these instructions, or scroll down to find some ready-made code for you to use.</p> README from gocql-astra <p>This provides a custom <code>gocql.HostDialer</code> that can be used to allow gocql to connect to DataStax Astra. The goal is to provide native support for gocql on Astra.</p> <p>This library relies on the following features of gocql:</p> <ul> <li>The ability to customize connection features via the HostDialer interface</li> <li>Querying system.peers if system.peers_v2 should be used but isn't available </li> </ul> <p>You must use a version of gocql which supports both of these features.  Both features have been merged into master as of version 1.2.1 so any release &gt;= 1.2.1 should work.</p> How to use gocql-astra <p>Using an Astra bundle:</p> <pre><code>cluster, err := gocqlastra.NewClusterFromBundle(\"/path/to/your/bundle.zip\", \"&lt;username&gt;\", \"&lt;password&gt;\", 10 * time.Second)\nif err != nil {\npanic(\"unable to load the bundle\")\n}\nsession, err := gocql.NewSession(*cluster)\n// ...\n</code></pre> <p>Using an Astra token:</p> <pre><code>cluster, err = gocqlastra.NewClusterFromURL(gocqlastra.AstraAPIURL, \"&lt;astra-database-id&gt;\", \"&lt;astra-token&gt;\", 10 * time.Second)\nif err != nil {\npanic(\"unable to load the bundle\")\n}\nsession, err := gocql.NewSession(*cluster)\n// ...\n</code></pre> <p>Environment variable version</p> <p>To use this library with environment variables, you can follow these steps.</p> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <p>To get started you need to Install the Astra CLI. Create a directory you want to use and change into that directory. </p> <p>Using the token you created with the \"Database Administrator\" permission, use the CLI to setup your environment.</p> <pre><code>astra setup\n</code></pre> <p>Create a database and keyspace to work with.</p> <pre><code>astra db create workshops -k gotest --if-not-exist\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <p>The best way to use this sample is to clone it from the repository.</p> <p>Clone the  repository and change into the 'gocql-astra' directory in that repository.</p> <pre><code>git clone https://github.com/awesome-astra/go-sample-code\ncd go-sample-code/gocql-astra/envvars\n</code></pre> <p>Create .env with astra CLI</p> <pre><code>astra db create-dotenv workshops -k gotest \n</code></pre> <p>Build the environment variable example.</p> <pre><code>go build envvars.go\n</code></pre> <p>Run the code in your environment.</p> <pre><code>./envvars\n</code></pre> Sample code details <p>\"If you want to use this sample without cloning the repository, you will need to have the following:\"</p> <ul> <li>github.com/datastax/astra-client-go/v2 v2.2.9</li> <li>github.com/datastax/cql-proxy v0.1.3</li> </ul> <pre><code>package main\n\nimport (\n    \"fmt\"\n    \"log\"\n    \"os\"\n    \"time\"\n\n    gocqlastra \"github.com/datastax/gocql-astra\"\n    \"github.com/gocql/gocql\"\n    \"github.com/joho/godotenv\"\n)\n\nfunc main() {\n\n    var err error\n\n    err = godotenv.Load()\n\n    var cluster *gocql.ClusterConfig\n    if len(os.Getenv(\"ASTRA_DB_SECURE_BUNDLE_PATH\")) &gt; 0 {\n        cluster, err = gocqlastra.NewClusterFromBundle(os.Getenv(\"ASTRA_DB_SECURE_BUNDLE_PATH\"), \"token\", os.Getenv(\"ASTRA_DB_APPLICATION_TOKEN\"), 10*time.Second)\n        if err != nil {\n            err = fmt.Errorf(\"unable to open bundle %s from file: %v\", os.Getenv(\"ASTRA_DB_SECURE_BUNDLE_PATH\"), err)\n            panic(err)\n        }\n    } else if len(os.Getenv(\"ASTRA_DB_APPLICATION_TOKEN\")) &gt; 0 {\n        if len(os.Getenv(\"ASTRA_DB_ID\")) == 0 {\n            panic(\"database ID is required when using a token\")\n        }\n        cluster, err = gocqlastra.NewClusterFromURL(\"https://api.astra.datastax.com\", os.Getenv(\"ASTRA_DB_ID\"), os.Getenv(\"ASTRA_DB_APPLICATION_TOKEN\"), 10*time.Second)\n        fmt.Println(cluster)\n        if err != nil {\n            fmt.Errorf(\"unable to load cluster %s from astra: %v\", os.Getenv(\"ASTRA_DB_APPLICATION_TOKEN\"), err)\n        }\n    } else {\n        fmt.Errorf(\"must provide either bundle path or token\")\n    }\n\n    start := time.Now()\n    session, err := gocql.NewSession(*cluster)\n    elapsed := time.Now().Sub(start)\n    if err != nil {\n        log.Fatalf(\"unable to connect session: %v\", err)\n    }\n\n    fmt.Println(\"Making the query now\")\n\n    iter := session.Query(\"SELECT release_version FROM system.local\").Iter()\n\n    var version string\n    for iter.Scan(&amp;version) {\n        fmt.Println(version)\n    }\n\n    if err = iter.Close(); err != nil {\n        log.Printf(\"error running query: %v\", err)\n    }\n\n    fmt.Printf(\"Connection process took %s\\n\", elapsed)\n}\n</code></pre> <p>To get this to work, you will need to pull the dependencies:</p> <pre><code>go mod init gocql\ngo mod tidy\ngo build envvars.go\n./envvars\n</code></pre>"},{"location":"pages/develop/languages/go/#issues","title":"Issues","text":"<ul> <li>Need to verify that topology/status events correctly update the driver when using Astra.</li> <li>This seems to work correctly and was tested by removing Astra coordinators</li> <li>There is a bit of weirdness around contact points. I'm just using a place holder <code>\"0.0.0.0\"</code> (some valid IP address)  then the <code>HostDialer</code> provides a host ID from the metadata service when the host ID in the <code>HostInfo</code> is empty.</li> </ul>"},{"location":"pages/develop/languages/go/#32-other-astra-cql-interfaces","title":"3.2 Other Astra CQL Interfaces","text":"<ul> <li>cql-proxy This proxy sidecar is not Go-specific, but it works with the existing Go drivers to provide an interface into Astra.</li> </ul>"},{"location":"pages/develop/languages/go/#4-the-stargate-api-signing-library","title":"4. The Stargate API Signing Library","text":""},{"location":"pages/develop/languages/go/#41-using-the-stargate-api-signing-library","title":"4.1 Using the Stargate API Signing Library","text":"<p>\u2139\ufe0f Overview</p> <p>These instructions are aimed at helping people connect to Astra DB programmatically using Stargate's API interface</p> <p>\ud83d\udda5\ufe0f Sample Code</p> <p>To use the signing library, you simply include it in your code and then create a client for making calls.</p> Sample go code for Stargate APIs <pre><code>package main\n\nimport (\n    \"bytes\"\n    \"fmt\"\n    \"os\"\n\n    \"github.com/awesome-astra/astra_stargate_go\"\n\n    \"github.com/joho/godotenv\"\n)\n\nfunc main() {\n    err := godotenv.Load()\n    if len(os.Getenv(\"ASTRA_DB_APPLICATION_TOKEN\")) == 0 {\n        fmt.Println(fmt.Errorf(\"please set your environment variables or use 'astra db create-dotenv' to create a .env file\"))\n        return\n    }\n\n    client := astra_stargate_go.NewBasicAuthClient(os.Getenv(\"ASTRA_DB_APPLICATION_TOKEN\"), os.Getenv(\"ASTRA_DB_ID\"), os.Getenv(\"ASTRA_DB_REGION\"))\n    if err != nil {\n        fmt.Println(err)\n    }\n\n    // Basic REST Query\n    fmt.Println(\"Basic REST query for keyspaces\")\n    responsebody, err := client.APIGet(\"/api/rest/v1/keyspaces\")\n    if err != nil {\n        fmt.Println(err)\n    }\n    fmt.Println(responsebody)\n\n    // Basic Document Query\n    fmt.Println(\"Create 'library' collection in the library keyspace\")\n    jsonStr := []byte(`{\"name\":\"library\"}`)\n    responsebody, err = client.APIPost(\"/api/rest/v2/namespaces/library/collections\", bytes.NewBuffer(jsonStr))\n    if err != nil {\n        fmt.Println(err)\n    }\n    fmt.Println(responsebody)\n\n    // Basic GraphQL query\n    query := \"{\\\"query\\\":\\\"query GetTables {keyspace(name: \\\\\\\"library\\\\\\\") {name}}\\\"}\"\n    queryBody := []byte(query)\n    bodyReader := bytes.NewBuffer(queryBody)\n\n    if err != nil {\n        panic(err)\n    }\n    req, err := client.APIPost(\"/api/graphql-schema\", bodyReader)\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(req)\n\n}\n</code></pre>"},{"location":"pages/develop/languages/go/#5-stargate-rest-api","title":"5 Stargate REST API","text":"<p>While the basic code is shown above, you can interact with a more extensive REST example by following these instructions.</p> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <p>To get started you need to Install the Astra CLI. Create a directory you want to use and change into that directory. </p> <p>Clone the repository into your directory, then change into the astra_stargate_rest directory.</p> <pre><code>git clone https://github.com/awesome-astra/go-sample-code\ncd astra_stargate_rest\n</code></pre> <p>Using the token you created with the \"Database Administrator\" permission, use the CLI to setup your environment.</p> <pre><code>astra setup\n</code></pre> <p>Create a database and keyspace to work with.</p> <pre><code>astra db create workshops -k library --if-not-exist\n</code></pre> <p>Create .env with astra CLI</p> <pre><code>astra db create-dotenv workshops -k library \n</code></pre> <p>Run the code in your environment.</p> <pre><code>go build astra_stargate_example.go\n./astra_stargate_example\n</code></pre>"},{"location":"pages/develop/languages/go/#6-stargate-graphql-api","title":"6 Stargate GraphQL API","text":"<p>While the basic code is shown above, you can interact with a more extensive REST example by following these instructions.</p> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <p>To get started you need to Install the Astra CLI. Create a directory you want to use and change into that directory. </p> <p>Clone the repository into your directory, then change into the astra_stargate_rest directory.</p> <pre><code>git clone https://github.com/awesome-astra/go-sample-code\ncd astra_stargate_graphql\n</code></pre> <p>Using the token you created with the \"Database Administrator\" permission, use the CLI to setup your environment.</p> <pre><code>astra setup\n</code></pre> <p>Create a database and keyspace to work with.</p> <pre><code>astra db create workshops -k library --if-not-exist\n</code></pre> <p>Create .env with astra CLI</p> <pre><code>astra db create-dotenv workshops -k library \n</code></pre> <p>Run the code in your environment.</p> <pre><code>go build astra_stargate_graphql.go\n./astra_stargate_graphql\n</code></pre>"},{"location":"pages/develop/languages/go/#7-stargate-document-api","title":"7 Stargate Document API","text":"<p>While the basic code is shown above, you can interact with a more extensive REST example by following these instructions.</p> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <p>To get started you need to Install the Astra CLI. Create a directory you want to use and change into that directory. </p> <p>Clone the repository into your directory, then change into the astra_stargate_rest directory.</p> <pre><code>git clone https://github.com/awesome-astra/go-sample-code\ncd astra_stargate_document\n</code></pre> <p>Using the token you created with the \"Database Administrator\" permission, use the CLI to setup your environment.</p> <pre><code>astra setup\n</code></pre> <p>Create a database and keyspace to work with.</p> <pre><code>astra db create workshops -k library --if-not-exist\n</code></pre> <p>Create .env with astra CLI</p> <pre><code>astra db create-dotenv workshops -k library \n</code></pre> <p>Run the code in your environment.</p> <pre><code>go build astra_stargate_document.go\n./astra_stargate_document\n</code></pre>"},{"location":"pages/develop/languages/go/#8-cql-api-grpc","title":"8. CQL API GRPC","text":""},{"location":"pages/develop/languages/go/#81-the-gocql-grpc-cassandra-astra-driver","title":"8.1 The Gocql GRPC Cassandra Astra Driver","text":"<p>\u2139\ufe0f Overview</p> <p>These instructions are aimed at helping people connect to Astra DB programmatically using the Astra specific Golang driver  </p> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <p>To get started you need to Install the Astra CLI. Create a directory you want to use and change into that directory. </p> <p>Using the token you created with the \"Database Administrator\" permission, use the CLI to setup your environment.</p> <pre><code>astra setup\n</code></pre> <p>Create a database and keyspace to work with.</p> <pre><code>astra db create workshops -k library --if-not-exist\n</code></pre> <p>Create .env with astra CLI</p> <pre><code>astra db create-dotenv workshops -k library \n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <p>Clone the repository into your directory, then change into the astra-gprc directory.</p> <pre><code>git clone https://github.com/awesome-astra/go-sample-code\ncd astra-grpc\n</code></pre> <p>Run the code in your environment.</p> <pre><code>go build AstraGRPCQuickStart.go\n./AstraGRPCQuickStart\n</code></pre>"},{"location":"pages/develop/languages/java/","title":"\u2022 Java","text":"<p>Astra offers different Apis. Select the API you want to use below to get documentation.</p> <p> </p>"},{"location":"pages/develop/languages/java/#1-pre-requisites","title":"1. Pre-requisites","text":"<ul> <li>Java Development Kit (JDK) 8+</li> </ul> <p>Use reference documentation to install a Java Development Kit and validate your installation with</p> <pre><code>java --version\n</code></pre> <ul> <li>Apache Maven (3.8+)</li> </ul> <p>The different samples and tutorials have been designed with <code>Apache Maven</code>.Use the reference documentation top install maven validate your installation with </p> <pre><code>mvn -version\n</code></pre> <ul> <li>Datastax Astra</li> </ul> Setup Actions <ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> </ul>"},{"location":"pages/develop/languages/java/#2-cassandra-drivers","title":"2. Cassandra Drivers","text":""},{"location":"pages/develop/languages/java/#21-connectivity","title":"2.1 Connectivity","text":"<p>To access Datastax Astra with Java drivers 2 assets are needed:</p> <ul> <li> <p>An Astra Token stands as your credentials (<code>clientId / clientSecret</code>). It holds the different permissions. The scope of a token is the whole organization but permissions can be edited to limit usage to a single database To create one with the expected properties use those instructions</p> </li> <li> <p>A Secure Connect Bundle contains the certificates and endpoints informations to open a mTLS connection. Often mentionned as <code>scb</code> its scope is a database AND a region. If your database is deployed on multiple regions you will have to download the bundle for each one and initiate the connection accordingly. Instructions to download Secure Connect Bundle are here</p> </li> </ul> <p></p>"},{"location":"pages/develop/languages/java/#22-drivers-4x","title":"2.2 Drivers 4.x","text":"4.x is the recommended version for the drivers <p>The official documentation for the drivers can be found here</p> <p>Using the DataStax Java Driver to connect to a DataStax Astra database is almost identical to using the driver to connect to any normal Apache Cassandra\u00ae database. The only differences are in how the driver is configured in an application and that you will need to obtain a secure connect bundle.</p>"},{"location":"pages/develop/languages/java/#project-dependencies","title":"Project Dependencies","text":"Import dependencies in your <code>pom.xml</code> <ul> <li> <p>Any version <code>4.x</code> should be compatible with Astra.</p> </li> <li> <p>Update your <code>pom.xml</code> file with the latest version of the 4.x libraries: </p> </li> </ul> <pre><code>&lt;!-- (REQUIRED) --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.oss&lt;/groupId&gt;\n&lt;artifactId&gt;java-driver-core&lt;/artifactId&gt;\n&lt;version&gt;${latest4x}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;!-- OPTIONAL --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.oss&lt;/groupId&gt;\n&lt;artifactId&gt;java-driver-query-builder&lt;/artifactId&gt;\n&lt;version&gt;${latest4x}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.oss&lt;/groupId&gt;\n&lt;artifactId&gt;java-driver-mapper-runtime&lt;/artifactId&gt;\n&lt;version&gt;${latest4x}&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"pages/develop/languages/java/#quickstart","title":"QuickStart","text":"Sample Connection Code <ul> <li>Create an <code>AstraDriver4x.java</code> class with the following code</li> </ul> <pre><code>import java.nio.file.Paths;\nimport com.datastax.oss.driver.api.core.CqlSession;\npublic class AstraDriver4x {\npublic static void main(String[] args) {\ntry (CqlSession cqlSession = CqlSession.builder()\n.withCloudSecureConnectBundle(Paths.get(\"/path/to/scb.zip\"))\n.withAuthCredentials(\"user_name\",\"password\")\n.withKeyspace(\"keyspace_name\")\n.build()) {\nSystem.out.println(\"Hello keyspace {} !\" + cqlSession.getKeyspace().get());\n}\n}\n}\n</code></pre> <p> \u00a0Download This sample code   </p> <p>What you need to know</p> <p>\ud83d\udce6 About Secure Connect Bundle</p> <ul> <li>The path to the secure connect bundle for your Astra database is specified with <code>withCloudSecureConnectBundle()</code>, it accepts <code>String</code>, <code>File</code> and <code>URL</code>. </li> <li>An SSL connection will be established automatically. Manual SSL configuration is not allowed, any settings in the driver configuration (<code>advanced.ssl-engine-factory</code>) will be ignored.</li> <li>The secure connect bundle contains all of the necessary contact information. Specifying contact points manually is not allowed, and will result in an error</li> </ul> <p>\u2699\ufe0f About Parameters</p> <ul> <li>The authentication credentials must be specified separately with <code>withAuthCredentials()</code>, and match the username and password that were configured when creating the Astra database.</li> <li> <p>The keyspace is here required and provided with <code>.withKeyspace()</code></p> </li> <li> <p>if the driver configuration does not specify an explicit consistency level, it will default to <code>LOCAL_QUORUM</code> (instead of LOCAL_ONE when connecting to a normal Cassandra database).</p> </li> <li> <p>Extra configuration can be provided in <code>application.conf</code> file. </p> </li> </ul> <p>\ud83d\udd0c About <code>CqlSession</code></p> <ul> <li> <p>All operations of the drivers can be execute from this object.</p> </li> <li> <p>It a stateful, <code>autocloseable</code>, object, and must be a singleton in your application.</p> </li> </ul>"},{"location":"pages/develop/languages/java/#file-based-configuration","title":"File-based configuration","text":"<p>Alternatively, or complementary the connection information can be specified in the driver\u2019s configuration file (<code>application.conf</code>). Merge the following options with any content already present. All keys available in the file are available in reference.conf</p> Recommended <code>application.conf</code> <pre><code>datastax-java-driver {\n  basic {\n    request {\n        timeout     = 10 seconds\n      consistency = LOCAL_QUORUM\n    }\n    # change this to match the target keyspace\n    session-keyspace = keyspace_name\n    cloud {\n      secure-connect-bundle = /path/to/secure-connect-database_name.zip\n    }\n  }\n  advanced {\n    auth-provider {\n      class = PlainTextAuthProvider\n      username = user_name \n      password = password\n    }\n    connection {\n      init-query-timeout = 10 seconds\n      set-keyspace-timeout = 10 seconds\n      pool {\n        local-size = 1\n      }\n    }\n    reconnection-policy {\n      class = ExponentialReconnectionPolicy\n      base-delay = 5 seconds\n      max-delay = 60 seconds\n    }\n    control-connection.timeout = 10 seconds\n  }\n}\n</code></pre> <p>With the file in the classpaht the previous code is updated as the following:</p> <pre><code>import java.nio.file.Paths;\nimport com.datastax.oss.driver.api.core.CqlSession;\npublic class AstraDriver4x {\npublic static void main(String[] args) {\ntry (CqlSession cqlSession = CqlSession.builder().build()) {\nSystem.out.println(\"Hello keyspace {} !\" + cqlSession.getKeyspace().get());\n}\n}\n}\n</code></pre> <p>What you need to know</p> <ul> <li>The configuration file <code>application.conf</code> is automatically loaded when present on the classpath. It can be used in any java-based application with no difference (spring, quarkus...)</li> <li><code>dc-failover</code> is NOT available as a different secure connect bundles are required for different regions (1 region = 1 dc in Astra)</li> </ul>"},{"location":"pages/develop/languages/java/#sample-code-library","title":"Sample Code Library","text":"Classname Description ShowMetaData4x Connect to Astra and show keyspaces and metadata from the CqlSession CreateSchema4x Create schema with different <code>table</code> and <code>type</code> (UDT) if they do not exist in keyspace DropSchema4x Remove assets of the schema,<code>table</code> and <code>type</code> (UDT) if they exist in target keyspace ConfigurationFile4x Setup the driver to use customize configuration file and not default <code>application.conf</code> ProgrammaticConfiguration Setup the driver in a programmatic way and not reading <code>application.conf</code> Getting Started First touch with executing queries Simple4x Read, update, insert, delete operations using <code>QueryBuilder</code> Paging4x Illustrating FetchSize and how to retrieve page by page Batches4x Group statements within batches ListSetMapUdt4x Advanced types insertions with <code>list</code>, <code>set</code>, <code>map</code> but also <code>User Defined Type</code> Json4x Work with columns or full record with <code>JSON</code> Async4x Sample operations as Simple in <code>Asynchronous</code> way ObjectMapping4x Map table record to Java POJO at driver level Counter4x Working with <code>counters</code> increment/decrement Lwt4x Working for Lightweight transactions read-before-write BlobAndCodec4x Working with <code>BLOB</code> and binary data but also how to create your own <code>CustomCodec</code> CloudAstra4x Working with <code>BLOB</code> and binary data but also how to create your own <code>CustomCodec</code> Reactive4x Working with the Reactive API introduce in driver 4.x"},{"location":"pages/develop/languages/java/#sample-projects-gallery","title":"Sample Projects Gallery","text":"Classname Description Spring PetClinic in Reactive Implementation of the <code>PetClinic</code> spring application using the reactive part of the drivers. Other frameworks used are <code>spring-data-cassandra</code> and <code>spring-boot</code> Quarkus Todo application Leveraging Quarkus extension to build a quarkus application Better Reads A clone of Good reads using Spring Boot and Spring Data Cassandra E-Commerce A full fledge e-commerce portal with catalog, shopping cart, payment and order processing with Spring Boot Build Microservices Microservices with Spring Devoxx 2022 3h of deep dive on how to build java applications with Spring, Quarkus and Micronaut Java Native Build todo application in Java Native with Spring, Quarkus and Micronaut Stargate TV Show Reproduce the wheel or Stargate TV Show with destination in Astra Spring Data Cassandra Deep dive with Spring data cassandra"},{"location":"pages/develop/languages/java/#32-drivers-3x","title":"3.2 Drivers 3.x","text":"<p>Version 3.x is still maintained but not recommended version. It will not get evolutions in the future</p>"},{"location":"pages/develop/languages/java/#project-dependencies_1","title":"Project Dependencies","text":"Import dependencies in your <code>pom.xml</code> <ul> <li>Version 3.8+ or more is required to connect to Astra.</li> <li>Update your <code>pom.xml</code> file with the latest version of the 3.x libraries: </li> </ul> <pre><code>&lt;!-- Mandatory --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.cassandra&lt;/groupId&gt;\n&lt;artifactId&gt;cassandra-driver-core&lt;/artifactId&gt;\n&lt;version&gt;${latest3x}&lt;/version&gt; &lt;/dependency&gt;\n&lt;!-- Optional, Used for object mapping--&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.cassandra&lt;/groupId&gt;\n&lt;artifactId&gt;cassandra-driver-mapping&lt;/artifactId&gt;\n&lt;version&gt;${latest3x}&lt;/version&gt; &lt;/dependency&gt;\n&lt;!-- Optional, Used for conversion ad-hoc--&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.cassandra&lt;/groupId&gt;\n&lt;artifactId&gt;cassandra-driver-extra&lt;/artifactId&gt;\n&lt;version&gt;${latest3x}&lt;/version&gt; &lt;/dependency&gt;\n</code></pre>"},{"location":"pages/develop/languages/java/#quickstart_1","title":"QuickStart","text":"Example Code <pre><code>import java.io.File;\nimport com.datastax.driver.core.Cluster;\nimport com.datastax.driver.core.Session;\npublic class AstraDriver3x {\npublic static void main(String[] args) {\ntry(Cluster cluster = Cluster.builder()\n.withCloudSecureConnectBundle(new File(\"/path/to/scb.zip\"))\n.withCredentials(\"clientId\", \"clientSecret\")\n.build() ) {\nSession session = cluster.connect(\"keyspace\");\nSystem.out.println(\"Hello keyspace \" + session.getLoggedKeyspace());\n}\n}\n}\n</code></pre> <p> \u00a0Download Driver 3x Sample   </p> <p>What you need to know</p> <ul> <li>If you work with previous versions of the driver (lower than <code>3.8</code> ) the support of Astra is not Ad-hoc it is recommended to migrate. Yet it is possible to use the <code>SSL</code> options. Documentation and sample codes can be found here. </li> </ul>"},{"location":"pages/develop/languages/java/#sample-code-library_1","title":"Sample Code Library","text":"Classname Description GettingStarted3x First touch with executing queries Simple3x Read, update, insert, delete operations using <code>QueryBuilder</code> ShowMetaData3x Connect to cluster then show keyspaces and metadata CreateKeyspace3x Create the <code>killrvideo</code> keyspace using <code>SchemaBuilder</code> if not exist CreateSchema3x Create <code>table</code> and <code>type</code> in <code>killrvideo</code> keyspace if they don't exist DropKeyspace3x Drop the <code>killrvideo</code> keyspace if existis using  <code>SchemaBuilder</code> DropSchema3x Drop all  <code>table</code> and <code>type</code> in <code>killrvideo</code> keyspace if they exist Paging3x Illustrating FetchSize and how to retrieve page by page Batches3x Group statements within batches ListSetMapUdt3x Advanced types insertions with <code>list</code>, <code>set</code>, <code>map</code> but also <code>User Defined Type</code> Json3x Work with columns or full record with <code>JSON</code> Async3x Sample operations as Simple in <code>Asynchronous</code> way ObjectMapping3x Map table record to Java POJO at driver level Counter3x Working with <code>counters</code> increment/decrement Lwt3x Working for Lightweight transactions read-before-write BlobAndCodec3x Working with <code>BLOB</code> and binary data but also how to create your own <code>CustomCodec</code> CloudAstra3x Working with <code>BLOB</code> and binary data but also how to create your own <code>CustomCodec</code>"},{"location":"pages/develop/languages/java/#33-astra-sdk","title":"3.3 Astra SDK","text":"<p>The <code>Astra SDK</code> sets up the connection to work with the AstraDB cloud-based service. You will work with the class <code>AstraClient</code>, Reference documentation.</p> Import dependencies in your <code>pom.xml</code> <ul> <li>Update your <code>pom.xml</code> file with the latest version of the SDK </li> </ul> <pre><code>&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.astra&lt;/groupId&gt;\n&lt;artifactId&gt;astra-sdk&lt;/artifactId&gt;\n&lt;version&gt;${latestSDK}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> Standalone Code <pre><code>import java.io.File;\nimport com.datastax.astra.sdk.AstraClient;\nimport com.datastax.oss.driver.api.core.CqlSession;\npublic class AstraSdk {\n// Define inputs\nstatic final String ASTRA_DB_TOKEN  = \"&lt;provide_a_clientSecret&gt;\";\nstatic final String ASTRA_DB_ID     = \"&lt;provide_your_database_id&gt;\";\nstatic final String ASTRA_DB_REGION = \"&lt;provide_your_database_region&gt;\";\nstatic final String ASTRA_KEYSPACE  = \"&lt;provide_your_keyspace&gt;\";\n// Init Astra Client\npublic static void main(String[] args) {\ntry(AstraClient cli = AstraClient.builder()\n.withToken(ASTRA_DB_TOKEN)\n.withDatabaseId(ASTRA_DB_ID)\n.withDatabaseRegion(ASTRA_DB_REGION)\n.withCqlKeyspace(ASTRA_DB_KEYSPACE)\n.enableCql()\n.build()) {\nSystem.out.println(\"CqlVersion:\" + astraClient.cqlSession()\n.execute(\"SELECT cql_version from system.local\")\n.one().getString(\"cql_version\"));\n}\n}\n}\n</code></pre> Resources <p> \u00a0Download SDK Sample   </p> <ul> <li>To get the full fledged information regarding the SDK check the github repository</li> </ul>"},{"location":"pages/develop/languages/java/#4-api-rest","title":"4. Api Rest","text":"<p>\u26a0\ufe0f We recommend to use version <code>V2</code> (with V2 in the URL) as it covers more features and the V1 would be deprecated sooner.</p> <p></p> <p>To know more regarding this interface specially you can have a look to dedicated section of the wiki or reference Stargate Rest Api Quick Start Guide.</p>"},{"location":"pages/develop/languages/java/#41-http-client","title":"4.1 <code>Http Client</code>","text":"<p>You need an <code>HTTP Client</code> to use the Rest API. There are a lot of clients in the Java languages like HttpURLConnection, HttpClient introduced in Java 11, Apache HTTPClient, OkHttpClient, Jetty HttpClient. A comparison is provided is this blogpost to make your choice. In this tutorial, we will use the <code>Apache HttpClient</code>, which is included in the SDK. You should adapt the code depending on the framework you have chosen.</p> Import dependencies in your <code>pom.xml</code> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;org.apache.httpcomponents.client5&lt;/groupId&gt;\n&lt;artifactId&gt;httpclient5&lt;/artifactId&gt;\n&lt;version&gt;5.1.3&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> Standalone Code <pre><code>import java.io.File;\npublic class AstraRestApiHttpClient {\nstatic final String ASTRA_TOKEN       = \"&lt;change_with_your_token&gt;\";\nstatic final String ASTRA_DB_ID       = \"&lt;change_with_your_database_identifier&gt;\";\nstatic final String ASTRA_DB_REGION   = \"&lt;change_with_your_database_region&gt;\";\nstatic final String ASTRA_DB_KEYSPACE = \"&lt;change_with_your_keyspace&gt;\";\npublic static void main(String[] args) throws Exception {\nString apiRestEndpoint = new StringBuilder(\"https://\")\n.append(ASTRA_DB_ID).append(\"-\")\n.append(ASTRA_DB_REGION)\n.append(\".apps.astra.datastax.com/api/rest\")\n.toString();\nSystem.out.println(\"Rest Endpoint is \" + apiRestEndpoint);\ntry (CloseableHttpClient httpClient = HttpClients.createDefault()) {\n// Work with HTTP CLIENT\nlistKeyspaces(httpClient, apiRestEndpoint);\ncreateTable(httpClient, apiRestEndpoint);\n}\n}\n}\n</code></pre> <ul> <li>Operations</li> </ul> List Keyspaces <p></p> <ul> <li>Code</li> </ul> <pre><code>private static void listKeyspaces(CloseableHttpClient httpClient, String apiRestEndpoint)\nthrows Exception {\n// Build Request\nHttpGet listKeyspacesReq = new HttpGet(apiRestEndpoint + \"/v2/schemas/keyspaces\");\nlistKeyspacesReq.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(listKeyspacesReq)) {\nif (200 == res.getCode()) {\nlogger.info(\"[OK] Keyspaces list retrieved\");\nlogger.info(\"Returned message: {}\", EntityUtils.toString(res.getEntity()));\n}\n</code></pre> Creating a table <p></p> <ul> <li>Sample <code>JSON</code> payload <code>createTableJson</code>.</li> </ul> <pre><code>{\n\"name\": \"users\",\n\"columnDefinitions\": [\n{  \"name\": \"firstname\", \"typeDefinition\": \"text\" },\n{  \"name\": \"lastname\",  \"typeDefinition\": \"text\" },\n{  \"name\": \"email\",     \"typeDefinition\": \"text\" },\n{  \"name\": \"color\",     \"typeDefinition\": \"text\" }\n],\n\"primaryKey\": { \"partitionKey\": [\"firstname\"],\n\"clusteringKey\": [\"lastname\"]\n},\n\"tableOptions\": {\n\"defaultTimeToLive\": 0,\n\"clusteringExpression\": [{ \"column\": \"lastname\", \"order\": \"ASC\" }]\n}\n}\n</code></pre> <ul> <li>Creating the http request using that payload</li> </ul> <pre><code>private static void createTable(CloseableHttpClient httpClient, String apiRestEndpoint)\nthrows Exception {\nHttpPost createTableReq = new HttpPost(apiRestEndpoint\n+ \"/v2/schemas/keyspaces/\" + ASTRA_DB_KEYSPACE + \"/tables\");\ncreateTableReq.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\nString createTableJson = \"{...JSON.....}\";\ncreateTableReq.setEntity(new StringEntity(createTableJson, ContentType.APPLICATION_JSON));\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(createTableReq)) {\nif (201 == res.getCode()) {\nlogger.info(\"[OK] Table Created (if needed)\");\nlogger.info(\"Returned message: {}\", EntityUtils.toString(res.getEntity()));\n}\n}\n}\n</code></pre> Insert a new Row <p></p> <pre><code>private static void insertRow(CloseableHttpClient httpClient, String apiRestEndpoint)\nthrows Exception {\nHttpPost insertCedrick = new HttpPost(apiRestEndpoint + \"/v2/keyspaces/\"\n+ ASTRA_DB_KEYSPACE + \"/users\" );\ninsertCedrick.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\ninsertCedrick.setEntity(new StringEntity(\"{\"\n+ \" \\\"firstname\\\": \\\"Cedrick\\\",\"\n+ \" \\\"lastname\\\" : \\\"Lunven\\\",\"\n+ \" \\\"email\\\"    : \\\"c.lunven@gmail.com\\\",\"\n+ \" \\\"color\\\"    : \\\"blue\\\" }\", ContentType.APPLICATION_JSON));\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(insertCedrick)) {\nif (201 == res.getCode()) {\nlogger.info(\"[OK] Row inserted\");\nlogger.info(\"Returned message: {}\", EntityUtils.toString(res.getEntity()));\n}\n}\n}\n</code></pre> Retrieve a row <p></p> <pre><code>private static void retrieveRow(CloseableHttpClient httpClient, String apiRestEndpoint)\nthrows Exception {\n// Build Request\nHttpGet rowReq = new HttpGet(apiRestEndpoint + \"/v2/keyspaces/\"\n+ ASTRA_DB_KEYSPACE + \"/users/Cedrick/Lunven\" );\nrowReq.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(rowReq)) {\nif (200 == res.getCode()) {\nString payload =  EntityUtils.toString(res.getEntity());\nlogger.info(\"[OK] Row retrieved\");\nlogger.info(\"Row retrieved : {}\", payload);\n}\n}\n}\n</code></pre> Resources <p> \u00a0Download REST HTTP CLIENT   </p> <ul> <li>To get the full fledged information regarding the SDK check the github repository</li> </ul>"},{"location":"pages/develop/languages/java/#42-astra-sdk","title":"4.2 <code>Astra SDK</code>","text":"<p>The <code>Astra SDK</code> sets up the connection to work with the AstraDB cloud-based service. You will work with the class <code>AstraClient</code>, Reference documentation.</p> Import dependencies in your <code>pom.xml</code> <ul> <li>Update your <code>pom.xml</code> file with the latest version of the SDK </li> </ul> <pre><code>&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.astra&lt;/groupId&gt;\n&lt;artifactId&gt;astra-sdk&lt;/artifactId&gt;\n&lt;version&gt;${latestSDK}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> Standalone Code <pre><code>import java.io.File;\nimport com.datastax.astra.sdk.AstraClient;\nimport com.datastax.oss.driver.api.core.CqlSession;\npublic class AstraSdk {\n// Define inputs\nstatic final String ASTRA_DB_TOKEN  = \"&lt;provide_a_clientSecret&gt;\";\nstatic final String ASTRA_DB_ID     = \"&lt;provide_your_database_id&gt;\";\nstatic final String ASTRA_DB_REGION = \"&lt;provide_your_database_region&gt;\";\nstatic final String ASTRA_KEYSPACE  = \"&lt;provide_your_keyspace&gt;\";\n// Init Astra Client\npublic static void main(String[] args) {\ntry(AstraClient cli = AstraClient.builder()\n.withToken(ASTRA_DB_TOKEN)\n.withDatabaseId(ASTRA_DB_ID)\n.withDatabaseRegion(ASTRA_DB_REGION)\n.withCqlKeyspace(ASTRA_DB_KEYSPACE)\n.build()) {\nSystem.out.println(\"+ List of Keyspaces: \" + astraClient.apiStargateData()\n.keyspaceNames()\n.collect(Collectors.toList()));\n}\n}\n}\n</code></pre> Resources <p> \u00a0Download SDK Sample   </p> <ul> <li>To get the full fledged information regarding the SDK check the github repository</li> </ul>"},{"location":"pages/develop/languages/java/#5-api-document","title":"5. Api Document","text":"<p>The Document API is an HTTP REST API and part of the open source Stargate.io. The idea is to provide an abstraction on top of Apache Cassandra\u2122 to allow document-oriented access patterns. To get familiar with it you can access documentation and sandbox here</p>"},{"location":"pages/develop/languages/java/#51-http-client","title":"5.1 <code>Http Client</code>","text":"Import dependencies in your <code>pom.xml</code> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;org.apache.httpcomponents.client5&lt;/groupId&gt;\n&lt;artifactId&gt;httpclient5&lt;/artifactId&gt;\n&lt;version&gt;5.1.3&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> Standalone Code <pre><code>static final String ASTRA_TOKEN       = \"change_me\";\nstatic final String ASTRA_DB_ID       = \"change_me\";\nstatic final String ASTRA_DB_REGION   = \"change_me\";\nstatic final String ASTRA_DB_KEYSPACE = \"change_me\";\nstatic  Logger logger = LoggerFactory.getLogger(AstraDocApiHttpClient.class);\npublic static void main(String[] args) throws Exception {\ntry (CloseableHttpClient httpClient = HttpClients.createDefault()) {\n// Build Request\nString apiRestEndpoint = new StringBuilder(\"https://\")\n.append(ASTRA_DB_ID).append(\"-\")\n.append(ASTRA_DB_REGION)\n.append(\".apps.astra.datastax.com/api/rest\")\n.toString();\nHttpGet req = new HttpGet(apiRestEndpoint + \"/v2/schemas/namespaces\");\nreq.addHeader(\"X-Cassandra-Token\", ASTRA_TOKEN);\n// Execute Request\ntry(CloseableHttpResponse res = httpClient.execute(req)) {\nif (200 == res.getCode()) {\nlogger.info(\"[OK] Namespaces list retrieved\");\nlogger.info(\"Returned message: {}\", EntityUtils.toString(res.getEntity()));\n}\n}\n}\n}\n</code></pre> Resources <p> \u00a0Download SDK Sample   </p>"},{"location":"pages/develop/languages/java/#52-astra-sdk","title":"5.2 <code>Astra SDK</code>","text":"<p>The <code>Astra SDK</code> sets up the connection to work with the AstraDB cloud-based service. You will work with the class <code>AstraClient</code>, Reference documentation.</p> Import dependencies in your <code>pom.xml</code> <ul> <li>Update your <code>pom.xml</code> file with the latest version of the SDK </li> </ul> <pre><code>&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.astra&lt;/groupId&gt;\n&lt;artifactId&gt;astra-sdk&lt;/artifactId&gt;\n&lt;version&gt;${latestSDK}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> Standalone Code <pre><code>import java.io.File;\nimport com.datastax.astra.sdk.AstraClient;\nimport com.datastax.oss.driver.api.core.CqlSession;\npublic class AstraSdk {\n// Define inputs\nstatic final String ASTRA_DB_TOKEN  = \"&lt;provide_a_clientSecret&gt;\";\nstatic final String ASTRA_DB_ID     = \"&lt;provide_your_database_id&gt;\";\nstatic final String ASTRA_DB_REGION = \"&lt;provide_your_database_region&gt;\";\nstatic final String ASTRA_KEYSPACE  = \"&lt;provide_your_keyspace&gt;\";\n// Init Astra Client\npublic static void main(String[] args) {\ntry(AstraClient cli = AstraClient.builder()\n.withToken(ASTRA_DB_TOKEN)\n.withDatabaseId(ASTRA_DB_ID)\n.withDatabaseRegion(ASTRA_DB_REGION)\n.withCqlKeyspace(ASTRA_DB_KEYSPACE)\n.build()) {\nSystem.out.println(\"+ List of Keyspaces: \" + astraClient.apiStargateDocument()\n.namespaceNames()\n.collect(Collectors.toList()));\n}\n}\n}\n</code></pre> Resources <p> \u00a0Download SDK Sample   </p> <ul> <li>To get the full fledged information regarding the SDK check the github repository</li> </ul>"},{"location":"pages/develop/languages/java/#6-api-graphql","title":"6 Api GraphQL","text":""},{"location":"pages/develop/languages/java/#61-astra-sdk","title":"6.1 <code>Astra SDK</code>","text":"<p>The <code>Astra SDK</code> sets up the connection to work with the AstraDB cloud-based service. You will work with the class <code>AstraClient</code>, Reference documentation.</p> Import dependencies in your <code>pom.xml</code> <ul> <li>Update your <code>pom.xml</code> file with the latest version of the SDK </li> </ul> <pre><code>&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.astra&lt;/groupId&gt;\n&lt;artifactId&gt;astra-sdk&lt;/artifactId&gt;\n&lt;version&gt;${latestSDK}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> Standalone Code <pre><code>import java.io.File;\nimport com.datastax.astra.sdk.AstraClient;\nimport com.datastax.oss.driver.api.core.CqlSession;\npublic class AstraSdk {\n// Define inputs\nstatic final String ASTRA_DB_TOKEN  = \"&lt;provide_a_clientSecret&gt;\";\nstatic final String ASTRA_DB_ID     = \"&lt;provide_your_database_id&gt;\";\nstatic final String ASTRA_DB_REGION = \"&lt;provide_your_database_region&gt;\";\nstatic final String ASTRA_KEYSPACE  = \"&lt;provide_your_keyspace&gt;\";\n// Init Astra Client\npublic static void main(String[] args) {\ntry(AstraClient cli = AstraClient.builder()\n.withToken(ASTRA_DB_TOKEN)\n.withDatabaseId(ASTRA_DB_ID)\n.withDatabaseRegion(ASTRA_DB_REGION)\n.withCqlKeyspace(ASTRA_DB_KEYSPACE)\n.build()) {\nSystem.out.println(\"+ Keyspaces (graphQL) : \" + astraClient\n.apiStargateGraphQL()\n.cqlSchema()\n.keyspaces());\n}\n}\n}\n</code></pre> Resources <p> \u00a0Download SDK Sample   </p> <ul> <li>To get the full fledged information regarding the SDK check the github repository</li> </ul>"},{"location":"pages/develop/languages/java/#7-api-grpc","title":"7. Api gRPC","text":""},{"location":"pages/develop/languages/java/#71-grpc-client","title":"7.1 Grpc Client","text":"Import dependencies in your <code>pom.xml</code> <ul> <li>Update your <code>pom.xml</code> file with the latest version of the SDK </li> </ul> <pre><code>&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.stargate.grpc&lt;/groupId&gt;\n&lt;artifactId&gt;grpc-proto&lt;/artifactId&gt;\n&lt;version&gt;${latest-grpc-stargate}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.grpc&lt;/groupId&gt;\n&lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> Standalone Code <pre><code>  public class GrpcClient {\n// Define inputs\nstatic final String ASTRA_DB_TOKEN  = \"&lt;provide_a_clientSecret&gt;\";\nstatic final String ASTRA_DB_ID     = \"&lt;provide_your_database_id&gt;\";\nstatic final String ASTRA_DB_REGION = \"&lt;provide_your_database_region&gt;\";\n// Open Grpc communicatino \nManagedChannel channel = ManagedChannelBuilder\n.forAddress(ASTRA_DB_ID + \"-\" + ASTRA_DB_REGION + \".apps.astra.datastax.com\", 443)\n.useTransportSecurity()\n.build();\n// use Grpc Stub generated from .proto as a client\nStargateGrpc.StargateBlockingStub cloudNativeClient = StargateGrpc\n.newBlockingStub(channel)\n.withCallCredentials(new StargateBearerToken(ASTRA_DB_TOKEN))\n.withDeadlineAfter(5, TimeUnit.SECONDS);\n// create Query\nString cqlQuery = \"SELECT data_center from system.local\";\n// Execute the Query\nResponse res = cloudNativeClient.executeQuery(QueryOuterClass\n.Query.newBuilder().setCql(cqlQuery).build());\n// Accessing Row result\nQueryOuterClass.Row row = res.getResultSet().getRowsList().get(0);\n// Access the single value\nString datacenterName = row.getValues(0).getString();\nSystem.out.println(\"You are connected to '%s'\".formatted(datacenterName));\n</code></pre>"},{"location":"pages/develop/languages/java/#72-astra-sdk","title":"7.2 Astra SDK","text":"<p>The <code>Astra SDK</code> sets up the connection to work with the AstraDB cloud-based service. You will work with the class <code>AstraClient</code>, Reference documentation.</p> Import dependencies in your <code>pom.xml</code> <ul> <li>Update your <code>pom.xml</code> file with the latest version of the SDK </li> </ul> <pre><code>&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.astra&lt;/groupId&gt;\n&lt;artifactId&gt;astra-sdk&lt;/artifactId&gt;\n&lt;version&gt;${latestSDK}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> Standalone Code <pre><code>// Initialize Astra Client with token and database identifiers\ntry(AstraClient astraClient = AstraClient.builder()\n.withDatabaseId(ASTRA_DB_ID)\n.withDatabaseRegion(ASTRA_DB_REGION)\n.withToken(ASTRA_DB_TOKEN)\n.enableGrpc()\n.build()) {\n// Accessin the gRPC API\nApiGrpcClient cloudNativeClient = astraClient.apiStargateGrpc();\n// Reuse cql query\nString cqlQuery = \"SELECT data_center from system.local\";\n// Executing Query\nResultSetGrpc rs = cloudNativeClient.execute(cqlQuery);\n// Accessing reulst\nString datacenterName = rs.one().getString(\"data_center\");\nSystem.out.println(\"You are connected to '%s'\".formatted(datacenterName));\n// Validating the test\nAssertions.assertNotNull(datacenterName);\n}\n</code></pre>"},{"location":"pages/develop/languages/javascript/","title":"\u2022 Javascript","text":""},{"location":"pages/develop/languages/javascript/#1-overview","title":"1. Overview","text":"<p>Astra provides multiple services such as; Database and Streaming, with multiple Apis and interfaces. There are different frameworks and tools to connect to Astra depending on the Api interface you choose.</p> <p>Pick the interface in the table below to get relevant instructions. In most cases, you will download a working sample. There are standalone examples designed to be as simple as possible. Please note that a Software developement KIT (SDK) is also available for you to reduce the amount of boilerplate code needed to get started.  More information here.</p>"},{"location":"pages/develop/languages/javascript/#2-interfaces-list","title":"2. Interfaces List","text":"Component Interface Description Astra DB Main connection to Cassandra Astra DB CQL exposes as stateless rest resources Astra DB Use Cassandra as a Document DB Astra DB Create tables and use generated CRUD Astra DB CQL exposes through serialized protobuf Astra Streaming Create Producer, Consumers, Subscriptions.. Astra Streaming Administrate your Pulsar cluster Astra Core Manage Databases Astra Core Manage users and roles Astra Core Manage Streaming"},{"location":"pages/develop/languages/javascript/#3-cql","title":"3. CQL","text":""},{"location":"pages/develop/languages/javascript/#31-cassandra-native-driver","title":"3.1 Cassandra Native Driver","text":"<p>\u2139\ufe0f Overview</p> <p>These instructions are aimed at helping people connect to Astra DB programmatically using the DataStax Node driver.</p> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul> <p>Covered the basics and looking for more? We\u2019ve got docs to help you complete a variety of tasks. Here are some relevant topics for you:</p> <ul> <li>Node.js Driver Overview</li> <li>Migrating Node.js Driver</li> </ul> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <p>You need a current version of Node (16+) and NPM (9+)</p> <p>\ud83d\udce6 Setup Project</p> <pre><code>npm install cassandra-driver\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code Create a connect-database.js file in the main directory of your Node.js project:</p> <pre><code>mkdir nodejsProject\ncd nodejsProject\ntouch connect-database.js\n</code></pre> <p>Add the following connection code to the new file. Set username to your App Token\u2019s Client ID. Set password to your App Token\u2019s Client Secret. Set PATH/TO secure with the path to your secure connect bundle zip file.</p> <pre><code>const { Client } = require(\"cassandra-driver\");\nasync function run() {\n   const client = new Client({\n      cloud: {\n      secureConnectBundle: \"&lt;&lt;PATH/TO/&gt;&gt;secure-connect-stargate.zip\",\n      },\n      credentials: {\n      username: \"&lt;&lt;CLIENT ID&gt;&gt;\",\n      password: \"&lt;&lt;CLIENT SECRET&gt;&gt;\",\n      },\n   });\n\n   await client.connect();\n\n   // Execute a query\n   const rs = await client.execute(\"SELECT * FROM system.local\");\n   console.log(`Your cluster returned ${rs.rowLength} row(s)`);\n\n   await client.shutdown();\n}\n\n// Run the async function\nrun();\n</code></pre> <p>Ensure you set username to your App Token's Client ID, password to your App Token's Client Secret, and path/to/secure-connect-database_name.zip with the path to your SCB.  This code creates a Client instance to connect to your Astra DB, runs a CQL query, and prints the output to the console.</p> <p>Then, Save and close the connect-database.js file and run the connect-database.js example with the Node.js runtime.</p> <pre><code>node connect-database.js\n</code></pre>"},{"location":"pages/develop/languages/javascript/#32-cassandra-cloud-driver-grpc","title":"3.2 Cassandra Cloud Driver (GRPC)","text":"<p>\u2139\ufe0f Overview</p> <p>The cloud native (known as Google Remote Procedure Call or gRPC) client is well-supported across multiple languages. Using the gRPC client means you can easily query CQL from any source without the worry of driver installation or upgrades.</p> <p>Covered the basics and looking for more? We\u2019ve got docs to help you complete a variety of tasks. Here are some relevant topics for you:</p> <ul> <li>Node.js Driver Overview</li> <li>Node.js Querying -Processing a result set</li> <li>Node.js Developing</li> <li>Node full sample script</li> </ul> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <ul> <li>If you do not already have one, get an API Token and set the role to \u201cDatabase Administrator\u201d.</li> <li>Create a keyspace.</li> <li>Create a table in your keyspace(optional): REST</li> </ul> <p>\ud83d\udce6 Setup Project</p> <p>Install stargate-grpc-node-client using either npm or yarn:</p> <p>npm command</p> <pre><code>npm i @stargate-oss/stargate-grpc-node-client\n</code></pre> <p>Yarn command</p> <pre><code>yarn add @stargate-oss/stargate-grpc-node-client\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <p>This example assumes that you\u2019re running Stargate on Astra DB. For more information, please see the documentation. You\u2019ll need to download your token from the Astra DB dashboard and add the token to the connection portion of the script.</p> <p>The token to use in the Header of API calls is the same as your database's Application token. It starts with an AstraCS: prefix, followed by a generated alphanumeric string. You can generate this token in Astra DB console, via Organization Settings &gt; Token Management &gt; Select Role &gt; Generate Token. Copy the token value, and paste it into your API call to authenticate with Astra DB resources.</p> <pre><code>// Astra DB configuration\n// replace with values from the Astra DB dashboard\nconst astra_uri = \"{astra-base-url}-{astra-region}.apps.astra.datastax.com:443\";\nconst bearer_token = \"AstraCS:xxxxxxx\";\n\n// Set up the authentication\n// For Astra DB: Enter a bearer token for Astra, downloaded from the Astra DB dashboard\nconst bearerToken = new StargateBearerToken(bearer_token);\nconst credentials = grpc.credentials.combineChannelCredentials(\n  grpc.credentials.createSsl(), bearerToken);\n\n// Uncomment if you need to check the credentials\n//console.log(credentials);\n</code></pre> <p>For a connection to a remote Stargate instance like Astra automatically generate on every call to the client:</p> <pre><code>// Create the gRPC client\n// For Astra DB: passing the credentials created above\nconst stargateClient = new StargateClient(astra_uri, credentials);\n\nconsole.log(\"made client\");\n\n// Create a promisified version of the client, so we don't need to use callbacks\nconst promisifiedClient = promisifyStargateClient(stargateClient);\n\nconsole.log(\"promisified client\")\n</code></pre>"},{"location":"pages/develop/languages/javascript/#33-astra-sdk-astrajscollections-and-astrajsrest","title":"3.3 Astra SDK (@astrajs/collections and @astrajs/rest)","text":"<p>\u2139\ufe0f Overview</p> <p>The JavaScript SDK allows you to perform standard CRUD operations on your data using Javascript.</p> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li> <p>You should Download your Secure bundle</p> </li> <li> <p>In the command-line interface associated with your development environment, paste the following and replace  with your Application Token: <pre><code>export ASTRA_DB_ID=887ff1a8-f81a-4a7a-a11b-d5379998b36e\nexport ASTRA_DB_REGION=us-east1\nexport ASTRA_DB_APPLICATION_TOKEN=&lt;app_token&gt;\n</code></pre> <li>Use printenv to ensure the environment variables were exported correctly.</li> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>A current version of node (16+) and NPM (8+)\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>npm install @astrajs/rest\nnpm install @astrajs/collections\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <p>Sample code for Document API: <pre><code>const { createClient } = require(\"@astrajs/rest\");\n\n// create an Astra DB client\nconst astraClient = await createClient({\n  astraDatabaseId: process.env.ASTRA_DB_ID,\n  astraDatabaseRegion: process.env.ASTRA_DB_REGION,\n  applicationToken: process.env.ASTRA_DB_APPLICATION_TOKEN,\n});\n\nconst basePath = \"/api/rest/v2/namespaces/app/collections/users\";\n\n// get a single user by document id\nconst { data, status } = await astraClient.get(`${basePath}/cliff@wicklow.com`);\n\n// get a subdocument by path\nconst { data, status } = await astraClient.get(\n  `${basePath}/cliff@wicklow.com/blog/comments`\n);\n\n// search a collection of documents\nconst { data, status } = await astraClient.get(basePath, {\n  params: {\n    where: {\n      name: { $eq: \"Cliff\" },\n    },\n  },\n});\n\n// create a new user without a document id\nconst { data, status } = await astraClient.post(basePath, {\n  name: \"cliff\",\n});\n\n// create a new user with a document id\nconst { data, status } = await astraClient.put(\n  `${basePath}/cliff@wicklow.com`,\n  {\n    name: \"cliff\",\n  }\n);\n\n// create a user subdocument\nconst { data, status } = await astraClient.put(\n  `${basePath}/cliff@wicklow.com/blog`,\n  {\n    title: \"new blog\",\n  }\n);\n\n// partially update user\nconst { data, status } = await astraClient.patch(\n  `${basePath}/cliff@wicklow.com`,\n  {\n    name: \"cliff\",\n  }\n);\n\n// delete a user\nconst { data, status } = await astraClient.delete(\n  `${basePath}/cliff@wicklow.com`\n);\n</code></pre></p>"},{"location":"pages/develop/languages/javascript/#4-stargate-rest-api","title":"4. Stargate REST Api","text":""},{"location":"pages/develop/languages/javascript/#41-astra-sdk","title":"4.1 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <p>The JavaScript SDK allows you to perform standard CRUD operations on your data using Javascript.</p> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>A current version of node (16+) and NPM (8+)\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>npm install @astrajs/rest\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <p>Create a REST API client <pre><code>const { createClient}= require(\"@astrajs/rest\")\nconst chalk = require('chalk')\nlet astraRestClient = null;\n\nconst requestWithRetry = async (url, client) =&gt; {\n  const MAX_RETRIES = 20;\n  for (let i = 1; i &lt;= MAX_RETRIES; i++) {\n    try {\n      let response = await client.get(url);\n      return response\n    } catch(e) {\n      const timeout = 500 * i * 10;\n      console.log(chalk.blue('         ... waiting', timeout, 'ms'));\n      await wait(timeout);\n    }\n  }\n}\n\nfunction wait(timeout) {\n    return new Promise((resolve) =&gt; {\n        setTimeout(() =&gt; {\n            resolve();\n        }, timeout);\n    });\n}\n\nconst getAstraRestClient = async () =&gt; {\n  if (astraRestClient === null) {\n    astraRestClient = await createClient(\n      {\n        astraDatabaseId: process.env.ASTRA_DB_ID,\n        astraDatabaseRegion: process.env.ASTRA_DB_REGION,\n        applicationToken: process.env.ASTRA_DB_APPLICATION_TOKEN,\n        debug: true\n      },\n      30000\n    );\n  }\n  return astraRestClient;\n};\n\nconst getRestClient = async () =&gt; {\n  if (astraRestClient === null) {\n    const astraRestClient = await getAstraRestClient();\n    await wait(1000);\n    return astraRestClient;\n  };\n  return astraRestClient;\n}\n\nmodule.exports = { getRestClient, requestWithRetry, wait, astraRestClient };\n</code></pre></p> <p>Then use that within another application: <pre><code>const { getRestClient, requestWithRetry, wait } = require(\"./utils/astraRestClient\");\n\nexports.handler = async (event, context) =&gt; {\n  const client = await getClient();\n  let res;\n  try {\n    res = await client.get('/api/rest/v2/keyspaces/todos/rest?where=\\{\"key\":\\{\"$eq\":\\\"rest\"\\}\\}')\n    const formattedTodos = Object.keys(res.data).map((item) =&gt; res.data[item]);\n    return {\n      headers: '{Content-Type: application/json}',\n      statusCode: 200,\n      body: JSON.stringify(formattedTodos),\n      headers: {\n        'Content-Type': 'application/json'\n      },\n    };\n  } catch (e) {\n    return {\n      statusCode: 400,\n      body: JSON.stringify(e),\n    };\n  }\n};\n\nasync function getClient() {\n  let client = await getRestClient();\n  if (client === null) {\n    wait(1000)\n    return getClient()\n  }\n  return client\n}\n</code></pre></p> <p>Other rest command examples: <pre><code>let path = '/api/rest/v2/keyspaces/todos/rest/' + body.id;\n    body = {\"text\":body.text, \"completed\":body.completed}\n    const res = await todos.put(path, body);\n</code></pre></p> <pre><code>const todos = await getRestClient();\n  const body = JSON.parse(event.body);\n  event.body.key = \"todo\"\n\n  const res = await todos.post('/api/rest/v2/keyspaces/todos/rest', event.body);\n</code></pre>"},{"location":"pages/develop/languages/javascript/#5-stargate-document-api","title":"5. Stargate Document Api","text":""},{"location":"pages/develop/languages/javascript/#51-astra-sdk","title":"5.1 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <p>The JavaScript SDK allows you to perform standard CRUD operations on your data using Javascript.</p> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>A current version of node (16+) and NPM (8+)\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>npm install @astrajs/collection\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <p>Sample code for Document API: <pre><code>const { createClient } = require(\"@astrajs/rest\");\n\n// create an Astra DB client\nconst astraClient = await createClient({\n  astraDatabaseId: process.env.ASTRA_DB_ID,\n  astraDatabaseRegion: process.env.ASTRA_DB_REGION,\n  applicationToken: process.env.ASTRA_DB_APPLICATION_TOKEN,\n});\n\nconst basePath = \"/api/rest/v2/namespaces/app/collections/users\";\n\n// get a single user by document id\nconst { data, status } = await astraClient.get(`${basePath}/cliff@wicklow.com`);\n\n// get a subdocument by path\nconst { data, status } = await astraClient.get(\n  `${basePath}/cliff@wicklow.com/blog/comments`\n);\n\n// search a collection of documents\nconst { data, status } = await astraClient.get(basePath, {\n  params: {\n    where: {\n      name: { $eq: \"Cliff\" },\n    },\n  },\n});\n\n// create a new user without a document id\nconst { data, status } = await astraClient.post(basePath, {\n  name: \"cliff\",\n});\n\n// create a new user with a document id\nconst { data, status } = await astraClient.put(\n  `${basePath}/cliff@wicklow.com`,\n  {\n    name: \"cliff\",\n  }\n);\n\n// create a user subdocument\nconst { data, status } = await astraClient.put(\n  `${basePath}/cliff@wicklow.com/blog`,\n  {\n    title: \"new blog\",\n  }\n);\n\n// partially update user\nconst { data, status } = await astraClient.patch(\n  `${basePath}/cliff@wicklow.com`,\n  {\n    name: \"cliff\",\n  }\n);\n\n// delete a user\nconst { data, status } = await astraClient.delete(\n  `${basePath}/cliff@wicklow.com`\n);\n</code></pre></p>"},{"location":"pages/develop/languages/javascript/#6-stargate-graphql","title":"6 Stargate GraphQL","text":""},{"location":"pages/develop/languages/javascript/#61-cql-first","title":"6.1 CQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/javascript/#62-graphql-first","title":"6.2 GraphQL First","text":"<p>\u2139\ufe0f Overview</p> <p>\u2139\ufe0f Overview</p> <p>The JavaScript SDK allows you to perform standard CRUD operations on your data using Javascript.</p> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>A current version of node (16+) and NPM (8+)\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>npm install @astrajs/rest\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>const { getRestClient, requestWithRetry, wait, astraRestClient } = require(\"./utils/astraRestClient\");\n\n  let query = `mutation updategraphql {\n    graphql: updategraphql(value: {\n      id: \"${body.id}\",\n      completed: ${body.completed},\n      text: \"${body.text}\",\n      key: \"graphql\"\n  }) {value { text } }}`\n  let res = await client.post('/api/graphql/todos',\n    {query: query})\n</code></pre> <pre><code>let query = `query GQTodos {\n    graphql (value: {key:\"graphql\"}) {\n      values {\n        id\n        text\n        completed\n        key\n      }\n    }}`\n\nres = await client.post('/api/graphql/todos', query={query})\n</code></pre>"},{"location":"pages/develop/languages/javascript/#7-stargate-grpc","title":"7. Stargate gRPC","text":""},{"location":"pages/develop/languages/javascript/#71-stargate-client","title":"7.1 Stargate Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/javascript/#72-astra-sdk","title":"7.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/javascript/#8-pulsar-client","title":"8. Pulsar Client","text":""},{"location":"pages/develop/languages/javascript/#81-pulsar-client","title":"8.1 Pulsar Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/javascript/#82-astra-sdk","title":"8.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/javascript/#9-pulsar-admin","title":"9. Pulsar Admin","text":""},{"location":"pages/develop/languages/javascript/#10-devops-api-database","title":"10 Devops API Database","text":""},{"location":"pages/develop/languages/javascript/#11-devops-api-organization","title":"11 Devops API Organization","text":""},{"location":"pages/develop/languages/javascript/#12-devops-api-streaming","title":"12 Devops API Streaming","text":""},{"location":"pages/develop/languages/python/","title":"\u2022 Python","text":""},{"location":"pages/develop/languages/python/#1-overview","title":"1. Overview","text":"<p>Astra provides multiple services such as; Database and Streaming, with multiple Apis and interfaces. There are different frameworks and tools to connect to Astra depending on the Api interface you choose.</p> <p>Pick the interface in the table below to get relevant instructions. In most cases, you will download a working sample. There are standalone examples designed to be as simple as possible. Please note that a Software developement KIT (SDK) is also available for you to reduce the amount of boilerplate code needed to get started. More information is here.</p>"},{"location":"pages/develop/languages/python/#2-interfaces-list","title":"2. Interfaces List","text":"Component Interface Description Astra DB Main connection to Cassandra Astra DB CQL exposes as stateless rest resources Astra DB Use Cassandra as a Document DB Astra DB Create tables and use generated CRUD Astra DB CQL exposes through serialized protobuf Astra Streaming Create Producer, Consumers, Subscriptions.. Astra Streaming Administrate your Pulsar cluster Astra Core Manage Databases Astra Core Manage users and roles Astra Core Manage Streaming"},{"location":"pages/develop/languages/python/#3-cql","title":"3. CQL","text":""},{"location":"pages/develop/languages/python/#31-cassandra-drivers","title":"3.1 Cassandra Drivers","text":"<p>\u2139\ufe0f Overview</p> <p>These instructions are aimed at helping people connect to Astra DB programmatically using the DataStax Python driver.</p> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> </ul> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <p>You will need a recent version of Python 3.  Visit https://www.python.org/downloads/ for more information on downloads and installation instructions for your machine architecture.  To verify your Python install, run the following command:</p> <pre><code>python -V\n</code></pre> <p>With Python installed locally, you can now use Pip (Python's package manager) to install the DataStax Python driver.</p> <pre><code>pip install cassandra-driver\n</code></pre> <p>You can verify that the DataStax Python driver was installed successfully with this command:</p> <pre><code>python -c 'import cassandra; print (cassandra.__version__)'\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <p>Create a new file and/or directory for your Python program.</p> <pre><code>mkdir python_project\ncd python_project\ntouch testAstra.py\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <p>To connect to an Astra DB cluster, you will need a secure token generated specifically for use with your Astra DB cluster.</p> <pre><code>mkdir ~/mySecureBundleDir\ncd ~/mySecureBundleDir\nmv ~/Downloads/secure-connect-bundle.zip .\n</code></pre> <p>Open up your favorite editor or IDE, and add 3 imports:</p> <pre><code>from cassandra.cluster import Cluster\nfrom cassandra.auth import PlainTextAuthProvider\nimport sys\n</code></pre> <p>Next we will inject the connection parameters into the code.  This can be done either by reading them as environment variables or passing them as command line arguments.</p> <p>This example will be done using command line arguments:</p> <pre><code>clientID=sys.argv[1]\nsecret=sys.argv[2]\nsecureBundleLocation=sys.argv[3]\n</code></pre> <p>We'll also define the location of our secure connect bundle, and set that as a property in our <code>cloud_config</code>:</p> <pre><code>cloud_config= {\n'secure_connect_bundle': secureBundleLocation\n}\n</code></pre> <p>Next, we'll define our authenticator and pass our credentials to it.</p> <pre><code>auth_provider = PlainTextAuthProvider(clientID, secret)\n</code></pre> <p>With all of that defined, we can build a cluster object and a connection:</p> <pre><code>cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\nsession = cluster.connect()\n</code></pre> <p>With a connection made, we can run a simple query to return the name of the cluster from the <code>system.local</code> table:</p> <pre><code>row = session.execute(\"select cluster_name from system.local\").one()\nif row:\nprint(row[0])\nelse:\nprint(\"An error occurred.\")\n</code></pre> <p>Running this code with arguments in the proper order should yield output similar to this:</p> <pre><code>python testAstra.py token \"AstraCS:ASjPlHbTYourSecureTokenGoesHered3cdab53b\" /Users/aaronploetz/mySecureBundleDir/secure-connect-bundle.zip\n\ncndb\n</code></pre> <p>The complete code to this example can be found here.</p>"},{"location":"pages/develop/languages/python/#32-astra-sdk","title":"3.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#4-stargate-rest-api","title":"4. Stargate REST Api","text":""},{"location":"pages/develop/languages/python/#41-axios","title":"4.1 Axios","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#42-astra-sdk","title":"4.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#5-stargate-document-api","title":"5. Stargate Document Api","text":""},{"location":"pages/develop/languages/python/#51-axios","title":"5.1 Axios","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#52-astra-sdk","title":"5.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#6-stargate-graphql","title":"6 Stargate GraphQL","text":""},{"location":"pages/develop/languages/python/#61-cql-first","title":"6.1 CQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#62-graphql-first","title":"6.2 GraphQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#7-stargate-grpc","title":"7. Stargate gRPC","text":""},{"location":"pages/develop/languages/python/#71-stargate-client","title":"7.1 Stargate Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#72-astra-sdk","title":"7.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#8-pulsar-client","title":"8. Pulsar Client","text":""},{"location":"pages/develop/languages/python/#81-pulsar-client","title":"8.1 Pulsar Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#82-astra-sdk","title":"8.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/python/#9-pulsar-admin","title":"9. Pulsar Admin","text":""},{"location":"pages/develop/languages/python/#10-devops-api-database","title":"10 Devops API Database","text":""},{"location":"pages/develop/languages/python/#11-devops-api-organization","title":"11 Devops API Organization","text":""},{"location":"pages/develop/languages/python/#12-devops-api-streaming","title":"12 Devops API Streaming","text":""},{"location":"pages/develop/languages/rust/","title":"\u2022 Rust","text":""},{"location":"pages/develop/languages/rust/#1-overview","title":"1. Overview","text":"<p>Astra provides multiple services such as; Database and Streaming, with multiple Apis and interfaces. There are different frameworks and tools to connect to Astra depending on the Api interface you choose.</p> <p>Pick the interface in the table below to get relevant instructions. In most cases, you will download a working sample. There are standalone examples designed to be as simple as possible. Please note that a Software developement KIT (SDK) is also available for you to reduce the amount of boilerplate code needed to get started. More information is here.</p>"},{"location":"pages/develop/languages/rust/#2-interfaces-list","title":"2. Interfaces List","text":"Component Interface Description Astra DB Main connection to Cassandra Astra DB CQL exposes as stateless rest resources Astra DB Use Cassandra as a Document DB Astra DB Create tables and use generated CRUD Astra DB CQL exposes through serialized protobuf Astra Streaming Create Producer, Consumers, Subscriptions.. Astra Streaming Administrate your Pulsar cluster Astra Core Manage Databases Astra Core Manage users and roles Astra Core Manage Streaming"},{"location":"pages/develop/languages/rust/#3-cql","title":"3. CQL","text":""},{"location":"pages/develop/languages/rust/#31-cassandra-drivers","title":"3.1 Cassandra Drivers","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#32-astra-sdk","title":"3.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#4-stargate-rest-api","title":"4. Stargate REST Api","text":""},{"location":"pages/develop/languages/rust/#41-axios","title":"4.1 Axios","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#42-astra-sdk","title":"4.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#5-stargate-document-api","title":"5. Stargate Document Api","text":""},{"location":"pages/develop/languages/rust/#51-axios","title":"5.1 Axios","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#52-astra-sdk","title":"5.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#6-stargate-graphql","title":"6 Stargate GraphQL","text":""},{"location":"pages/develop/languages/rust/#61-cql-first","title":"6.1 CQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#62-graphql-first","title":"6.2 GraphQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#7-stargate-grpc","title":"7. Stargate gRPC","text":""},{"location":"pages/develop/languages/rust/#71-stargate-client","title":"7.1 Stargate Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#72-astra-sdk","title":"7.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#8-pulsar-client","title":"8. Pulsar Client","text":""},{"location":"pages/develop/languages/rust/#81-pulsar-client","title":"8.1 Pulsar Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#82-astra-sdk","title":"8.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/rust/#9-pulsar-admin","title":"9. Pulsar Admin","text":""},{"location":"pages/develop/languages/rust/#10-devops-api-database","title":"10 Devops API Database","text":""},{"location":"pages/develop/languages/rust/#11-devops-api-organization","title":"11 Devops API Organization","text":""},{"location":"pages/develop/languages/rust/#12-devops-api-streaming","title":"12 Devops API Streaming","text":""},{"location":"pages/develop/languages/scala/","title":"\u2022 Scala","text":""},{"location":"pages/develop/languages/scala/#1-overview","title":"1. Overview","text":"<p>Astra provides multiple services such as; Database and Streaming, with multiple Apis and interfaces. There are different frameworks and tools to connect to Astra depending on the Api interface you choose.</p> <p>Pick the interface in the table below to get relevant instructions. In most cases, you will download a working sample. There are standalone examples designed to be as simple as possible. Please note that a Software developement KIT (SDK) is also available for you to reduce the amount of boilerplate code needed to get started. More information is here.</p>"},{"location":"pages/develop/languages/scala/#2-interfaces-list","title":"2. Interfaces List","text":"Component Interface Description Astra DB Main connection to Cassandra Astra DB CQL exposes as stateless rest resources Astra DB Use Cassandra as a Document DB Astra DB Create tables and use generated CRUD Astra DB CQL exposes through serialized protobuf Astra Streaming Create Producer, Consumers, Subscriptions.. Astra Streaming Administrate your Pulsar cluster Astra Core Manage Databases Astra Core Manage users and roles Astra Core Manage Streaming"},{"location":"pages/develop/languages/scala/#3-cql","title":"3. CQL","text":""},{"location":"pages/develop/languages/scala/#31-cassandra-drivers","title":"3.1 Cassandra Drivers","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#32-astra-sdk","title":"3.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#4-stargate-rest-api","title":"4. Stargate REST Api","text":""},{"location":"pages/develop/languages/scala/#41-axios","title":"4.1 Axios","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#42-astra-sdk","title":"4.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#5-stargate-document-api","title":"5. Stargate Document Api","text":""},{"location":"pages/develop/languages/scala/#51-axios","title":"5.1 Axios","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#52-astra-sdk","title":"5.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#6-stargate-graphql","title":"6 Stargate GraphQL","text":""},{"location":"pages/develop/languages/scala/#61-cql-first","title":"6.1 CQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#62-graphql-first","title":"6.2 GraphQL First","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#7-stargate-grpc","title":"7. Stargate gRPC","text":""},{"location":"pages/develop/languages/scala/#71-stargate-client","title":"7.1 Stargate Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#72-astra-sdk","title":"7.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#8-pulsar-client","title":"8. Pulsar Client","text":""},{"location":"pages/develop/languages/scala/#81-pulsar-client","title":"8.1 Pulsar Client","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#82-astra-sdk","title":"8.2 Astra SDK","text":"<p>\u2139\ufe0f Overview</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [ASTRA]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Prerequisites [Development Environment]</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udce6 Setup Project</p> <pre><code>TODO\n</code></pre> <p>\ud83d\udda5\ufe0f Sample Code</p> <pre><code>TODO\n</code></pre>"},{"location":"pages/develop/languages/scala/#9-pulsar-admin","title":"9. Pulsar Admin","text":""},{"location":"pages/develop/languages/scala/#10-devops-api-database","title":"10 Devops API Database","text":""},{"location":"pages/develop/languages/scala/#11-devops-api-organization","title":"11 Devops API Organization","text":""},{"location":"pages/develop/languages/scala/#12-devops-api-streaming","title":"12 Devops API Streaming","text":""},{"location":"pages/develop/platform/aws-gamesparks/","title":"AWS GameSparks","text":"<p>Notice</p> <p>This tutorial is currently in Beta. Feel free to contact us if you run into any issues or need additional help with completing the tutorial.</p>"},{"location":"pages/develop/platform/aws-gamesparks/#aws-gamesparks","title":"AWS GameSparks","text":""},{"location":"pages/develop/platform/aws-gamesparks/#overview","title":"Overview","text":"<p>In this tutorial, we will be creating a simple app that connects to Astra Block using AWS GameSparks, AWS Lambda, and Unity. </p> <p></p> <p>AWS GameSparks is a fully managed AWS service that provides a multi-service backend for game developers. GameSparks works together with AWS Lambda which connects directly to our Astra DB Database and Astra Block.</p>"},{"location":"pages/develop/platform/aws-gamesparks/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>Request for access to Astra Block.</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> <li>Have Unity Hub installed.</li> <li>Have 2020.3 Unity version installed (This project uses 3.4.1).</li> </ul>"},{"location":"pages/develop/platform/aws-gamesparks/#step-1-aws-lambda","title":"Step 1: AWS Lambda","text":"<p>This section of the tutorial will be referencing a majority of the AWS Lambda tutorial with some minor adjustments. </p> <ol> <li> <p>First, choose one of the four options available: Python Driver, Python SDK, Java Driver, Java gRPC. This tutorial uses Python Driver. </p> </li> <li> <p>In Step 2 of the AWS Lambda integration tutorial, you are asked to create file <code>lambda_function.py</code> with the function source code. Use the following code for the <code>lambda_handler</code> function. <pre><code>def lambda_handler(event, context):\nnum1 = event['num1']\nnum2 = event['num2']\nrow = session.execute(\"select * from krypton_dev.sorted_nfts where block_number_hour=\" + str(num1) + \" and block_number=\" + str(num2) + \" limit 1;\").one()\nprint(type(row[5]))\nreturn {\n\"result\": row[5]\n}\n</code></pre> This queries the <code>sorted_nfts</code> table then returns the name of the NFT at the given <code>block_number</code> and <code>block_number_hour</code>.</p> </li> <li> <p>Create the deployment package and AWS Lambda function as stated in the tutorial. </p> </li> <li> <p>Test the function by navigating to the Test tab. Scroll down to the Event JSON section and update the values with the following values: <pre><code>{\n\"num1\": \"41447\",\n\"num2\": \"14920967\"\n}\n</code></pre></p> </li> <li>Click the Test button and observe the output. It should have returned the NFT name <code>Banksy Culture</code>.  </li> </ol>"},{"location":"pages/develop/platform/aws-gamesparks/#step-2-aws-gamesparks","title":"Step 2: AWS GameSparks","text":"<p>This section of the tutorial will focus on setting up AWS GameSparks as a backend and connect it to the AWS Lambda function that you just created.</p>"},{"location":"pages/develop/platform/aws-gamesparks/#create-a-game-backend","title":"Create a game backend","text":"<ol> <li> <p>Firstly, open the Amazon GameSparks Console and click on Create game to create a game and start developing your game backend: </p> </li> <li> <p>Set a name for your Game and click Create  You have now created your AWS GameSparks backend ready to be configured to your game and AWS Lambda. </p> </li> </ol>"},{"location":"pages/develop/platform/aws-gamesparks/#deployment","title":"Deployment","text":"<p>Prior to any major development, we are first going to deploy a fresh new snapshot of the game backend. A snapshot allows you to store data representing a certain point of progress in a game.  </p> <ol> <li> <p>From the Dev page, click Deploy as new snapshot.  </p> </li> <li> <p>Here, you can enter an optional description and click Save to continue.  </p> </li> <li> <p>In a few minutes, you should see that the snapshot and game backend has now been deployed. Note: Everytime a new feature is added to the game, a new snapshot will also have to be deployed.   </p> </li> </ol>"},{"location":"pages/develop/platform/aws-gamesparks/#give-your-gamesparks-backend-permission-to-access-lambda","title":"Give your GameSparks backend permission to access Lambda","text":"<p>Now that the game backend is deployed, we must give it permission to access the AWS Lambda function that we set up previously in Step 1. This will allow the two entities to communicate with each other, send/receive requests to the game backend, and more. Firstly, we will have to grant permissions by creating an IAM Policy. </p>"},{"location":"pages/develop/platform/aws-gamesparks/#create-policy","title":"Create Policy","text":"<ol> <li> <p>Go to the IAM Create policy page and click Import managed policy. This will allow you import a role with specific permissions to Lambda.  </p> </li> <li> <p>Filter the policies by searching for LambdaRole in the search bar. Choose AWSLambdaRole. Then select Import. </p> </li> <li> <p>AWSLambdaRole policy will allow you to invoke any Lambda function that we deploy. However, you also have the option to specify a specific function that you would like to invoke. Do this by going to the JSON tab, and navigating to where it says <code>\"Resource\"</code>. Replace the <code>\"*\"</code> with the ARN from your Lambda Function to invoke a specific function. For this tutorial, you can leave it as <code>\"*\"</code>.  </p> </li> <li> <p>Choose Next:Tags then Next:Review. </p> </li> <li> <p>In Review, give your policy a name such as <code>AllowLambdaInvokeAll</code> and finish by choosing Create Policy. </p> </li> </ol>"},{"location":"pages/develop/platform/aws-gamesparks/#attach-policy","title":"Attach policy","text":"<p>Next, we are going to the attach the policy we just created to our GameSparks backend IAM role.</p> <ol> <li> <p>Go back to your Amazon GameSparks Console, select your game, and go to the Dev section in your navigation bar. Under Dev, go to Configuration and choose \"View in IAM console\". </p> </li> <li> <p>The IAM console opens to the IAM role for your Dev stage. On the Permissions tab, choose Add permissions and Attach policies: </p> </li> <li> <p>Filter for the policy name you created, select it, and press Add permissions.  </p> </li> <li> <p>Great! You have now given your AWS GameSparks backend permission to call to your AWS Lambda Function.  </p> </li> </ol>"},{"location":"pages/develop/platform/aws-gamesparks/#step-3-connecting-your-gamesparks-backend-to-lambda","title":"Step 3: Connecting your GameSparks backend to Lambda","text":"How This Works? <p>To invoke Lambda functions from Amazon GameSparks you need to create a Message inside the game backend. There are 3 types of messages: Events, Requests, and Notifications. Once created, you can call a Lambda function from there. Learn more here.</p> <p>For this example, we will be using Request so that our front end client (Unity) can get data from our Amazon GameSparks backend. This request will internally call the Lambda function we previously set up and return a response. </p>"},{"location":"pages/develop/platform/aws-gamesparks/#create-getsortednft-request","title":"Create GetSortedNFT request","text":"<ol> <li> <p>Return to your GameSparks backend, and select Cloud code from the navigation bar. Once you are there, select Create Message.  </p> </li> <li> <p>Select Request and give it a name. For this example, we will name it GetSortedNFT based on our Lambda function. Then click, Create </p> </li> <li> <p>Here, you will configure the Request fields. Recall the AWS Lambda function that we created. There were 2 input fields that were needed to retrieve a response: <pre><code>{\n\"num1\": \"41447\",\n\"num2\": \"14920967\"\n}\n</code></pre> You will configure a Request field for each input value needed in the Lambda function and a Response field. We will call these fields <code>input1</code> and <code>input2</code>.   Make sure to also take note of the Shape so that it matches the type of your Response field.</p> </li> <li> <p>Update the Request handle code with the following: <pre><code>GameSparks().Logging().Debug(\"In lambdaAstraDBTest request handler\");\n\nconst response = GameSparks().Lambda(\"lambdaAstraDBTest\").Invoke(\n    {\n        \"num1\": message.input1,\n        \"num2\": message.input2\n    }\n);\n\nGameSparks().Logging().Debug(\"Result from Lambda is:\");\nGameSparks().Logging().Debug(JSON.stringify(response.Payload));\n\nreturn GameSparks().Messaging().Response({\"result\": JSON.stringify(response.Payload.result)});\n</code></pre> Then click Save.</p> </li> <li> <p>Test your Request in the Cloud Console by clicking Test.  </p> </li> <li> <p>Make sure your Player is connected and that you deploy a new snapshot by clicking the banner. You should always deploy a new snapshot between changes.</p> </li> <li> <p>Once Step 6 is done, select Populate example which will allow you to give input to the Request Body. Here, you can populate values <code>input1</code> and <code>input2</code> with the same values you gave when you set up your AWS Lambda function. <code>input1</code> being the <code>block_number_hour</code> and <code>input2</code> being the <code>block_number</code> from your <code>sorted_nfts</code> table. Remember to use valid block_number_hour and block_number values.</p> </li> </ol> <p><pre><code>{\n\"input1\": 41447,\n\"input2\": 14920967\n}\n</code></pre> 8. Finally, click Send message to send this request to the backend. You should see in the Log inspector your request being sent and received.  9. Congrats! You have now sent a request and received a response using AWS GameSparks and AWS Lambda. </p>"},{"location":"pages/develop/platform/aws-gamesparks/#step-4-connecting-unity-to-gamesparks-backend","title":"Step 4: Connecting Unity to GameSparks backend","text":"<p>Now you are ready to connect your backend to our Unity front end. First, download the Unity sample project we have prepared from our Awesome Astra repo. </p> <p>Note</p> <p>The sample project already includes the Amazon GameSparks SDK installed, or you can follow the instructions here.</p>"},{"location":"pages/develop/platform/aws-gamesparks/#setting-up","title":"Setting Up","text":"<ol> <li> <p>Open the project with Unity Hub </p> </li> <li> <p>On the Project tab go to Assets -&gt; Amazon -&gt; GameSparks and choose the Connection.asset </p> </li> <li> <p>In the Insepctor tab on the right, you will see the Amazon GameSparks connection settings. As you can see currently, Game Key is blank. You will obtain this from your GameSparks Console -&gt; Dev -&gt; Dev stage configuration -&gt; Under Key </p> </li> <li> <p>Copy this value and paste it into Game Key back in Unity. </p> </li> </ol> <p>Great! Setup is now complete! </p>"},{"location":"pages/develop/platform/aws-gamesparks/#running-the-game","title":"Running the game","text":"<ol> <li> <p>To run the game, go back to your Project tab -&gt; Assets -&gt; Scenes -&gt; Select the AstraBlockGameSparksDemo Scene. This is the scene that we are going to play. </p> </li> <li> <p>Click the \"Play\" button at the top of the screen. You should see a notification saying the scripts are rendering.  </p> </li> <li> <p>Once that is complete, you can type directly into the input box where it says Enter Block Number.... Once you click submit, you should see the Block Number populate, and shortly after, the NFT Title will return the name of the NFT at that given block number.  </p> </li> <li> <p>Try submitting different Block Numbers to see the different results you get back for your NFTs!</p> </li> </ol>"},{"location":"pages/develop/platform/aws-gamesparks/#finish","title":"Finish","text":"<p>Congratulations! You have completed the Astra Block with AWS GameSparks, AWS Lambda, and Unity tutorial! This is only the beginning as you can connect your AWS Lambda to any table given within Astra Block, query for different values, etc. </p> <p> \ud83c\udfe0 Back to HOME </p>"},{"location":"pages/develop/platform/aws-lambda-function/","title":"AWS Lambda Functions","text":""},{"location":"pages/develop/platform/aws-lambda-function/#aws-lambda-functions","title":"AWS Lambda Functions","text":""},{"location":"pages/develop/platform/aws-lambda-function/#overview","title":"Overview","text":"<p>AWS Lambda is AWS' function-as-a-service offering that provides a serverless execution environment for your code. AWS Lambda functions are commonly used to:</p> <ul> <li>Extend Astra DB with additional data processing capabilities, such as aggregating, summarizing and validating data periodically;</li> <li>Connect Astra DB with other cloud services into data pipelines that move, process and analyze data.</li> </ul>"},{"location":"pages/develop/platform/aws-lambda-function/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> <li>Optionally, if you are new to AWS Lambda, practice creating a simpler function first.</li> </ul>"},{"location":"pages/develop/platform/aws-lambda-function/#using-python-driver","title":"Using Python Driver","text":""},{"location":"pages/develop/platform/aws-lambda-function/#1-create-a-deployment-package","title":"\u2705 1.  Create a deployment package.","text":"<p>A deployment package is a <code>.zip</code> file with a function source code and dependencies. To access Astra DB from a function using Python Driver, we must add cassandra-driver, a Python client library for Apache Cassandra, DataStax Astra DB and DataStax Enterprise, as a dependency. In addition, as part of the deployment package, we need to include a secure connect bundle for a database in Astra DB that we want to query.</p> <ol> <li> <p>Open a command prompt and create a project directory: <pre><code>mkdir lambda-astra-db-project\ncd lambda-astra-db-project\n</code></pre></p> </li> <li> <p>Create file <code>lambda_function.py</code> with the function source code: <pre><code>from cassandra.cluster import Cluster\nfrom cassandra.auth import PlainTextAuthProvider\nimport os\nASTRA_DB_CLIENT_ID = os.environ.get('ASTRA_DB_CLIENT_ID')\nASTRA_DB_CLIENT_SECRET = os.environ.get('ASTRA_DB_CLIENT_SECRET')\ncloud_config= {\n'secure_connect_bundle': 'secure-connect-bundle-for-your-database.zip',\n'use_default_tempdir': True\n}\nauth_provider = PlainTextAuthProvider(ASTRA_DB_CLIENT_ID, ASTRA_DB_CLIENT_SECRET)\ncluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\nsession = cluster.connect()\ndef lambda_handler(event, context):\nrow = session.execute(\"SELECT cql_version FROM system.local WHERE key = 'local';\").one()\ncql_version = row[0]\nprint(cql_version) \nprint('Success')\nreturn cql_version\n</code></pre> You can learn more about the code above by reading the cassandra-driver documentation.</p> </li> <li> <p>Install the cassandra-driver library: <pre><code>pip install --target . cassandra-driver\n</code></pre></p> </li> <li> <p>Download the Secure Connect Bundle for your database and copy it into the project directory.</p> </li> <li> <p>Create a deployment package with <code>lambda_function.py</code>, <code>cassandra-driver</code>, and secure connect bundle: <pre><code>zip -r lambda-astra-db-deployment-package.zip .\n</code></pre></p> </li> </ol>"},{"location":"pages/develop/platform/aws-lambda-function/#2-create-a-function","title":"\u2705 2.  Create a function.","text":"<ol> <li> <p>Go to the Functions page of the Lambda console and click Create function. </p> </li> <li> <p>Choose Author from scratch.</p> </li> <li> <p>Under the Basic information section, specify preferred Function name, Runtime, and Architecture. </p> </li> <li> <p>Click Create function.</p> </li> <li> <p>Under the Code tab and the Code source section, select Upload from and upload the deployment package created in the previous steps.   Since the deployment package exceeds 3 MBs, the Console Editor may not be available to view the source code: </p> </li> <li> <p>Under the Configuration tab, select and create these Environment variables:</p> <ul> <li><code>ASTRA_DB_CLIENT_ID</code>: A Client ID is generated together with an application token (see the Prerequisites section above).</li> <li><code>ASTRA_DB_CLIENT_SECRET</code>: A Client secret is generated together with an application token (see the Prerequisites section above).  Note that, for better security, you can alternatively use the AWS Secret Manager service to store and manage client id and secret, and then retrieve them programmatically. </li> </ul> </li> <li> <p>Optionally, to optimize function performance, consider configuring reserved and provisioned concurrency under the Configuration tab.</p> </li> </ol>"},{"location":"pages/develop/platform/aws-lambda-function/#3-test-the-function","title":"\u2705 3.  Test the function.","text":"<p>Under the Test tab, click the Test button and observe the output.  Notice the CQL version output and return value of 3.4.5.</p>"},{"location":"pages/develop/platform/aws-lambda-function/#using-python-sdk","title":"Using Python SDK","text":""},{"location":"pages/develop/platform/aws-lambda-function/#1-create-a-deployment-package_1","title":"\u2705 1.  Create a deployment package.","text":"<p>A deployment package is a <code>.zip</code> file with a function source code and dependencies. To access Astra DB from a function using REST API, we must add AstraPy, a Pythonic SDK for DataStax Astra and Stargate, as a dependency.</p> <ol> <li> <p>Open a command prompt and create a project directory: <pre><code>mkdir lambda-astra-db-project\ncd lambda-astra-db-project\n</code></pre></p> </li> <li> <p>Create file <code>lambda_function.py</code> with the function source code: <pre><code>from astrapy.rest import create_client, http_methods\nimport os\nASTRA_DB_ID = os.environ.get('ASTRA_DB_ID')\nASTRA_DB_REGION = os.environ.get('ASTRA_DB_REGION')\nASTRA_DB_APPLICATION_TOKEN = os.environ.get('ASTRA_DB_APPLICATION_TOKEN')\nastra_http_client = create_client(astra_database_id=ASTRA_DB_ID,\nastra_database_region=ASTRA_DB_REGION,\nastra_application_token=ASTRA_DB_APPLICATION_TOKEN)\ndef lambda_handler(event, context):\nres = astra_http_client.request(\nmethod=http_methods.GET,\npath=f\"/api/rest/v2/keyspaces/system/local/local\"\n)\ncql_version = res[\"data\"][0]['cql_version']\nprint(cql_version) \nprint('Success')\nreturn cql_version\n</code></pre> You can learn more about the code above by reading the AstraPy documentation.</p> </li> <li> <p>Install the AstraPy library: <pre><code>pip install --target . astrapy\n</code></pre></p> </li> <li> <p>Create a deployment package with <code>lambda_function.py</code> and <code>astrapy</code>: <pre><code>zip -r lambda-astra-db-deployment-package.zip .\n</code></pre></p> </li> </ol>"},{"location":"pages/develop/platform/aws-lambda-function/#2-create-a-function_1","title":"\u2705 2.  Create a function.","text":"<ol> <li> <p>Go to the Functions page of the Lambda console and click Create function. </p> </li> <li> <p>Choose Author from scratch.</p> </li> <li> <p>Under the Basic information section, specify preferred Function name, Runtime, and Architecture. </p> </li> <li> <p>Click Create function.</p> </li> <li> <p>Under the Code tab and the Code source section, select Upload from and upload the deployment package created in the previous steps.  </p> </li> <li> <p>Verify that the uploaded function has the correct <code>lambda_function.py</code> and dependencies:  You can learn more about the code above by reading the AstraPy documentation.</p> </li> <li> <p>Click Deploy to deploy the function.</p> </li> <li> <p>Under the Configuration tab, select and create these Environment variables:</p> <ul> <li><code>ASTRA_DB_ID</code>: A Database ID value can be found on the Astra DB dashboard.</li> <li><code>ASTRA_DB_REGION</code>: A Region name can be found on the overview page for a specific Astra DB database.</li> <li><code>ASTRA_DB_APPLICATION_TOKEN</code>: An Application Token can be generated for a specific Astra DB database (see the Prerequisites section above).  Note that, for better security, you can alternatively use the AWS Secret Manager service to store and manage an application token as a secret. A secret can then be retrieved programmatically. </li> </ul> </li> <li> <p>Optionally, to optimize function performance, consider configuring reserved and provisioned concurrency under the Configuration tab.</p> </li> </ol>"},{"location":"pages/develop/platform/aws-lambda-function/#3-test-the-function_1","title":"\u2705 3.  Test the function.","text":"<p>Under the Test tab, click the Test button and observe the output.  Notice the CQL version output and return value of 3.4.5.</p>"},{"location":"pages/develop/platform/aws-lambda-function/#using-java-driver","title":"Using Java Driver","text":""},{"location":"pages/develop/platform/aws-lambda-function/#1-create-a-deployment-package_2","title":"\u2705 1.  Create a deployment package.","text":"<p>A deployment package is a <code>.zip</code> or <code>.jar</code> file archive with compiled function code and dependencies. In this tutorial, we use Apache Maven\u2122 to create, compile and package a function into a <code>.jar</code> file. We need to include the following pieces into a deployment package to access Astra DB from an AWS Lambda function: a) aws-lambda-java-core that defines necessary interfaces and classes to create functions; b) java-driver that enables connectivity to Apache Cassandra, DataStax Astra DB and DataStax Enterprise; and c) secure connect bundle for a database in Astra DB that we want to query.</p> <ol> <li> <p>Open a command prompt and create a new project using Apache Maven\u2122: <pre><code>mvn archetype:generate -DgroupId=com.example -DartifactId=AstraDBFunction -DinteractiveMode=false\n</code></pre></p> </li> <li> <p>Rename file <code>App.java</code> to <code>AstraDBFunction.java</code> and replace its content with the function source code: <pre><code>package com.example;\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport com.datastax.oss.driver.api.core.CqlSession;\nimport com.datastax.oss.driver.api.core.cql.ResultSet;\nimport com.datastax.oss.driver.api.core.cql.Row;\nimport java.nio.file.Paths;\nimport java.util.Map;\npublic class AstraDBFunction implements RequestHandler&lt;Map&lt;String,String&gt;, String&gt;{\nprivate static final String ASTRA_DB_CLIENT_ID = System.getenv(\"ASTRA_DB_CLIENT_ID\");\nprivate static final String ASTRA_DB_CLIENT_SECRET = System.getenv(\"ASTRA_DB_CLIENT_SECRET\");\nprivate static CqlSession session = CqlSession.builder()\n.withCloudSecureConnectBundle(Paths.get(\"secure-connect-bundle-for-your-database.zip\"))\n.withAuthCredentials(ASTRA_DB_CLIENT_ID,ASTRA_DB_CLIENT_SECRET)\n.build();\npublic String handleRequest(Map&lt;String,String&gt; event, Context context)\n{\nLambdaLogger logger = context.getLogger();\nResultSet rs = session.execute(\"SELECT cql_version FROM system.local WHERE key = 'local';\");\nRow row = rs.one();\nString response = row.getString(\"cql_version\");\nlogger.log(response + \" Success \\n\"); return response;\n}  }\n</code></pre> You can learn more about the code above by reading the java-driver documentation.</p> </li> <li> <p>In the project directory, under <code>/src/main</code>, create directory <code>resources</code>.</p> </li> <li> <p>Download the Secure Connect Bundle for your database and copy it into the <code>resources</code> directory. The project directory structure should look like this: </p> </li> <li> <p>Add AWS Lambda and Java Driver dependencies to the <code>pom.xml</code> file: <pre><code>    &lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;aws-lambda-java-core&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/com.amazonaws/aws-lambda-java-core/1.2.2/versions --&gt;\n&lt;version&gt;1.2.2&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;aws-lambda-java-events&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/com.amazonaws/aws-lambda-java-events/3.11.0/versions --&gt;\n&lt;version&gt;3.11.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;aws-lambda-java-log4j2&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/com.amazonaws/aws-lambda-java-log4j2/1.5.1/versions --&gt;\n&lt;version&gt;1.5.1&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.oss&lt;/groupId&gt;\n&lt;artifactId&gt;java-driver-core&lt;/artifactId&gt;\n&lt;!--Use the latest version from https://search.maven.org/artifact/com.datastax.oss/java-driver-core --&gt;\n&lt;version&gt;4.15.0&lt;/version&gt;\n&lt;/dependency&gt;  </code></pre></p> </li> <li> <p>Add or replace an existing <code>build</code> section in the <code>pom.xml</code> file with the following: <pre><code>  &lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n&lt;version&gt;2.22.2&lt;/version&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;\n&lt;version&gt;3.2.2&lt;/version&gt;\n&lt;configuration&gt;\n&lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt;\n&lt;filters&gt;\n&lt;filter&gt;\n&lt;artifact&gt;*:*&lt;/artifact&gt;\n&lt;excludes&gt;\n&lt;exclude&gt;**/Log4j2Plugins.dat&lt;/exclude&gt;\n&lt;/excludes&gt;\n&lt;/filter&gt;\n&lt;/filters&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;phase&gt;package&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;shade&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n&lt;version&gt;3.8.1&lt;/version&gt;\n&lt;configuration&gt;\n&lt;source&gt;11&lt;/source&gt;\n&lt;target&gt;11&lt;/target&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre></p> </li> <li> <p>Run the Maven command in the project directory to compile code and create a <code>.jar</code> file: <pre><code> mvn clean compile package\n</code></pre> Find the deployment package file <code>AstraDBFunction-1.0-SNAPSHOT.jar</code> under the <code>target</code> directory: </p> </li> </ol>"},{"location":"pages/develop/platform/aws-lambda-function/#2-create-a-function_2","title":"\u2705 2.  Create a function.","text":"<ol> <li> <p>Go to the Functions page of the Lambda console and click Create function. </p> </li> <li> <p>Choose Author from scratch.</p> </li> <li> <p>Under the Basic information section, specify preferred Function name, Runtime, and Architecture. </p> </li> <li> <p>Click Create function.</p> </li> <li> <p>Under the Code tab and the Code source section, select Upload from and upload the deployment package created in the previous steps.   Since the deployment package exceeds 3 MBs, the Console Editor may not be available to view the source code: </p> </li> <li> <p>Under the Code tab, change Handler in section Runtime settings to <code>com.example.AstraDBFunction::handleRequest</code>: </p> </li> <li> <p>Under the Configuration tab, select and create these Environment variables:</p> <ul> <li><code>ASTRA_DB_CLIENT_ID</code>: A Client ID is generated together with an application token (see the Prerequisites section above).</li> <li><code>ASTRA_DB_CLIENT_SECRET</code>: A Client secret is generated together with an application token (see the Prerequisites section above).  Note that, for better security, you can alternatively use the AWS Secret Manager service to store and manage client id and secret, and then retrieve them programmatically. </li> </ul> </li> <li> <p>Optionally, to optimize function performance, consider configuring reserved and provisioned concurrency under the Configuration tab. For optimized cold start performance, use provisioned concurrency instead of Lambda SnapStart. In case of Lambda SnapStart, database session connections have to be re-initialized after a snapshot is restored, resulting in a substantial performance hit. </p> </li> </ol>"},{"location":"pages/develop/platform/aws-lambda-function/#3-test-the-function_2","title":"\u2705 3.  Test the function.","text":"<p>Under the Test tab, click the Test button and observe the output.  Notice the CQL version output and return value of 3.4.5.</p>"},{"location":"pages/develop/platform/aws-lambda-function/#using-java-grpc","title":"Using Java gRPC","text":""},{"location":"pages/develop/platform/aws-lambda-function/#1-create-a-deployment-package_3","title":"\u2705 1.  Create a deployment package.","text":"<p>A deployment package is a <code>.zip</code> or <code>.jar</code> file archive with compiled function code and dependencies. In this tutorial, we use Apache Maven\u2122 to create, compile and package a function into a <code>.jar</code> file. We need to include the following pieces into a deployment package to access Astra DB from an AWS Lambda function:   - aws-lambda-java-core that defines necessary interfaces and classes to create functions;   - Stargate that enables connectivity to Apache Cassandra, DataStax Astra DB and DataStax Enterprise; and   - gRPC that works as a high performance Remote Procedure Call (RPC) framework.</p> <ol> <li> <p>Open a command prompt and create a new project using Apache Maven\u2122: <pre><code>mvn archetype:generate -DgroupId=com.example -DartifactId=AstraDBFunction -DinteractiveMode=false\n</code></pre>  The project directory structure should look like this: </p> </li> <li> <p>Rename file <code>App.java</code> to <code>AstraDBFunction.java</code> and replace its content with the function source code: <pre><code>package com.example;\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.LambdaLogger;\nimport java.util.Map;\nimport io.grpc.ManagedChannel;\nimport io.grpc.ManagedChannelBuilder;\nimport io.stargate.grpc.StargateBearerToken;\nimport io.stargate.proto.QueryOuterClass;\nimport io.stargate.proto.QueryOuterClass.Row;\nimport io.stargate.proto.StargateGrpc;\npublic class AstraDBFunction implements RequestHandler&lt;Map&lt;String,String&gt;, String&gt;{\nprivate static final String ASTRA_DB_TOKEN    = System.getenv(\"ASTRA_DB_APPLICATION_TOKEN\");\nprivate static final String ASTRA_DB_ID       = System.getenv(\"ASTRA_DB_ID\");\nprivate static final String ASTRA_DB_REGION   = System.getenv(\"ASTRA_DB_REGION\");\npublic static ManagedChannel channel = ManagedChannelBuilder\n.forAddress(ASTRA_DB_ID + \"-\" + ASTRA_DB_REGION + \".apps.astra.datastax.com\", 443)\n.useTransportSecurity()\n.build();\npublic static StargateGrpc.StargateBlockingStub blockingStub =\nStargateGrpc.newBlockingStub(channel).withCallCredentials(new StargateBearerToken(ASTRA_DB_TOKEN));\npublic String handleRequest(Map&lt;String,String&gt; event, Context context)\n{\nLambdaLogger logger = context.getLogger();\nQueryOuterClass.Response queryString = blockingStub.executeQuery(QueryOuterClass\n.Query.newBuilder()\n.setCql(\"SELECT cql_version FROM system.local WHERE key = 'local';\")\n.build());\nQueryOuterClass.ResultSet rs = queryString.getResultSet();\nString response = rs.getRows(0).getValues(0).getString();\nlogger.log(response + \" Success \\n\"); return response;\n}  }\n</code></pre> You can learn more about the code above by reading the Stargate documentation.</p> </li> <li> <p>Add AWS Lambda, Stargate and gRPC dependencies to the <code>pom.xml</code> file: <pre><code>    &lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;aws-lambda-java-core&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/com.amazonaws/aws-lambda-java-core/1.2.2/versions --&gt;\n&lt;version&gt;1.2.1&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;aws-lambda-java-events&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/com.amazonaws/aws-lambda-java-events/3.11.0/versions --&gt;\n&lt;version&gt;3.11.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n&lt;artifactId&gt;aws-lambda-java-log4j2&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/com.amazonaws/aws-lambda-java-log4j2/1.5.1/versions --&gt;\n&lt;version&gt;1.5.1&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.stargate.grpc&lt;/groupId&gt;\n&lt;artifactId&gt;grpc-proto&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/io.stargate.grpc/grpc-proto/2.0.4/versions --&gt;\n&lt;version&gt;1.0.41&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.grpc&lt;/groupId&gt;\n&lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/io.grpc/grpc-netty-shaded/1.51.1/versions --&gt;\n&lt;version&gt;1.41.0&lt;/version&gt;\n&lt;/dependency&gt;   </code></pre></p> </li> <li> <p>Add or replace an existing <code>build</code> section in the <code>pom.xml</code> file with the following: <pre><code>  &lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n&lt;version&gt;2.22.2&lt;/version&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;\n&lt;version&gt;3.2.2&lt;/version&gt;\n&lt;configuration&gt;\n&lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;phase&gt;package&lt;/phase&gt;\n&lt;goals&gt;\n&lt;goal&gt;shade&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n&lt;version&gt;3.8.1&lt;/version&gt;\n&lt;configuration&gt;\n&lt;source&gt;1.8&lt;/source&gt;\n&lt;target&gt;1.8&lt;/target&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre></p> </li> <li> <p>Run the Maven command in the project directory to compile code and create a <code>.jar</code> file: <pre><code> mvn clean compile package\n</code></pre> Find the deployment package file <code>AstraDBFunction-1.0-SNAPSHOT.jar</code> under the <code>target</code> directory: </p> </li> </ol>"},{"location":"pages/develop/platform/aws-lambda-function/#2-create-a-function_3","title":"\u2705 2.  Create a function.","text":"<ol> <li> <p>Go to the Functions page of the Lambda console and click Create function. </p> </li> <li> <p>Choose Author from scratch.</p> </li> <li> <p>Under the Basic information section, specify preferred Function name, Runtime, and Architecture. </p> </li> <li> <p>Click Create function.</p> </li> <li> <p>Under the Code tab and the Code source section, select Upload from and upload the deployment package created in the previous steps.   Since the deployment package exceeds 3 MBs, the Console Editor may not be available to view the source code: </p> </li> <li> <p>Under the Code tab, change Handler in section Runtime settings to <code>com.example.AstraDBFunction::handleRequest</code>: </p> </li> <li> <p>Under the Configuration tab, select and create these Environment variables:</p> <ul> <li><code>ASTRA_DB_ID</code>: A Database ID value can be found on the Astra DB dashboard.</li> <li><code>ASTRA_DB_REGION</code>: A Region name can be found on the overview page for a specific Astra DB database.</li> <li><code>ASTRA_DB_APPLICATION_TOKEN</code>: An Application Token can be generated for a specific Astra DB database (see the Prerequisites section above).  Note that, for better security, you can alternatively use the AWS Secret Manager service to store and manage an application token as a secret. A secret can then be retrieved programmatically. </li> </ul> </li> <li> <p>Optionally, to optimize function performance, consider configuring reserved and provisioned concurrency under the Configuration tab. For optimized cold start performance, prefer provisioned concurrency to Lambda SnapStart. For Lambda SnapStart to result in meaningful performance savings, a function needs to have substantial initiatization costs. </p> </li> </ol>"},{"location":"pages/develop/platform/aws-lambda-function/#3-test-the-function_3","title":"\u2705 3.  Test the function.","text":"<p>Under the Test tab, click the Test button and observe the output.  Notice the CQL version output and return value of 3.4.5.</p>"},{"location":"pages/develop/platform/azure-function/","title":"Azure Functions","text":""},{"location":"pages/develop/platform/azure-function/#azure-functions","title":"Azure Functions","text":""},{"location":"pages/develop/platform/azure-function/#overview","title":"Overview","text":"<p>Azure Functions is Microsoft Azure's function-as-a-service offering that provides a serverless execution environment for your code. Azure Functions are commonly used to:</p> <ul> <li>Extend Astra DB with additional data processing capabilities, such as aggregating, summarizing and validating data periodically;</li> <li>Connect Astra DB with other cloud services into data pipelines that move, process and analyze data.</li> </ul>"},{"location":"pages/develop/platform/azure-function/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> </ul>"},{"location":"pages/develop/platform/azure-function/#using-python-driver","title":"Using Python Driver","text":""},{"location":"pages/develop/platform/azure-function/#1-create-a-function","title":"\u2705 1. Create a function.","text":"<ol> <li> <p>Follow the Quickstart to create a Python function in Azure from the command line using the <code>v1</code> Python programming model and Azure CLI. Complete all the steps to successfully deploy and test the function in Azure.</p> </li> <li> <p>Use Azure CLI to add these runtime environment variables to the application settings:</p> <ul> <li><code>ASTRA_DB_CLIENT_ID</code>: A Client ID is generated together with an application token (see the Prerequisites section above).</li> <li><code>ASTRA_DB_CLIENT_SECRET</code>: A Client secret is generated together with an application token (see the Prerequisites section above). <pre><code>az functionapp config appsettings set --name &lt;APP_NAME&gt; --resource-group &lt;RESOURCE_GROUP_NAME&gt; --settings \"ASTRA_DB_CLIENT_ID=Hdisr...\"\naz functionapp config appsettings set --name &lt;APP_NAME&gt; --resource-group &lt;RESOURCE_GROUP_NAME&gt; --settings \"ASTRA_DB_CLIENT_SECRET=UB3Tm8cR,Ic...\"\n</code></pre> Note that <code>&lt;APP_NAME&gt;</code> and <code>&lt;RESOURCE_GROUP_NAME&gt;</code> must be replaced with correct application and resurce group names used in the previous step. Similarly, <code>ASTRA_DB_CLIENT_ID</code> and <code>ASTRA_DB_CLIENT_SECRET</code> must be assigned correct values generated for your database.</li> </ul> </li> <li> <p>Copy the secure connect bundle file to the project directory. (See the Prerequisites section above if you need to download your secure connect bundle.)</p> </li> <li> <p>Add cassandra-driver, a Python client library for Apache Cassandra, DataStax Astra DB and DataStax Enterprise, to the <code>requirements.txt</code> file: </p> </li> <li> <p>Replace the <code>__init__.py</code> content with: <pre><code>from cassandra.cluster import Cluster\nfrom cassandra.auth import PlainTextAuthProvider\nimport logging\nimport azure.functions as func\nimport os\nASTRA_DB_CLIENT_ID = os.environ['ASTRA_DB_CLIENT_ID']\nASTRA_DB_CLIENT_SECRET = os.environ['ASTRA_DB_CLIENT_SECRET']\ncloud_config= {\n'secure_connect_bundle': 'secure-connect-bundle-for-your-database.zip',\n'use_default_tempdir': True\n}\nauth_provider = PlainTextAuthProvider(ASTRA_DB_CLIENT_ID, ASTRA_DB_CLIENT_SECRET)\ncluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\ndef main(req: func.HttpRequest) -&gt; func.HttpResponse:    \nsession = cluster.connect()\nrow = session.execute(\"SELECT cql_version FROM system.local WHERE key = 'local';\").one()\ncql_version = row[0]   \nlogging.info(f\"{cql_version} Success\")\nreturn func.HttpResponse(f\"{cql_version} Success\")\n</code></pre> You can learn more about the code above by reading the python-driver documentation. Note that <code>secure-connect-bundle-for-your-database.zip</code> must be replaced with a correct file name for your secure connect bundle.</p> </li> </ol>"},{"location":"pages/develop/platform/azure-function/#2-deploy-the-function","title":"\u2705 2. Deploy the function.","text":"<ol> <li> <p>Use Astra CLI to deploy the updated function: <pre><code>func azure functionapp publish &lt;APP_NAME&gt;\n</code></pre></p> </li> <li> <p>On the Microsoft Azure portal, find the newly deployed function: </p> </li> </ol>"},{"location":"pages/develop/platform/azure-function/#3-test-the-function","title":"\u2705 3. Test the function.","text":"<ol> <li> <p>Under Developer, select Code + Test and then Test/Run. Locate the Run button: </p> </li> <li> <p>Click Run and observe the output and logs:  Notice the CQL version output 3.4.5 and status code 200.</p> </li> </ol>"},{"location":"pages/develop/platform/azure-function/#using-python-sdk","title":"Using Python SDK","text":""},{"location":"pages/develop/platform/azure-function/#1-create-a-function_1","title":"\u2705 1. Create a function.","text":"<ol> <li> <p>Follow the Quickstart to create a Python function in Azure from the command line using the <code>v1</code> Python programming model and Azure CLI. Complete all the steps to successfully deploy and test the function in Azure.</p> </li> <li> <p>Use Azure CLI to add these runtime environment variables to the application settings:</p> <ul> <li><code>ASTRA_DB_ID</code>: A Database ID value can be found on the Astra DB dashboard.</li> <li><code>ASTRA_DB_REGION</code>: A Region name can be found on the overview page for a specific Astra DB database.</li> <li><code>ASTRA_DB_APPLICATION_TOKEN</code>: An Application Token can be generated for a specific Astra DB database (see the Prerequisites section above). <pre><code>az functionapp config appsettings set --name &lt;APP_NAME&gt; --resource-group &lt;RESOURCE_GROUP_NAME&gt; --settings \"ASTRA_DB_ID=0c2f6f34-41ea-...\"\naz functionapp config appsettings set --name &lt;APP_NAME&gt; --resource-group &lt;RESOURCE_GROUP_NAME&gt; --settings \"ASTRA_DB_REGION=us-east1\"\naz functionapp config appsettings set --name &lt;APP_NAME&gt; --resource-group &lt;RESOURCE_GROUP_NAME&gt; --settings \"ASTRA_DB_APPLICATION_TOKEN=AstraCS:avDWzU...\"\n</code></pre> Note that <code>&lt;APP_NAME&gt;</code> and <code>&lt;RESOURCE_GROUP_NAME&gt;</code> must be replaced with correct application and resurce group names used in the previous step. Similarly, <code>ASTRA_DB_ID</code>, <code>ASTRA_DB_REGION</code> and <code>ASTRA_DB_APPLICATION_TOKEN</code> must be assigned correct values associated with your database.</li> </ul> </li> <li> <p>Add AstraPy, a Pythonic SDK for DataStax Astra and Stargate, to the <code>requirements.txt</code> file: </p> </li> <li> <p>Replace the <code>__init__.py</code> content with: <pre><code>from astrapy.rest import create_client, http_methods\nimport logging\nimport azure.functions as func\nimport os\nASTRA_DB_ID = os.environ['ASTRA_DB_ID']\nASTRA_DB_REGION = os.environ['ASTRA_DB_REGION']\nASTRA_DB_APPLICATION_TOKEN = os.environ['ASTRA_DB_APPLICATION_TOKEN']\nastra_http_client = create_client(astra_database_id=ASTRA_DB_ID,\nastra_database_region=ASTRA_DB_REGION,\nastra_application_token=ASTRA_DB_APPLICATION_TOKEN)\ndef main(req: func.HttpRequest) -&gt; func.HttpResponse:    \nres = astra_http_client.request(\nmethod=http_methods.GET,\npath=f\"/api/rest/v2/keyspaces/system/local/local\"\n)\ncql_version = res[\"data\"][0]['cql_version']   \nlogging.info(f\"{cql_version} Success\")\nreturn func.HttpResponse(f\"{cql_version} Success\")\n</code></pre> You can learn more about the code above by reading the AstraPy documentation.</p> </li> </ol>"},{"location":"pages/develop/platform/azure-function/#2-deploy-the-function_1","title":"\u2705 2. Deploy the function.","text":"<ol> <li> <p>Use Astra CLI to deploy the updated function: <pre><code>func azure functionapp publish &lt;APP_NAME&gt;\n</code></pre></p> </li> <li> <p>On the Microsoft Azure portal, find the newly deployed function: </p> </li> </ol>"},{"location":"pages/develop/platform/azure-function/#3-test-the-function_1","title":"\u2705 3. Test the function.","text":"<ol> <li> <p>Under Developer, select Code + Test and then Test/Run. Locate the Run button: </p> </li> <li> <p>Click Run and observe the output and logs:  Notice the CQL version output 3.4.5 and status code 200.</p> </li> </ol>"},{"location":"pages/develop/platform/circleci/","title":"CircleCI","text":"<p>\ud83c\udfe0 Back to HOME</p>"},{"location":"pages/develop/platform/circleci/#overview","title":"Overview","text":"<p>CircleCI is a popular CICD (continuous integration continuous delivery) tool which integrates with your application's GitHub repository.  With CircleCI you can quickly spin-up resources to run your application's unit tests under production environment conditions.</p> <ul> <li>Reference Documentation</li> </ul>"},{"location":"pages/develop/platform/circleci/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an account with GitHub or another cloud-based code repository.</li> <li>You should have an account with CircleCI.  You can elect to sign-up with single-sign-on using GitHub (recommended).</li> <li>You should have created an Astra Database We will need the <code>database id</code> and <code>region</code> of your Astra DB instance.</li> <li>You should have an Astra Token for your application.</li> <li>This example will be for a Java / Spring Boot project, but the process here is not language dependent.</li> </ul>"},{"location":"pages/develop/platform/circleci/#steps","title":"Steps","text":""},{"location":"pages/develop/platform/circleci/#1-enable-your-project","title":"1 - Enable your project.","text":"<p>When you view your dashboard on CircleCI, click on \"Projects\" in the left nav.  This should display all of the repositories from your GitHub account.  Find the project that you want to enable with CircleCI, and click \"Set Up Project.\"</p> <p>You will then see a popup asking you to designate or create a new CircleCI <code>config.yml</code> file.  Choose the option to \"Take me to a config template that I can edit.\"</p> <p>Next, you will be prompted to pick the project's language and/or dependency manager.  This will help to generate the <code>config.yml</code> file.  For this example, I will scroll down and select Java (Maven).</p>"},{"location":"pages/develop/platform/circleci/#2-configure-your-project","title":"2 - Configure your project.","text":"<p>You should now be able to see the code to the <code>config.yml</code> file in the bottom-half of the screen. You can also get to the config editor point from the \"Projects\" screen, by clicking on the 3 dots to the right of a valid, CircleCI project repository, as shown below in figure 1.</p> <p></p> <p>Figure 1 - How to find a project's configuration file editor from the \"Projects\" screen.</p> <p>Here is a sample CircleCI <code>config.yml</code>.  This file can also be found in the following repository and branch: https://github.com/aar0np/live-coding-exercise/blob/circleci-project-setup/.circleci/config.yml</p>"},{"location":"pages/develop/platform/circleci/#sample-circleciconfigyml","title":"Sample <code>circleci/config.yml</code>","text":"<pre><code># version of CircleCI pipeline process engine.\nversion: 2.1\n\n# Define jobs\njobs:\n  build-and-test:\n    docker:\n      - image: cimg/openjdk:17.0.4\n    steps:\n      - checkout\n      - run:\n          name: Maven build\n          command: mvn -B -DskipTests clean package\n      - run:\n          name: Test\n          command: mvn test\n\n# Invoke jobs via workflows\nworkflows:\n  project-workflow:\n    jobs:\n      - build-and-test\n</code></pre> <p>In this case, we are using the Astra Spring Boot Starter Kit to connect to Astra DB.  Because of this, running a simple <code>mvn test</code> is enough for our project to open a test connection out to your Astra database.</p>"},{"location":"pages/develop/platform/circleci/#3-setting-astra-db-connection-properties","title":"3 - Setting Astra DB connection properties.","text":"<p>From the \"three dots\" menu on the project page that we used in Step 2, you can see that there is an option called \"Project Settings.\"  Click on this option, and then click \"Environment Variables\" on the left nav of the next screen.  Here you can create variables for credentials, tokens, and other sensitive properties for your project.</p> <p>Click the blue \"Add Environment Variable\" button to enter both its name and value.  For my application, I needed to add the following environment variables:</p> <ul> <li>ASTRA_DB_ID</li> <li>ASTRA_DB_APP_TOKEN</li> <li>ASTRA_DB_REGION</li> <li>ASTRA DB KEYSPACE</li> </ul> <p>A portion of the environment variable values will be obscured by Xs.  Note that you cannot edit or read existing environment variables.  For security reasons, they can only be deleted and re-created.</p>"},{"location":"pages/develop/platform/circleci/#4-running-your-cicd-pipeline","title":"4 - Running your CICD pipeline.","text":"<p>With the config.yml in place and environment variables defined, you should now be ready to run your pipeline.  Go back to the config editor, and verify that your <code>config.yml</code> shows \"green\" on the bottom.  If there is an error in the YAML, it will be in red.  From here, click on the name of the job defined in your config.  For my project, it will be the \"build-and-test\" option toward the bottom, as shown in figure 2.</p> <p></p> <p>Figure 2 - Configuration file editor screen.  Notice that my job name \"build-and-test\" is a clickable link at the bottom.</p> <p>Clicking on the job link will take you to the screen where you can run/rerun your pipeline.  Simply click on the \"Rerun\" button and select \"Rerun workflow from start\" option.  Assuming everything is properly configured and your Astra DB is not hibernated, the pipeline should complete successfully.  If it does not, click on the job link to see the individual steps, and open the failing step to troubleshoot the problem.</p>"},{"location":"pages/develop/platform/google-cloud-function/","title":"Google Cloud Functions","text":""},{"location":"pages/develop/platform/google-cloud-function/#google-cloud-functions","title":"Google Cloud Functions","text":""},{"location":"pages/develop/platform/google-cloud-function/#overview","title":"Overview","text":"<p>Cloud Functions is Google's function-as-a-service offering that provides a serverless execution environment for your code. Cloud Functions are commonly used to:</p> <ul> <li>Extend Astra DB with additional data processing capabilities, such as aggregating, summarizing and validating data periodically;</li> <li>Connect Astra DB with other cloud services into data pipelines that move, process and analyze data.</li> </ul>"},{"location":"pages/develop/platform/google-cloud-function/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> <li>Optionally, if you are new to Cloud Functions, practice creating a simpler function first.</li> </ul>"},{"location":"pages/develop/platform/google-cloud-function/#using-python-driver","title":"Using Python Driver","text":""},{"location":"pages/develop/platform/google-cloud-function/#1-create-a-secret-with-the-secure-connect-bundle-file","title":"\u2705 1. Create a secret with the secure connect bundle file.","text":"<ol> <li> <p>Go to the Secret Manager page, select a project that has Secret Manager and Cloud Functions enabled, and click Create secret.</p> </li> <li> <p>Give a Name to the secret and upload the secure connect bundle file as a Secret value. (See the Prerequisites section above if you need to download your secure connect bundle.) Optionally, customize other secret management settings. </p> </li> <li> <p>Click Create secret.</p> </li> <li> <p>On the Secret Manager page, find the newly created secret. </p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#2-create-a-function","title":"\u2705 2. Create a function.","text":"<ol> <li>Go to the Functions Overview page, select the same project that has Secret Manager and Cloud Functions enabled, and click Create function.</li> <li>Under the Basics section, specify preferred Function name and Region.</li> <li> <p>Under the Trigger section, select HTTP, Allow unauthenticated invocations, and Require HTTPS. </p> </li> <li> <p>Click Save.</p> </li> <li> <p>Under the Runtime, build, connections and security settings section, customize additional settings and create these Runtime environment variables:</p> <ul> <li><code>ASTRA_DB_CLIENT_ID</code>: A Client ID is generated together with an application token (see the Prerequisites section above).</li> <li><code>ASTRA_DB_CLIENT_SECRET</code>: A Client secret is generated together with an application token (see the Prerequisites section above).  Note that, for better security, you can alternatively use the Secret Manager service to store and manage a client secret. A secret can then be similarly exposed as an environment variable. The settings can be found under the Runtime, build, connections and security settings section, the Security tab, and the Secrets field.</li> </ul> </li> <li> <p>Under the Runtime, build, connections and security settings section and the Security, click Reference a secret. Select the previously created Secret with the secure connect bundle file, Grant the service account access to the secret, if needed, use Mounted as volume in the Reference method field, and enter secrets in the Mount path field.  Notice the final Path that should be used to access the secure connect bundle in the function code.</p> </li> <li> <p>Click Done and Next.</p> </li> <li> <p>Select Python 3.7 or your preferred version in the Runtime field.</p> </li> <li> <p>Select Inline Editor in the Source code field.</p> </li> <li> <p>Enter query_astra_db in the Entry point field.</p> </li> <li> <p>Add cassandra-driver, a Python client library for Apache Cassandra, DataStax Astra DB and DataStax Enterprise, to the <code>requirements.txt</code> file. </p> </li> <li> <p>Replace the <code>main.py</code> content with: <pre><code>from cassandra.cluster import Cluster\nfrom cassandra.auth import PlainTextAuthProvider\nimport os\nASTRA_DB_CLIENT_ID = os.environ.get('ASTRA_DB_CLIENT_ID')\nASTRA_DB_CLIENT_SECRET = os.environ.get('ASTRA_DB_CLIENT_SECRET')\ncloud_config= {\n'secure_connect_bundle': '/secrets/secure-connect-secret',\n'use_default_tempdir': True\n}\nauth_provider = PlainTextAuthProvider(ASTRA_DB_CLIENT_ID, ASTRA_DB_CLIENT_SECRET)\ncluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\ndef query_astra_db(request):\nsession = cluster.connect()\nrow = session.execute(\"SELECT cql_version FROM system.local WHERE key = 'local';\").one()\nprint(row[0])\nprint ('Success')\n</code></pre>  You can learn more about the code above by reading the python-driver documentation.</p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#3-deploy-the-function","title":"\u2705 3. Deploy the function.","text":"<ol> <li> <p>Click Deploy.</p> </li> <li> <p>On the Cloud Functions Overview page, find the newly deployed function. </p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#4-test-the-function","title":"\u2705 4. Test the function.","text":"<ol> <li> <p>Under Actions, select Test function. </p> </li> <li> <p>On the testing page, click Test the function and observe the output.  Notice the CQL version output 3.4.5 and status code 200.</p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#5-view-logs","title":"\u2705 5. View logs.","text":"<p>You can further explore the log history by either clicking on the Logs tab or the View all logs link that opens Logs Explorer.  </p>"},{"location":"pages/develop/platform/google-cloud-function/#using-python-sdk","title":"Using Python SDK","text":""},{"location":"pages/develop/platform/google-cloud-function/#1-create-a-function","title":"\u2705 1. Create a function.","text":"<ol> <li> <p>Go to the Functions Overview page, select a project that has Cloud Functions enabled, and click Create function.</p> </li> <li> <p>Under the Basics section, specify preferred Function name and Region.</p> </li> <li> <p>Under the Trigger section, select HTTP, Allow unauthenticated invocations, and Require HTTPS. </p> </li> <li> <p>Click Save.</p> </li> <li> <p>Under the Runtime, build, connections and security settings section, customize additional settings and create these Runtime environment variables:</p> <ul> <li><code>ASTRA_DB_ID</code>: A Database ID value can be found on the Astra DB dashboard.</li> <li><code>ASTRA_DB_REGION</code>: A Region name can be found on the overview page for a specific Astra DB database.</li> <li><code>ASTRA_DB_APPLICATION_TOKEN</code>: An Application Token can be generated for a specific Astra DB database (see the Prerequisites section above).  Note that, for better security, you can alternatively use the Secret Manager service to store and manage an application token as a secret. A secret can then be similarly exposed as an environment variable. The settings can be found under the Runtime, build, connections and security settings section, the Security tab, and the Secrets field.</li> </ul> </li> <li> <p>Click Next.</p> </li> <li> <p>Select Python 3.7 or your preferred version in the Runtime field.</p> </li> <li> <p>Select Inline Editor in the Source code field.</p> </li> <li> <p>Enter query_astra_db in the Entry point field.</p> </li> <li> <p>Add AstraPy, a Pythonic SDK for DataStax Astra and Stargate, and its preferred version to the <code>requirements.txt</code> file. </p> </li> <li> <p>Replace the <code>main.py</code> content with: <pre><code>from astrapy.rest import create_client, http_methods\nimport os\nASTRA_DB_ID = os.environ.get('ASTRA_DB_ID')\nASTRA_DB_REGION = os.environ.get('ASTRA_DB_REGION')\nASTRA_DB_APPLICATION_TOKEN = os.environ.get('ASTRA_DB_APPLICATION_TOKEN')\nastra_http_client = create_client(astra_database_id=ASTRA_DB_ID,\nastra_database_region=ASTRA_DB_REGION,\nastra_application_token=ASTRA_DB_APPLICATION_TOKEN)\ndef query_astra_db(request):\n# Retrieve a row with primary key value 'local'\n# from table 'local' in keyspace 'system'\nres = astra_http_client.request(\nmethod=http_methods.GET,\npath=f\"/api/rest/v2/keyspaces/system/local/local\"\n)\n# Print the 'cql_version' field value of the row\nprint(res[\"data\"][0]['cql_version']) \nprint ('Success')\n</code></pre>  You can learn more about the code above by reading the AstraPy documentation.</p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#2-deploy-the-function","title":"\u2705 2. Deploy the function.","text":"<ol> <li> <p>Click Deploy.</p> </li> <li> <p>On the Cloud Functions Overview page, find the newly deployed function. </p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#3-test-the-function","title":"\u2705 3. Test the function.","text":"<ol> <li> <p>Under Actions, select Test function. </p> </li> <li> <p>On the testing page, click Test the function and observe the output.  Notice the CQL version output 3.4.5 and status code 200.</p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#4-view-logs","title":"\u2705 4. View logs.","text":"<p>You can further explore the log history by either clicking on the Logs tab or the View all logs link that opens Logs Explorer.  </p>"},{"location":"pages/develop/platform/google-cloud-function/#using-java-driver","title":"Using Java Driver","text":""},{"location":"pages/develop/platform/google-cloud-function/#1-create-a-secret-with-the-secure-connect-bundle-file_1","title":"\u2705 1. Create a secret with the secure connect bundle file.","text":"<ol> <li> <p>Go to the Secret Manager page, select a project that has Secret Manager and Cloud Functions enabled, and click Create secret.</p> </li> <li> <p>Give a Name to the secret and upload the secure connect bundle file as a Secret value. (See the Prerequisites section above if you need to download your secure connect bundle.) Optionally, customize other secret management settings. </p> </li> <li> <p>Click Create secret.</p> </li> <li> <p>On the Secret Manager page, find the newly created secret. </p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#2-create-a-function_1","title":"\u2705 2. Create a function.","text":"<ol> <li>Go to the Functions Overview page, select the same project that has Secret Manager and Cloud Functions enabled, and click Create function.</li> <li>Under the Basics section, specify preferred Function name and Region.</li> <li> <p>Under the Trigger section, select HTTP, Allow unauthenticated invocations, and Require HTTPS. </p> </li> <li> <p>Click Save.</p> </li> <li> <p>Under the Runtime, build, connections and security settings section, customize additional settings and create these Runtime environment variables:</p> <ul> <li><code>ASTRA_DB_CLIENT_ID</code>: A Client ID is generated together with an application token (see the Prerequisites section above).</li> <li><code>ASTRA_DB_CLIENT_SECRET</code>: A Client secret is generated together with an application token (see the Prerequisites section above).  Note that, for better security, you can alternatively use the Secret Manager service to store and manage a client secret. A secret can then be similarly exposed as an environment variable. The settings can be found under the Runtime, build, connections and security settings section, the Security tab, and the Secrets field.</li> </ul> </li> <li> <p>Under the Runtime, build, connections and security settings section and the Security, click Reference a secret. Select the previously created Secret with the secure connect bundle file, Grant the service account access to the secret, if needed, use Mounted as volume in the Reference method field, and enter secrets in the Mount path field.  Notice the final Path that should be used to access the secure connect bundle in the function code.</p> </li> <li> <p>Click Done and Next.</p> </li> <li> <p>Select Java 11 or your preferred version in the Runtime field.</p> </li> <li> <p>Select Inline Editor in the Source code field.</p> </li> <li> <p>Enter com.example.AstraDBFunction in the Entry point field.</p> </li> <li> <p>Add java-driver, a Java client library for Apache Cassandra, DataStax Astra DB and DataStax Enterprise, to the <code>pom.xml</code> file: <pre><code>    &lt;dependency&gt;\n&lt;groupId&gt;com.datastax.oss&lt;/groupId&gt;\n&lt;artifactId&gt;java-driver-core&lt;/artifactId&gt;\n&lt;!--Use the latest version from https://search.maven.org/artifact/com.datastax.oss/java-driver-core --&gt;\n&lt;version&gt;4.15.0&lt;/version&gt;\n&lt;/dependency&gt;  </code></pre> </p> </li> <li> <p>Rename the <code>Example.java</code> file to <code>AstraDBFunction.java</code> and replace its content with: <pre><code>package com.example;\nimport com.google.cloud.functions.HttpFunction;\nimport com.google.cloud.functions.HttpRequest;\nimport com.google.cloud.functions.HttpResponse;\nimport java.io.BufferedWriter;\nimport com.datastax.oss.driver.api.core.CqlSession;\nimport com.datastax.oss.driver.api.core.cql.ResultSet;\nimport com.datastax.oss.driver.api.core.cql.Row;\nimport java.nio.file.Paths;\npublic class AstraDBFunction implements HttpFunction {\npublic static final String ASTRA_DB_CLIENT_ID = System.getenv(\"ASTRA_DB_CLIENT_ID\");\npublic static final String ASTRA_DB_CLIENT_SECRET = System.getenv(\"ASTRA_DB_CLIENT_SECRET\");\npublic static CqlSession session = CqlSession.builder()\n.withCloudSecureConnectBundle(Paths.get(\"/secrets/secure-connect-secret\"))\n.withAuthCredentials(ASTRA_DB_CLIENT_ID,ASTRA_DB_CLIENT_SECRET)\n.build();\npublic void service(HttpRequest request, HttpResponse response) throws Exception {\nBufferedWriter writer = response.getWriter();\nResultSet rs = session.execute(\"SELECT cql_version FROM system.local WHERE key = 'local';\");\nRow row = rs.one();\nwriter.write( row.getString(\"cql_version\") );\nwriter.newLine();\nwriter.write(\"Success\");\n}\n}\n</code></pre>  You can learn more about the code above by reading the java-driver documentation.</p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#3-deploy-the-function_1","title":"\u2705 3. Deploy the function.","text":"<ol> <li> <p>Click Deploy.</p> </li> <li> <p>On the Cloud Functions Overview page, find the newly deployed function. </p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#4-test-the-function_1","title":"\u2705 4. Test the function.","text":"<ol> <li> <p>Under Actions, select Test function. </p> </li> <li> <p>On the testing page, click Test the function and observe the output.  Notice the CQL version output 3.4.5 and status code 200.</p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#5-view-logs_1","title":"\u2705 5. View logs.","text":"<p>You can further explore the log history by either clicking on the Logs tab or the View all logs link that opens Logs Explorer.  </p>"},{"location":"pages/develop/platform/google-cloud-function/#using-java-grpc","title":"Using Java gRPC","text":""},{"location":"pages/develop/platform/google-cloud-function/#1-create-a-function_1","title":"\u2705 1. Create a function.","text":"<ol> <li>Go to the Functions Overview page, select a project that has Cloud Functions enabled, and click Create function.</li> <li>Under the Basics section, specify preferred Function name and Region.</li> <li> <p>Under the Trigger section, select HTTP, Allow unauthenticated invocations, and Require HTTPS. </p> </li> <li> <p>Click Save.</p> </li> <li> <p>Under the Runtime, build, connections and security settings section, customize additional settings and create these Runtime environment variables:</p> <ul> <li><code>ASTRA_DB_ID</code>: A Database ID value can be found on the Astra DB dashboard.</li> <li><code>ASTRA_DB_REGION</code>: A Region name can be found on the overview page for a specific Astra DB database.</li> <li><code>ASTRA_DB_APPLICATION_TOKEN</code>: An Application Token can be generated for a specific Astra DB database (see the Prerequisites section above).  Note that, for better security, you can alternatively use the Secret Manager service to store and manage an application token as a secret. A secret can then be similarly exposed as an environment variable. The settings can be found under the Runtime, build, connections and security settings section, the Security tab, and the Secrets field.</li> </ul> </li> <li> <p>Click Next.</p> </li> <li> <p>Select Java 11 or your preferred version in the Runtime field.</p> </li> <li> <p>Select Inline Editor in the Source code field.</p> </li> <li> <p>Enter com.example.AstraDBFunction in the Entry point field.</p> </li> <li> <p>Add gRPC dependencies to the <code>pom.xml</code> file: <pre><code>    &lt;dependency&gt;\n&lt;groupId&gt;io.stargate.grpc&lt;/groupId&gt;\n&lt;artifactId&gt;grpc-proto&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/io.stargate.grpc/grpc-proto/2.0.4/versions --&gt;\n&lt;version&gt;1.0.41&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.grpc&lt;/groupId&gt;\n&lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt;\n&lt;!-- Use the latest version from https://central.sonatype.dev/artifact/io.grpc/grpc-netty-shaded/1.51.1/versions --&gt;\n&lt;version&gt;1.41.0&lt;/version&gt;\n&lt;/dependency&gt;   </code></pre> </p> </li> <li> <p>Rename the <code>Example.java</code> file to <code>AstraDBFunction.java</code> and replace its content with: <pre><code>package com.example;\nimport com.google.cloud.functions.HttpFunction;\nimport com.google.cloud.functions.HttpRequest;\nimport com.google.cloud.functions.HttpResponse;\nimport java.io.BufferedWriter;\nimport java.util.concurrent.TimeUnit;\nimport io.grpc.ManagedChannel;\nimport io.grpc.ManagedChannelBuilder;\nimport io.stargate.grpc.StargateBearerToken;\nimport io.stargate.proto.QueryOuterClass;\nimport io.stargate.proto.QueryOuterClass.Row;\nimport io.stargate.proto.StargateGrpc;\npublic class AstraDBFunction implements HttpFunction {\npublic static final String ASTRA_DB_TOKEN    = System.getenv(\"ASTRA_DB_APPLICATION_TOKEN\");\npublic static final String ASTRA_DB_ID       = System.getenv(\"ASTRA_DB_ID\");\npublic static final String ASTRA_DB_REGION   = System.getenv(\"ASTRA_DB_REGION\");\npublic static ManagedChannel channel = ManagedChannelBuilder\n.forAddress(ASTRA_DB_ID + \"-\" + ASTRA_DB_REGION + \".apps.astra.datastax.com\", 443)\n.useTransportSecurity()\n.build();\npublic static StargateGrpc.StargateBlockingStub blockingStub =\nStargateGrpc.newBlockingStub(channel).withCallCredentials(new StargateBearerToken(ASTRA_DB_TOKEN));\npublic void service(HttpRequest request, HttpResponse response) throws Exception {\nQueryOuterClass.Response queryString = blockingStub.executeQuery(QueryOuterClass\n.Query.newBuilder()\n.setCql(\"SELECT cql_version FROM system.local WHERE key = 'local';\")\n.build());\nQueryOuterClass.ResultSet rs = queryString.getResultSet();\nBufferedWriter writer = response.getWriter();\nwriter.write( rs.getRows(0).getValues(0).getString() );\nwriter.newLine();\nwriter.write(\"Success\");\n}\n}\n</code></pre>  You can learn more about the code above by reading the Stargate documentation.</p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#2-deploy-the-function_1","title":"\u2705 2. Deploy the function.","text":"<ol> <li> <p>Click Deploy.</p> </li> <li> <p>On the Cloud Functions Overview page, find the newly deployed function. </p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#3-test-the-function_1","title":"\u2705 3. Test the function.","text":"<ol> <li> <p>Under Actions, select Test function. </p> </li> <li> <p>On the testing page, click Test the function and observe the output.  Notice the CQL version output 3.4.5 and status code 200.</p> </li> </ol>"},{"location":"pages/develop/platform/google-cloud-function/#4-view-logs_1","title":"\u2705 4. View logs.","text":"<p>You can further explore the log history by either clicking on the Logs tab or the View all logs link that opens Logs Explorer.  </p>"},{"location":"pages/develop/sdk/astra-sdk-java/","title":"\u2022 Astra SDK Java","text":""},{"location":"pages/develop/sdk/astra-sdk-java/#connect-with-the-java-sdk","title":"Connect with the Java SDK","text":"<p>The Java SDK (astra-sdk-java) allows you to perform standard CRUD operations on your data using Java.</p> <p>This SDK (Software Development Kit) makes it easy to call Stargate and/or Astra services using idiomatic Java APIs. The <code>Astra SDK</code> sets up the connection to work with the AstraDB cloud-based service. You will work with the class <code>AstraClient</code>.</p> <ul> <li> <p><code>Stargate SDK</code> works with both Stargate standalone installations and Stargate deployed in Astra. With standalone Stargate deployments you will initialize the framework with the class StargateClient and provide a list of nodes (IP). To start locally please follow Stargate SDK quickstart guide. The nodes will run in Docker.</p> </li> <li> <p><code>Astra SDK</code> reuses the previous library and setup the connection to work with AstraDB cloud-based service. You work with the class AstraClient (that configure StargateClient for you). As you can see on the figure below the AstraClient handles not only Stargate Apis but also Astra Devops Api and Apache Pulsar. To get started follow the Astra SDK quickstart guide.</p> </li> <li> <p><code>Astra Spring Boot Starter</code>: Imported in a Spring Boot application, it configures both Astra SDK and Spring Data Cassandra to work with AstraDB. Configuration is read in application.yaml. The starter will initialize any beans you would need (AstraClient, CqlSession, StargateClient. To get started follow the Astra Spring Boot Starter QuickStart guide.</p> </li> </ul>"},{"location":"pages/develop/sdk/astra-sdk-java/#1-prerequisites","title":"1 Prerequisites","text":"<ol> <li>Java Development Kit (JDK) 8+</li> </ol> <p>Use reference documentation to install a Java Development Kit. Validate your installation with:</p> <pre><code>java --version\n</code></pre> <ol> <li>Apache Maven (3.8+)</li> </ol> <p>The different samples and tutorials have been designed with <code>Apache Maven</code>. Use the reference documentation to install maven. Validate your installation with:</p> <pre><code>mvn -version\n</code></pre> <ol> <li>An Application Token (create a new one here) with the appropriate role set (API Admin User is needed for example below).</li> </ol>"},{"location":"pages/develop/sdk/astra-sdk-java/#2-quickstart","title":"2 Quickstart","text":""},{"location":"pages/develop/sdk/astra-sdk-java/#project-creation","title":"Project Creation","text":"<ol> <li>Use maven to generate a project template</li> </ol> <pre><code>mvn archetype:generate \\\n  -DarchetypeGroupId=org.apache.maven.archetypes \\\n  -DarchetypeArtifactId=maven-archetype-quickstart \\\n  -DarchetypeVersion=1.4 \\\n  -DgroupId=com.datastax.tutorial \\\n  -DartifactId=sdk-quickstart-astra \\\n  -Dversion=1.0.0-SNAPSHOT \\\n  -DinteractiveMode=false\n</code></pre> <ol> <li>Open the project in your favourite IDE and edit <code>pom.xml</code> to add the latest version of <code>com.datastax.astra/astra-sdk</code> as dependency ()</li> </ol> <pre><code>  &lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.datastax.astra&lt;/groupId&gt;\n&lt;artifactId&gt;astra-sdk&lt;/artifactId&gt;\n&lt;version&gt;${latestSDK}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre>"},{"location":"pages/develop/sdk/astra-sdk-java/#configuration","title":"Configuration","text":"<ol> <li>Create a new class <code>AstraSdk</code> and populate the 4 variables.</li> </ol> <p>Note: Depending on the framework you will declare in a configuration file like<code>application.properties</code> and load/inject them. We're just keeping things simple for now.</p> <ol> <li>Use the following values to populate your class variables below.</li> </ol> <p>COULD WE JUST INJECT THESE DIRECT INTO THE CODE BLOCK SINCE WE'RE NO LONGER USING MARKDOWN?</p> <pre><code>    export ASTRA_DB_ID=85ce6482-cce5-4ced-b98b-274981222051\n    export ASTRA_DB_REGION=us-central1\n    export ASTRA_DB_APPLICATION_TOKEN=&lt;app_token&gt;\n</code></pre> <pre><code>import java.io.File;\nimport com.datastax.astra.sdk.AstraClient;\nimport com.datastax.oss.driver.api.core.CqlSession;\npublic class AstraSdk {\n// Your Astra Token Starting with AstraCS:....\nstatic final String ASTRA_DB_TOKEN  = \"&lt;provide_a_clientSecret&gt;\";\n// The unique identifier for your database (Astra UI: Databases dashboard)\nstatic final String ASTRA_DB_ID     = \"&lt;provide_your_database_id&gt;\";\n// The region in use for this database (Astra UI : Database Details screen)\nstatic final String ASTRA_DB_REGION = \"&lt;provide_your_database_region&gt;\";\n// The keyspace in use for this database (Astra UI : Database Details screen)\nstatic final String ASTRA_KEYSPACE  = \"&lt;provide_your_keyspace&gt;\";\n// Define a Main\npublic static void main(String[] args) {}\n}\n</code></pre> <ol> <li>Within the <code>main</code> method, define the <code>AstraClient</code> as follow. This class is the entry point to every API for astra. It must be a singleton for your application. As autocloseable we can create is in a <code>try/resources</code> code block.</li> </ol> <pre><code>try(AstraClient cli = AstraClient.builder()\n.withToken(ASTRA_DB_TOKEN) .withDatabaseId(ASTRA_DB_ID) .withDatabaseRegion(ASTRA_DB_REGION)\n.withCqlKeyspace(ASTRA_DB_KEYSPACE)\n.enableCql()  // Only if you plan to use Cql native drivers\n.enableGrpc() // Only if you plan to use Grpc API\n.build()) {\n// Here we will use AstraClient\n}\n</code></pre>"},{"location":"pages/develop/sdk/astra-sdk-java/#cql-drivers","title":"CQL Drivers","text":"<p>To access CQL Native you want to access the <code>CqlSession</code> object. It is available through <code>astraClient.cqlSession()</code>.</p> <pre><code>public void sampleUsageOfCqlNative(AstraClient astraClient) {\nString cqlVersion = astraClient.cqlSession()\n.execute(\"SELECT cql_version from system.local\")\n.one()\n.getString(\"cql_version\");\nSystem.out.println(\"CqlVersion: \" + cqlVersion);\n}\n</code></pre>"},{"location":"pages/develop/sdk/astra-sdk-java/#api-rest","title":"API Rest","text":"<p>The <code>REST API</code> (also known as <code>api Data</code>) is wrapping exposing CQL language as Rest Resources. To get more information about this API check the dedicated page</p> <pre><code>public static void sampleUsageOfRestApi(AstraClient astraClient) {\n// List keyspaces\nSystem.out.println(\"Keyspaces:\" + astraClient\n.apiStargateData()\n.keyspaceNames()\n.collect(Collectors.toList()));\n// List Tables\nSystem.out.println(\"Tables : \" + astraClient\n.apiStargateData()\n.keyspace(ASTRA_DB_KEYSPACE)\n.tableNames()\n.collect(Collectors.toList()));\n// Syntax Sugar, simplify following expressions\nTableClient tableMovies = astraClient\n.apiStargateData()\n.keyspace(ASTRA_DB_KEYSPACE)\n.table(\"movies\");\n// Create table (movies)\ntableMovies.create(CreateTable.builder().ifNotExist(true)\n.addPartitionKey(\"genre\", \"text\")\n.addClusteringKey(\"year\", \"int\", Ordering.DESC)\n.addClusteringKey(\"title\", \"text\", Ordering.ASC)\n.addColumn(\"producer\", \"text\")\n.build()\n);\n// Insert a Movie\nMap&lt;String, Object&gt; movie = new HashMap&lt;&gt;();\nmovie.put(\"genre\", \"Sci-Fi\");\nmovie.put(\"year\", 1990);\nmovie.put(\"title\", \"Avatar\");\nmovie.put(\"producer\", \"James Cameron\");\ntableMovies.upsert(movie);\n// Select Movies\ntableMovies.search(SearchTableQuery.builder()\n.where(\"genre\").isEqualsTo(\"Sci-Fi\")\n.withReturnedFields(\"title\", \"year\")\n.build())\n.getResults()\n.stream()\n.forEach(row -&gt; System.out.println(row.get(\"title\") +\n\" (\" + row.get(\"year\") + \")\"));\n// Delete a movie\ntableMovies.key(\"Sci-Fi\", 1990, \"Avatar\").delete();    }\n</code></pre> <p>More information about Rest API</p>"},{"location":"pages/develop/sdk/astra-sdk-java/#api-document","title":"API Document","text":"<p>The <code>DOCUMENT API</code> exposes an Rest Resources to use Cassandra as a document-oriented database To get more information about this API check the dedicated page.</p> <pre><code>public static void sampleUsageOfDocumentApi(AstraClient astraClient) {\n// List Namespaces\nSystem.out.println(\"Namespaces:\" + astraClient\n.apiStargateDocument()\n.namespaceNames()\n.collect(Collectors.toList()));\n// List Collections\nSystem.out.println(\"Collections : \" + astraClient\n.apiStargateDocument()\n.namespace(ASTRA_DB_KEYSPACE)\n.tableNames()\n.collect(Collectors.toList()));\n// Syntax Sugar, simplify following expressions\nCollectionClient collectionVideo = astraClient\n.apiStargateDocument()\n.namespace(ASTRA_DB_KEYSPACE)\n.collection(\"video\");\n// Create collection (video)\ncollectionVideo.create();\n// Inserting document, given a POJO Video with 2 attributes name and format\nString avatarId = collectionVideo.create(new Video(\"Avatar\", \"MP4\"));\nString workshopId = collectionVideo.create(new Video(\"Workshop\", \"MP4\"));\n// Search Documents\nQuery query = Query.builder().selectAll()\n.where(\"format\").isEqualsTo(\"MP4\")\n.build();\ncollectionVideo.findAll(query, Video.class)\n.map(Document::getDocument)\n.map(Video::getName)\n.forEach(System.out::println);\n// Delete a Document\ncollectionVideo.document(avatarId).delete();\n}\n</code></pre>"},{"location":"pages/develop/sdk/astra-sdk-java/#api-graphql","title":"APi GraphQL","text":"<p>The <code>GRAPHQL API</code> exposes a graphQL endpoint to query CQL over graphQL. To know more about this api please check the dedicated page.</p> <pre><code>public static void sampleUsageOfGraphQLApi(AstraClient astraClient) {\n// List Keyspaces\nSystem.out.println(\"Keyspaces:\" + astraClient\n.apiStargateGraphQL()\n.cqlSchema()\n.keyspaces());\n// List Tables\nString getTables = \"query GetTables {\\n\"\n+ \"  keyspace(name: \\\"\" + ASTRA_DB_KEYSPACE + \"\\\") {\\n\"\n+ \"      name\\n\"\n+ \"      tables {\\n\"\n+ \"          name\\n\"\n+ \"          columns {\\n\"\n+ \"              name\\n\"\n+ \"              kind\\n\"\n+ \"              type {\\n\"\n+ \"                  basic\\n\"\n+ \"                  info {\\n\"\n+ \"                      name\\n\"\n+ \"                  }\\n\"\n+ \"              }\\n\"\n+ \"          }\\n\"\n+ \"      }\\n\"\n+ \"  }\\n\"\n+ \"}\";\nSystem.out.println(\"Tables : \" + astraClient\n.apiStargateGraphQL()\n.cqlSchema()\n.query(getTables));\n}\n</code></pre>"},{"location":"pages/develop/sdk/astra-sdk-java/#api-grpc","title":"API Grpc","text":"<p>The <code>GRPC API</code> exposes a grpc endpoint to query some CQL. From there it is very similar from native drivers. To know more about it check the dedicated page.</p> <pre><code>public static void sampleUsageOfGrpcApi(AstraClient astraClient) {\n// Access gRPC API\nApiGrpcClient cloudNativeClient = astraClient.apiStargateGrpc();\n// Executing Query\nResultSetGrpc rs = cloudNativeClient.execute(\"SELECT data_center from system.local\");\n// Parse Results\nString datacenterName = rs.one().getString(\"data_center\");\nSystem.out.println(\"You are connected to '%s'\".formatted(datacenterName));\n} </code></pre>"},{"location":"pages/tools/","title":"Tools List","text":"<ul> <li> <p>Apache Airflow: Apache Airflow is an open source workflow management system. It provides components which allow engineers to build data pipelines between different systems.</p> </li> <li> <p>Apache Flink: Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. </p> </li> <li> <p>Apache Nifi: NiFi was built to automate the flow of data between systems. While the term 'dataflow' is used in a variety of contexts, we use it here to mean the automated and managed flow of information between systems.</p> </li> <li> <p>Apache Spark: Apache Spark is an open-source, distributed processing system used for big data workloads. It utilizes in-memory caching, and optimized query execution for fast analytic queries against data of any size. Use Apache Spark to connect to your database and begin accessing your Astra DB tables using Scala in spark-shell.</p> </li> <li> <p>Authorizer: Authorizer is an open source auth solution for application.  It works with many different databases, allowing the developers to use a single datastore for the entire application stack and have complete control over all user data.</p> </li> <li> <p>Celery: Celery is an open-source, distributed task queue written in Python. With Celery you can run tasks (e.g. processing of messages) in an asynchronous fashion. Celery supports a variety of message buses and backends; among the supported backends are Cassandra and Astra DB.</p> </li> <li> <p>Cloud Functions (Python Driver): Google's function-as-a-service offering that provides a serverless execution environment for your code. Cloud Functions are commonly used to extend Astra DB with additional data processing capabilities and connect Astra DB with other cloud services into data pipelines.</p> </li> <li> <p>Cloud Functions (Python SDK): Google's function-as-a-service offering that provides a serverless execution environment for your code. Cloud Functions are commonly used to extend Astra DB with additional data processing capabilities and connect Astra DB with other cloud services into data pipelines.</p> </li> <li> <p>CQL Proxy: cql-proxy is designed to forward your application's CQL traffic to an appropriate database service. It listens on a local address and securely forwards that traffic.</p> </li> <li> <p>CQL Shell: the standalone CQLSH client is a separate, lightweight tool you can use to interact with your database.</p> </li> <li> <p>Datagrip Jetbrains: DataGrip is a database management environment for developers. It is designed to query, create, and manage databases. Databases can work locally, on a server, or in the cloud. Supports MySQL, PostgreSQL, Microsoft SQL Server, Oracle, and more. If you have a JDBC driver, add it to DataGrip, connect to your DBMS, and start working.</p> </li> <li> <p>DataStation: DataStation is an open-source data IDE for developers.</p> </li> <li> <p>DataStax Bulk: The DataStax Bulk Loader tool (DSBulk) is a unified tool for loading into and unloading from Cassandra-compatible storage engines, such as OSS Apache Cassandra\u00ae, DataStax Astra and DataStax Enterprise (DSE).</p> </li> <li> <p>DBeaver: DBeaver is a universal database management tool for everyone who needs to work with data in a professional way. With DBeaver you are able to manipulate with your data like in a regular spreadsheet, create analytical reports based on records from different data storages, export information in an appropriate format.</p> </li> <li> <p>Feast: Feast is a feature store for machine learning whose goal is to provide a (mostly cloud-based) infrastructure for managing, versioning and sharing features for training and serving ML models.</p> </li> <li> <p>Github Actions: GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline. You can create workflows that build and test every pull request to your repository, or deploy merged pull requests to production.</p> </li> <li> <p>Grafana: Grafana is an industry standard tool for data visualisation. With Grafana, you can explore your time-series data using different visualisations: charts, plots, diagrams and even configure alerting if a value exceeds some desired range.</p> </li> <li> <p>HashiCorp Vault: Vault is an identity-based secrets and encryption management system. A secret is anything that you want to tightly control access to, such as API encryption keys, passwords, or certificates. Vault provides encryption services that are gated by authentication and authorization methods.</p> <ul> <li>Astra DB Plugin</li> </ul> </li> <li> <p>IntelliJ IDEA: The Capable &amp; Ergonomic Java IDE by JetBrains</p> </li> <li> <p>JanusGraph: JanusGraph is designed to support the processing of graphs so large that they require storage and computational capacities beyond what a single machine can provide. Scaling graph data processing for real time traversals and analytical queries is JanusGraph\u2019s foundational benefit. This section will discuss the various specific benefits of JanusGraph and its underlying, supported persistence solutions.</p> </li> <li> <p>Liquibase: Liquibase is a database schema change management solution that enables you to revise and release database changes faster and safer from development to production.</p> </li> <li> <p>Micronaut: Micronaut is a modern, JVM-based, full stack Java framework designed for building modular, easily testable JVM applications with support for Java, Kotlin, and Groovy. Micronaut is developed by the creators of the Grails framework and takes inspiration from lessons learnt over the years building real-world applications from monoliths to microservices using Spring, Spring Boot and Grails.</p> </li> <li> <p>MindsDB:MindsDB enables you to use ML predictions in your database using SQL.</p> </li> <li> <p>Pentaho Data Integration: Pentaho Data Integration (PDI) provides the Extract, Transform, and Load (ETL) capabilities that facilitate the process of capturing, cleansing, and storing data using a uniform and consistent format that is accessible and relevant to end users and IoT technologies.</p> </li> <li> <p>Quine: Quine.io is a streaming graph capable of building high-volumes of data into a stateful graph.  It allows for real-time traversals on a graph, as well as for the data to be streamed-out for event processing.</p> </li> <li> <p>StepZen: StepZen helps developers build GraphQL faster, deploy in seconds, and run on StepZen. It simplifies how you access the data you need, and with zero infrastructure to build or manage, you can focus on crafting modern data-driven experiences.</p> </li> <li> <p>TablePlus: TablePlus is a modern, native tool with elegant UI that allows you to simultaneously manage multiple databases such as MySQL, PostgreSQL, SQLite, Microsoft SQL Server and more.</p> </li> <li> <p>Temporal: Temporal.io is an open source microservice orchestration platform that assists in tracking workflows in your application development. It provides the user with a plug-and-play persistence layer that lets the user choose and configure their Temporal Server with their preferred backend.</p> </li> </ul>"},{"location":"pages/tools/databases/janusgraph/","title":"JanusGraph","text":"<ul> <li>Documented on JanusGraph official documentation</li> </ul>"},{"location":"pages/tools/databases/janusgraph/#overview","title":"Overview","text":"<p>JanusGraph is designed to support the processing of graphs so large that they require storage and computational capacities beyond those that a single machine can provide. Scaling graph data processing for real time traversals and analytical queries is JanusGraph\u2019s foundational benefit. This section will discuss the various specific benefits of JanusGraph and its underlying, supported persistence solutions.</p> <ul> <li>\u2139\ufe0f Introduction to JanusGraph</li> <li>\ud83d\udce5 JanusGraph Installation</li> </ul> <p>JanusGraph uses the Java driver to connect to Cassandra as the storage backend. The Java driver itself supports connections to Astra DB natively. For example: <pre><code>CqlSession session = CqlSession.builder()\n  .withCloudSecureConnectBundle(Paths.get(\"/path/to/secure-connect-db_name.zip\"))\n  .withAuthCredentials(\"CLIENT_ID\", \"CLIENT_SECRET\")\n  .withKeyspace(\"keyspace_name\")\n  .build();\n</code></pre></p>"},{"location":"pages/tools/databases/janusgraph/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> </ul> <p>This article assumes you have a running installation of JanusGraph server. This was written and tested on JanusGraph <code>v0.6.2</code>. If JanusGraph <code>v0.6.0</code> is used instead, refer to this article. It has not been tested on older versions of JanusGraph. </p> <p>You will need to choose which keyspace to use to store your graph. If it doesn't exist, you will need to create the keyspace on the Astra UI. For simplicity, the keyspace is created as <code>janusgraph</code>.</p>"},{"location":"pages/tools/databases/janusgraph/#installation-and-setup","title":"Installation and Setup","text":"<p>Note: For simplicity, the secure connect bundle has been placed in <code>/path/to/scb</code></p>"},{"location":"pages/tools/databases/janusgraph/#step-1-db-information","title":"\u2705 Step 1: DB Information","text":"<p>On the JanusGraph server, move your secure bundle using secure copy or other techniques. For example: <pre><code>$ cd /path/to/scb\n$ ls -l secure-connect-janusgraph.zip\n</code></pre></p> <p>We will use this information to configure Astra DB as the storage backend for JanusGraph.</p>"},{"location":"pages/tools/databases/janusgraph/#step-2-graph-storage","title":"\u2705 Step 2: Graph Storage","text":"<p>While connecting to Astra DB from JanusGraph, it is preferred to make use of the secure connect bundle file as-is without extracting it. There are multiple ways in which a secure connect bundle file can be passed on to the JanusGraph configuration to connect to Astra DB using the DataStax driver.</p> <p>On the JanusGraph server, modify the CQL storage configuration file: <pre><code>$ cd janusgraph-0.6.2\n$ vi conf/janusgraph-cql.properties\n</code></pre> Make the necessary changes using one of the two templates:</p>"},{"location":"pages/tools/databases/janusgraph/#step-2a-internal-string-configuration","title":"\u2705 Step 2a: Internal string configuration","text":"<p>Set the property <code>storage.cql.internal.string-configuration</code> to <code>datastax-java-driver { basic.cloud.secure-connect-bundle=/path/to/scb/secure-connect-janusgraph.zip }</code> and set the username, password and keyspace details.</p> <p>For example: <pre><code>gremlin.graph=org.janusgraph.core.JanusGraphFactory\nstorage.backend=cql\nstorage.cql.keyspace=&lt;keyspace name which was created in AstraDB&gt;\nstorage.username=&lt;clientID&gt;\nstorage.password=&lt;clientSecret&gt;\nstorage.cql.internal.string-configuration=datastax-java-driver { basic.cloud.secure-connect-bundle=/path/to/scb/secure-connect-janusgraph.zip }\n</code></pre></p> <p>Also, you can set a JVM argument to pass the secure connect bundle file as shown below and remove that property <code>(storage.cql.internal.string-configuration)</code> from the list above.</p> <pre><code>-Ddatastax-java-driver.basic.cloud.secure-connect-bundle=/path/to/scb/secure-connect-janusgraph.zip\n</code></pre>"},{"location":"pages/tools/databases/janusgraph/#step-2b-internal-file-configuration","title":"\u2705 Step 2b: Internal file configuration","text":"<p>Set the property <code>storage.cql.internal.file-configuration</code> to an external configuration file if you would like to externalize the astra connection related properties to a separate file and specify the secure bundle and credentials information on that file.</p> <p>For example: <pre><code>gremlin.graph=org.janusgraph.core.JanusGraphFactory\nstorage.backend=cql\nstorage.cql.keyspace=janusgraph\n# Link to the external file that DataStax driver understands\nstorage.cql.internal.file-configuration=/path/to/scb/astra.conf\n</code></pre></p> <p><code>astra.conf</code> (external file) to contain: <pre><code>datastax-java-driver {\n  basic.cloud {\n    secure-connect-bundle = \"/path/to/scb/secure-connect-janusgraph.zip\"\n  }\n  basic.request {\n    timeout = \"10 seconds\"\n  }\n  advanced.auth-provider {\n    class = PlainTextAuthProvider\n    username = \"&lt;ClientID&gt;\"\n    password = \"&lt;ClientSecret&gt;\"\n  }\n}\n</code></pre></p> <p>IMPORTANT</p> <p>The ClientID and ClientSecret are from the token you generated in the Prerequisites section above.</p> <p><pre><code>### &lt;span class=\"nosurface\"&gt;\u2705 Step 3:&lt;/span&gt; Final Test\nStart a Gremlin console:\n</code></pre> $ bin/gremlin.sh</p> <pre><code>     \\,,,/\n     (o o)\n</code></pre> <p>-----oOOo-(3)-oOOo----- gremlin&gt; <code>Load a graph using Astra as the storage backend with:</code> gremlin&gt; graph = JanusGraphFactory.open('conf/janusgraph-cql.properties') ==&gt;standardjanusgraph[cql:[70bf8560-105f-11ec-a3ea-0800200c9a66-us-west1.db.astra.datastax.com]] ``` </p> <p>Note</p> <p>It is normal to see some warnings on the Gremlin console. I have attached a text file with a sample output so you know what to expect. </p> <p>In the Astra CQL Console, I can see JanusGraph created the following tables in the <code>janusgraph</code> keyspace: ``` token@cqlsh&gt; USE janusgraph; token@cqlsh:janusgraph&gt; DESCRIBE TABLES;</p> <p>edgestore_lock_  graphindex_lock_         janusgraph_ids  txlog            systemlog                graphindex      edgestore        system_properties_lock_  system_properties ```</p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/ide/datastation/","title":"DataStation","text":""},{"location":"pages/tools/ide/datastation/#overview","title":"Overview","text":"<p>DataStation is an open-source data IDE for developers. It allows you to easily build graphs and tables with data pulled from SQL databases, logging databases, metrics databases, HTTP servers, and all kinds of text and binary files. Need to join or munge data? Write embedded scripts as needed in languages like Python, JavaScript, R or SQL. All in one application. This tutorial will show you step-by-step how to connect your Astra DB with DataStation. </p> <ul> <li>\u2139\ufe0f Introduction to DataStation</li> <li>\ud83d\udce5 DataStation Quick Install</li> </ul>"},{"location":"pages/tools/ide/datastation/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should Install DataStation</li> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>Clone this repository to use to set up CQL-Proxy which is a sidecar that enables unsupported CQL drivers to work with DataStax Astra</li> <li>You need your Astra Token and Astra Database ID to use CQL-Proxy</li> <li>Follow the steps in the repo to spin up CQL-Proxy using Terminal/Command Line. Once successfully running, you should see the following output:</li> <pre><code>{\"level\":\"info\",\"ts\":1651012815.176512,\"caller\":\"proxy/proxy.go:222\",\"msg\":\"proxy is listening\",\"address\":\"[::]:9042\"}\n</code></pre> </ul>"},{"location":"pages/tools/ide/datastation/#installation-and-setup","title":"Installation and Setup","text":"<p>Once you have completed all of the Prerequisites and confirmed CQL Proxy is running, you are now able to move on to setting up your Astra DB with DataStation IDE. </p> <ol> <li> <p>First, launch your DataStation IDE.  </p> </li> <li> <p>Click Add Data Source and select Cassandra</p> </li> <li> <p>A dialog will appear that will prompt you to name this connection (in this example I used Test) and your Cassandra credentials:</p> <ul> <li>Host - Use <code>localhost:9042</code> or <code>127.0.0.1:9042</code></li> <li>Keyspace - Enter the name of the keyspace that you want to use from your Astra DB. </li> <li>Username - Use <code>token</code></li> <li> <p>Password - From your Astra Token creation in the Prerequisites, find your Token. </p> <ul> <li>Ex. <code>AstraCS:BWsdjhdf...</code> </li> </ul> <p></p> </li> </ul> </li> <li> <p>Once you've entered your credentials, click Add Panel and select Database under IMPORT FROM. This will allow DataStation to connect with the database you are trying to view through the credentials you had just entered in the previous step. </p> </li> </ol> Note <p>DataStation IDE currently doesn't show a success message after the credentials have been entered. The Password field will also show up blank once you've minimized the credentials panel on the sidebar, but this does not necessarily mean you have to re-enter your password.</p> <ol> <li>You will know your database has been added once your display looks like this. You can name this Panel what you'd like. In this example, it is titled Test Panel.      </li> <li>To test and validate, you can run a quick query to one of the tables that are present in the Keyspace that you provided in Step 3.      </li> </ol> <p>...and you're done! This tutorial quickly shows you how you can easily integrate your Astra DB with the DataStation IDE to run queries, build tables, and further enhance how you interact with your data. </p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/ide/eclipse/","title":"\u2022 Eclipse","text":"<p>Check back soon</p> <p>Nothing to see here yet! Check back for updates! </p>"},{"location":"pages/tools/ide/gitpod/","title":"\u2022 Gitpod","text":"<p>Check back soon</p> <p>Nothing to see here yet! Check back for updates! </p>"},{"location":"pages/tools/ide/intellij/","title":"IntelliJ","text":"<ul> <li>This content has been built using Reference Documentation</li> </ul>"},{"location":"pages/tools/ide/intellij/#overview","title":"Overview","text":"<p>IntelliJ IDEA is an integrated development environment written in Java for developing computer software written in Java, Kotlin, Groovy, and other JVM-based languages. It is developed by JetBrains, and is available as an Apache 2 Licensed community edition, and in a proprietary commercial edition.</p>"},{"location":"pages/tools/ide/intellij/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should download either Community or ultimate edition of intelliJ from the Download Page</li> </ul>"},{"location":"pages/tools/ide/intellij/#installation-guide","title":"Installation Guide","text":""},{"location":"pages/tools/ide/intellij/#1-download-plugin","title":"\u2705 1. Download Plugin","text":"<p>Astra DB Explorer Installation Page</p> <ul> <li>Open the plugin panel and search for <code>astra</code></li> </ul> <pre><code>File &gt; Preferences &gt; Plugins\n</code></pre> <ul> <li>Click the <code>[INSTALL]</code> button</li> </ul> <p></p> <ul> <li>Once the plugin is downloaded and installed you will be asked to restart</li> </ul> <p></p>"},{"location":"pages/tools/ide/intellij/#2-setup-plugin","title":"\u2705 2. Setup Plugin","text":"<ul> <li>During the first restart you will got an <code>IDE error occured</code> message it is expected we will now configure the plugin</li> </ul> <ul> <li> <p>The plugin configuration is defined in a file on disk located at <code>${user.home}/.astra/config</code>. Fortunately you can do it directly in the IDE</p> </li> <li> <p>In the bottom left hand corner locate the panel <code>astra.explorer</code> and open it</p> </li> </ul> <p></p>"},{"location":"pages/tools/ide/intellij/#3-edit-profiles","title":"\u2705 3. Edit Profiles","text":"<ul> <li>In the drop down menu select <code>Edit Profiles</code> the configuration file is referred as a profile</li> </ul> <ul> <li>You will be asked if you want to create the file, click <code>[CREATE]</code></li> </ul> <ul> <li>Also pick the first option in the radio button Edit this file anyway</li> </ul> <ul> <li>The file open and the content should look like. Not that the value used for the <code>bearerToken</code> is the one starting by <code>AstraCS:....</code>. Save the file</li> </ul> <pre><code>[astraProfileFile.profiles]\ndefault = \"AstraCS:XXXX\"\n</code></pre>"},{"location":"pages/tools/ide/intellij/#4-reload-profiles","title":"\u2705 4. Reload Profiles","text":"<ul> <li>Now on the drop down menu select <code>Reload Profiles</code></li> </ul> <ul> <li>Et voila! You can now list databases on your Astra organization and for each you can see the different keyspaces</li> </ul> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/ide/postman/","title":"Postman","text":""},{"location":"pages/tools/ide/postman/#overview","title":"Overview","text":"<p>Overview of Postman. What is it? Why is it important and useful with Astra?</p> <ul> <li>\ud83d\udce5 Temporal Quick Install</li> <li>\u2139\ufe0f Introduction to Temporal</li> <li>\u2139\ufe0f Part 1: Introduction to Temporal and Cassandra, Astra DB</li> </ul>"},{"location":"pages/tools/ide/postman/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul>"},{"location":"pages/tools/ide/postman/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"pages/tools/ide/postman/#step-1","title":"\u2705 Step 1:","text":""},{"location":"pages/tools/ide/postman/#step-2","title":"\u2705 Step 2:","text":"<p>\ud83c\udfe0 Back to HOME</p>"},{"location":"pages/tools/ide/vscode/","title":"\u2022 VSCode","text":"<p>Check back soon</p> <p>Nothing to see here yet! Check back for updates! </p>"},{"location":"pages/tools/integration/apache-airflow/","title":"Apache Airflow","text":""},{"location":"pages/tools/integration/apache-airflow/#overview","title":"Overview","text":"<p>Apache Airflow is an open source workflow management system. It provides components which allow engineers to build data pipelines between different systems. These instructions will step through tasks/adjustments to be done in each product (Astra DB, cql-proxy, Apache Airflow), ultimately resulting in Airflow being able to work with AstraDB in its directed acyclic graphs (DAG).</p> <ul> <li>\u2139\ufe0f Apache Airflow Documentation</li> </ul>"},{"location":"pages/tools/integration/apache-airflow/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> <li>You should install `python3` and `pip3` (local deployment of Airflow) or Docker (docker)</li> </ul> <p>This article was written for Apache Airflow version <code>2.2.3</code> on <code>MacOS</code> with Python <code>3.9</code>.</p>"},{"location":"pages/tools/integration/apache-airflow/#installation","title":"Installation","text":""},{"location":"pages/tools/integration/apache-airflow/#download-and-install","title":"\u2705 Download and install","text":"<p>Following the Apache Airflow reference documentation download and install the software.</p>"},{"location":"pages/tools/integration/apache-airflow/#create-the-keyspace-airflow","title":"\u2705 Create the keyspace <code>airflow</code>","text":"<p>From the Astra DB dashboard, click on your database name. Scroll down to where the keyspaces are listed, and click the <code>Add Keyspace</code> button to create a new keyspace. Name this keyspace <code>airflow</code>.</p>"},{"location":"pages/tools/integration/apache-airflow/#start-cql-proxy","title":"\u2705 Start Cql Proxy","text":"<p>DataStax\u2019s cql-proxy is designed to function as an intermediate connection point to allow legacy Apache Cassandra applications to connect to DataStax Astra DB using its new Secure Connect Bundle. There are a few ways to install and run DataStax\u2019s cql-proxy, as outlined in <code>cql-proxy</code>.</p> <p>Be sure to start <code>cql-proxy</code> with the following settings:</p> <ul> <li>Using the Secure Connect Bundle downloaded in the previous section</li> <li>Binding it to the listen IP of the server instance</li> <li>Specifying the username of \u201ctoken\u201d</li> <li>Specifying the Astra Token created for the user in Astra DB as the password</li> </ul> <p>You can run <code>cql-proxy</code> (in the foreground) from the command line in this way, like this:</p> <pre><code>./cql-proxy --bundle ~/local/astraCreds/secure-connect.zip \\\n--bind 127.0.0.1 \\\n--username token \\\n--password AstraCS:rtFckUZblahblahblahblahblahblaha3953d799a525\n</code></pre> <p>Important to note that the command shown above binds <code>cql-proxy</code> to localhost (127.0.0.1), meaning it is not reachable (by Airflow) from outside the server instance.</p>"},{"location":"pages/tools/integration/apache-airflow/#create-a-new-connection-in-apache-airflow","title":"\u2705 Create a new connection in Apache Airflow","text":"<p>Inside Apache Airflow, click <code>Connections</code> from underneath the <code>Admin</code> drop-down menu. Then click on the blue button labeled with the plus sign (<code>+</code>) to add a new connection. Fill out the form as shown in Figure 2:</p> <ul> <li>Connection Id: A unique identifier for the connection in Apache Airflow, which will be referenced inside the DAG code. We will use \u201ccassandra_cqlproxy.\u201d</li> <li>Connection Type: Select \u201cCassandra\u201d from the drop-down. If it is not present, you will have to install Airflow\u2019s Cassandra provider.</li> <li>Host: The listen address that cql-proxy is bound to. In this case, that is \u201c127.0.0.1.\u201d</li> <li>Schema: The Cassandra keyspace which we created in Astra DB. We\u2019ll set that to \u201cairflow\u201d in this case.</li> <li>Login: Your Astra DB client id.</li> <li>Password: Your Astra DB client secret.</li> <li>Port: The port that cql-proxy is listening on for the CQL native binary protocol, most likely 9042.</li> </ul> <p></p> <p>Figure 2 - Create a new Cassandra connection for Apache Airflow.</p> <p>Click the blue <code>Save</code> button to persist the new connection.</p>"},{"location":"pages/tools/integration/apache-airflow/#create-a-new-dag-in-apache-airflow","title":"\u2705 Create a new DAG in Apache Airflow","text":"<p>A directed acyclic graph (DAG) is essentially a Python script which imports one or more libraries specific to Airflow. To create a new DAG, first locate your DAG directory. By default, Airflow looks for custom DAGs in the <code>~/airflow/dags/</code> directory.</p> <p>For testing, there is a sample DAG out in the following GitHub repository: https://github.com/aar0np/DS_Python_stuff/blob/main/cassandra_test_dag.py</p> <p>This DAG uses the following line to reference the Cassandra connection we created in the above step:</p> <pre><code>hook = CassandraHook('cassandra_cqlproxy')\n</code></pre> <p>The other important aspect is that this DAG sets its unique identifier as <code>cass_hooks_tutorial</code>:</p> <pre><code>with DAG(\n    'cass_hooks_tutorial',\n</code></pre> <p>It also specifically creates two unique tasks:</p> <ul> <li><code>check_table_exists</code></li> <li><code>query_system_local</code></li> </ul>"},{"location":"pages/tools/integration/apache-airflow/#final-test","title":"\u2705 Final Test","text":"<p>To test the connection, copy the DAG mentioned above into the <code>/dags/</code> directory. Then we will invoke Airflow\u2019s task testing functionality, by running airflow tasks test and specifying:</p> <ul> <li>The DAG\u2019s unique identifier</li> <li>The name of the task to be run</li> <li>The execution date</li> </ul> <p>If today\u2019s date is 2022-02-08, the command looks like this:</p> <pre><code>airflow tasks test cass_hooks_tutorial check_table_exists 2022-02-08\n</code></pre> <p>Many messages will go by quickly. If it worked, the final messages should look something like this:</p> <pre><code>INFO - Done. Returned value was: True\nINFO - Marking task as SUCCESS. dag_id=cass_hooks_tutorial, task_id=check_table_exists, execution_date=20220208T000000, start_date=20220208T195333, end_date=20220208T195334\n</code></pre>"},{"location":"pages/tools/integration/apache-airflow/#acknowledgements","title":"Acknowledgements","text":"<p>Special thanks goes out to Obioma Anomnachi of Anant. Obi\u2019s video and GitHub repo proved quite helpful in building out this tutorial.</p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/integration/apache-nifi/","title":"Apache NiFi","text":"<p>This is an adaptation of the Steven Matison Blogpost</p> <p>\ud83d\udccb On this page</p> <ul> <li>A - Overview</li> <li>B - Prerequisites</li> <li>C - Log Ingestion to Astra with Stargate Document Api</li> </ul>"},{"location":"pages/tools/integration/apache-nifi/#overview","title":"Overview","text":""},{"location":"pages/tools/integration/apache-nifi/#what-is-nifi","title":"\ud83d\udcd8  What is NiFi?","text":"<p>Apache NiFi is a software project from the Apache Software Foundation designed to automate the flow of data between software systems. It is super powerful tool I have been using for a few years to develop data flows and data pipelines. With NiFi I can do just about anything without writing a single line of code.</p> <p>You can use NiFi\u2019s <code>invokeHttp processor</code> for any Astra API calls.</p> <p>You can also use native NiFi Cassandra Processors:</p> <ul> <li>QueryCassandraRecord</li> <li>PutCassandraRecord</li> <li>and PutCassandraQL against Astra.</li> </ul>"},{"location":"pages/tools/integration/apache-nifi/#my-astra-nifi-templates","title":"\ud83d\udcd8  My Astra NiFi Templates","text":"<ul> <li> <p>You can find my official NiFi Astra Cassandra templates here</p> </li> <li> <p>You can also find templates from my previous life here</p> </li> </ul>"},{"location":"pages/tools/integration/apache-nifi/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should install a `Java JDK 1.8+` and Apache Maven</li> <li>Download and install Apache Nifi</li> <li>You should add `invokeHttp` and `Cassandra` [processors](https://nifi.apache.org/docs/nifi-docs/html/getting-started.html#adding-a-processor)</li> </ul>"},{"location":"pages/tools/integration/apache-nifi/#log-ingestion-to-astra-with-nifi","title":"Log Ingestion to Astra with NiFi","text":"<p>In this blog I am going to show you how to ingest raw log data into cassandra using NiFi and Astra. With NiFi ingesting data from any source is super easy. With Astra and Cassandra ingesting raw data can be a challenge due to data model constraints (primary keys and clustering columns).</p> <p>In this demo I am going to remove that constraint and ingest all raw data using Astra &amp; Stargate Document API which is accepting of schemaless JSON data. Although not a focus off this blog, it is fully possible to build a cassandra data model and do this log ingestion using NiFi Cassandra Processors or Astra REST API against standard cassandra database tables.</p> <p>In this demo we are going to communicate with Astra via Stargate\u2019s Documement APIs.</p>"},{"location":"pages/tools/integration/apache-nifi/#step-1-get-nifi-authorized-for-astra-calls","title":"\u2705 Step 1 :  Get NiFi Authorized for Astra Calls","text":""},{"location":"pages/tools/integration/apache-nifi/#getauthtoken","title":"GetAuthToken","text":"<ul> <li>Upload and add Get Astra Get Auth Token Template to your canvas. Record the Process Group Id for later.</li> <li>Collect Astra details needed: astra databaseid, region, api url, username, password.</li> <li>Update Process Group variables with API url, process Group Id, Username and Password.</li> <li>Configure and Enable SSL Context Services. For simple demo purposes we use java cacerts and in my environment I have copied ca certs to local path /nifi/ssl/cacerts. You will need to locate your path to cacerts and adjust. The cacerts password is \u201cchangeit\u201d. You can also use Astra Secure Bundle and keystore/trustore found within that bundled zip file.</li> <li>Confirm NiFi host:port in the Blue InvokeHTTP Processors.</li> <li>Play the data flow and confirm variable astraToken is filled with authorization token.</li> </ul> <p>\u2139\ufe0f Things to Note:</p> <ul> <li>Top of flow (GenerateFlowFile) will kick off the auth process every 30 minutes.</li> <li>For sake of this demo, all variables are included in GetAuthToken Process Group. In production or in your data flow you will want those variables in the parent location. Adjust your own flow accordingly.</li> <li>For demo purposes failure routes are visible. In production, these may be auto terminated or routed to exception handling.</li> </ul>"},{"location":"pages/tools/integration/apache-nifi/#step-2-create-data-flow-for-log-ingestion","title":"\u2705 Step 2 :  Create Data Flow for Log Ingestion","text":"<p>In this first example, we are going to ingest apache log data from a custom log file. Reference the template Astra Apache Logs to Cassandra with Stargate for this data flow. This log data happens to be on the same NiFi host in the normal /var/log/httpd/ location. The custom apache log file is in the format of:</p> <pre><code>&lt;IfModule log_config_module&gt;\nLogFormat \"%&gt;s  %U  %h  %{%Y-%m-%d %H:%M:%S}t\" urlsdetails\n        CustomLog \"/var/log/httpd/access-file-details.log\" urlsdetails\n&lt;/IfModule&gt;\n</code></pre> <p>The CSVReader Schema used in QueryRecord is as follows:</p> <pre><code>{\n\"name\": \"apache_logs\",\n\"type\": \"record\",\n\"fields\": [\n{ \"name\": \"http_status\", \"type\": \"string\" },\n{ \"name\": \"access_url\", \"type\": \"string\" },\n{ \"name\": \"ip\", \"type\": \"string\" },\n{ \"name\": \"apachetime\", \"type\": \"string\" }\n]\n}\n</code></pre> <p>And the output of the JSON Writer is as follows:</p> <pre><code>{\n\"http_status\": \"200\",\n\"access_url\": \"/INTROV8.mp3\",\n\"ip\": \"115.164.45.55\",\n\"apachetime\": \"2021-01-26 14:16:58\"\n}\n</code></pre> <p>\u26a0\ufe0f Notice this JSON structure is exactly what we need to insert into Astra. We do not have to create the collection or schema ahead of time. This collection creation will automatically happen with the delivery of the first document. \ud83d\udca1</p> <p>\u2139\ufe0f Things to Note:</p> <ul> <li>For portability of the log data flow template, the SSL Context Service is duplicated. You can adjust your flow to use a single context service at the root canvas level.</li> <li>Some of the NiFi Variables from above template are referenced in this template. Adjust your flow accordingly with root level variables or import this template into same Process Group above.</li> </ul>"},{"location":"pages/tools/integration/apache-nifi/#step-3-verify-log-data-with-cql-console","title":"\u2705 Step 3 :  Verify Log Data With Cql Console","text":"<p>Login to the Astra and navigate to your Cql Consoe and execute the following query:</p> <pre><code>select count(*) FROM apache_log;\n</code></pre> <p>\u26a0\ufe0f For this demo it is not important to look at the data, only important to verify results are in Astra. In future updates I will go into Postman and show how to access the data in a meaningful manner. For now, let us just bask in the glory of being able to ingest log data to cassandra without data modeling.</p>"},{"location":"pages/tools/integration/apache-nifi/#whats-next","title":"What\u2019s Next","text":"<p>We can now use Stargate Document API to query this data source and even search into the JSON Object. We can have conversations about the raw data, build cassandra data models, and investigate how this log data can be used downtream from cassandra. Stay tuned as I add other Log Ingestion Use Cases, a UUID Generator, and more Astra NiFi content here.</p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/integration/apache-spark/","title":"Apache Spark","text":"<ul> <li>This article includes information that was originally written by Arpan Patel on Anant Github and Astra DataStax</li> </ul>"},{"location":"pages/tools/integration/apache-spark/#overview","title":"Overview","text":"<p>Apache Spark is an open-source, distributed processing system used for big data workloads. It utilizes in-memory caching, and optimized query execution for fast analytic queries against data of any size. Use Apache Spark to connect to your database and begin accessing your Astra DB tables using Scala in spark-shell.</p> <ul> <li>\u2139\ufe0f Introduction to Apache Spark</li> <li>\ud83d\udce5 Apache Spark Download Link</li> </ul>"},{"location":"pages/tools/integration/apache-spark/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle and unpack it.</li> <li>Download and install the latest version of Spark Cassandra Connector that matches with your Apache Spark and Scala version from the maven central repository. To find the right version of SCC, please check SCC compatibility here.</li> </ul>"},{"location":"pages/tools/integration/apache-spark/#installation-and-setup","title":"Installation and Setup","text":"<p>These steps assume you will be using Apache Spark in local mode. For help using Spark cluster mode click the chat button on the bottom of the screen.</p>"},{"location":"pages/tools/integration/apache-spark/#steps","title":"\u2705  Steps:","text":"<ol> <li> <p>Expand the downloaded Apache Spark package into a directory, and assign the directory name to <code>$SPARK_HOME</code>.</p> </li> <li> <p>Navigate to this directory using <code>cd $SPARK_HOME</code></p> </li> <li> <p>Append the following lines at the end of a file called <code>$SPARK_HOME/conf/spark-defaults.conf</code> (you may be able to find a template under $SPARK_HOME/conf directory), and replace the second column (value) with the first four lines:</p> </li> </ol> <pre><code>spark.files $SECURE_CONNECT_BUNDLE_FILE_PATH/secure-connect-astraiscool.zip\nspark.cassandra.connection.config.cloud.path secure-connect-astraiscool.zip\nspark.cassandra.auth.username &lt;&lt;CLIENT ID&gt;&gt;\nspark.cassandra.auth.password &lt;&lt;CLIENT SECRET&gt;&gt;\nspark.dse.continuousPagingEnabled false\n</code></pre> <ol> <li>Launch spark-shell and enter the following scala commands:</li> </ol> <pre><code>import com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._\nspark.read.cassandraFormat(\"tables\", \"system_schema\").load().count()\n</code></pre> <p>You should expect to see the following output:</p> <pre><code>$ bin/spark-shell\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\nSpark context Web UI available at http://localhost:4040\nSpark context available as 'sc' (master = local[*], app id = local-1608781805157).\nSpark session available as 'spark'.\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.0.1\n      /_/\n\nUsing Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 11.0.9.1)\nType in expressions to have them evaluated.\nType :help for more information.\n\nscala&gt; import com.datastax.spark.connector._\nimport com.datastax.spark.connector._\n\nscala&gt; import org.apache.spark.sql.cassandra._\nimport org.apache.spark.sql.cassandra._\n\nscala&gt; spark.read.cassandraFormat(\"tables\", \"system_schema\").load().count()\nres0: Long = 25\nscala&gt; :quit\n</code></pre> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/integration/authorizer/","title":"Authorizer","text":""},{"location":"pages/tools/integration/authorizer/#overview","title":"Overview","text":"<p>Authorizer is an open source auth solution for application.  It works with many different databases, allowing the developers to use a single datastore for the entire application stack and have complete control over all user data.</p> <ul> <li>\u2139\ufe0f Authorizer Documentation</li> </ul>"},{"location":"pages/tools/integration/authorizer/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> </ul>"},{"location":"pages/tools/integration/authorizer/#installation","title":"Installation","text":""},{"location":"pages/tools/integration/authorizer/#step-0-download-and-install","title":"\u2705 Step 0  Download and install","text":"<p>Following the Authorizer documentation download and untar the software where you would like to install it.</p>"},{"location":"pages/tools/integration/authorizer/#step-1-create-the-keyspace-authorizer","title":"\u2705 Step 1  Create the keyspace <code>authorizer</code>","text":"<p>From the Astra DB dashboard, click on your database name. Scroll down to where the keyspaces are listed, and click the <code>Add Keyspace</code> button to create a new keyspace. Name this keyspace <code>authorizer</code>.</p>"},{"location":"pages/tools/integration/authorizer/#step-2-create-configuration-file","title":"\u2705 Step 2  Create configuration file","text":"<p>Use the delivered <code>.env.sample</code> file to create a new <code>.env</code> file for your configuration.  Edit this file with Atom, Vi, or whichever editor you choose. <pre><code>    cd authorizer\n    cp .env.sample .env\n    atom .env\n</code></pre></p>"},{"location":"pages/tools/integration/authorizer/#step-3-create-base64-encoded-strings-from-your-cert-cacrt-and-key-files","title":"\u2705 Step 3  Create base64 encoded strings from your cert, ca.crt, and key files","text":"<p>To successfully connect with Astra DB, you will need to open the secure bundle and convert the following files into base64 encoded strings:</p> <ul> <li>cert</li> <li>ca.crt</li> <li>key</li> </ul> <p>You can accomplish this with the <code>base64</code> command:</p> <pre><code>base64 cert cert_base64_file\nbase64 ca.crt ca_base64_file\nbase64 key key_base64_file\n</code></pre> <p>Note that you can omit the file parameter and output the base64 encoded string to STDOUT for easy copy/paste accessibility.</p>"},{"location":"pages/tools/integration/authorizer/#step-4-connect-to-astra-db","title":"\u2705 Step 4  Connect to Astra DB","text":"<p>To connect to Astra DB, you will need to specify the following variables in the <code>.env</code> file:</p> <pre><code>DATABASE_HOST=\"ASTRA_DB_ID-ASTRA_DB_REGION.db.astra.datastax.com\"\nDATABASE_TYPE=\"cassandradb\"\nDATABASE_PORT=29042\nDATABASE_USERNAME=\"token\"\nDATABASE_PASSWORD=\"AstraCS:yourAstraT0ken\"\n\nDATABASE_CERT=\"LS0tLS1CRUdJTiBDblahblahblahnotrealRVJUSUZJQ0FURS0tLS0\"\nDATABASE_CERT_KEY=\"RXNRNVcKYXkwblahblahblahnotrealkt4b1FnL2s4K29IaD\"\nDATABASE_CA_CERT=\"WVhneERqQU1CZblahblahblahnotrealWQkFzVEJVTnNiM1Z\"\n</code></pre>"},{"location":"pages/tools/integration/authorizer/#step-5-start-authorizer","title":"\u2705 Step 5  Start Authorizer","text":"<p>From the <code>authorizer</code> directory, run the <code>server</code> binary from the <code>build</code> directory.  It will run in the foreground. <pre><code>build/server\n</code></pre></p> <p>Verify that it is running by bringing up the Authorizer dashboard in a browser: http://127.0.0.1:8080/dashboard/</p>"},{"location":"pages/tools/integration/authorizer/#acknowledgements","title":"Acknowledgements","text":"<p>Special thanks goes out to Lakhan Samani of Authorizer. YouTube channel GitHub repo</p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/integration/cadence/","title":"Cadence","text":""},{"location":"pages/tools/integration/cadence/#overview","title":"Overview","text":"<p>Cadence is a multi-tenant orchestration framework that helps with managing workflows. It scales horizontally to handle millions of concurrent executions from various customers. Cadence Open Sources uses docker compose to run their server, and uses Apache Cassandra\u24c7 as its default backend dependency. Using docker compose, users are able to also use Cadence with MySQL, PostgreSQL, Statsd+Graphite, and Elasticsearch.</p> <ul> <li>\u2139\ufe0f Introduction to Cadence</li> <li>\ud83d\udce5 Cadence Quick Install</li> </ul>"},{"location":"pages/tools/integration/cadence/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul> <p>Note</p> <p>This runbook was written using Mac OS Monterey but it will also work with Windows. Any Windows-specific instructions will be noted as such.</p>"},{"location":"pages/tools/integration/cadence/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"pages/tools/integration/cadence/#1-setup-astra","title":"\u2705 1.  Setup Astra","text":"<ol> <li>In your Astra database, create two new keyspaces called \"cadence\" and \"cadence_visibility\". You will be using both of these in the next steps.</li> <li>Make sure to create an Astra token with Admin Role</li> <li>Get your Database ID</li> </ol> Find your Database ID in one of two ways <ol> <li>Navigate to your your database and get the last ID in the URL: <code>https://astra.datastax.com/org/.../database/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx</code></li> <li>Copy and paste the Datacenter ID without the trailing <code>-1</code> from the Regions section of your Astra Dashboard.</li> </ol>"},{"location":"pages/tools/integration/cadence/#2-cadence-pre-setup","title":"\u2705 2.  Cadence Pre-setup","text":"<ol> <li>Clone this GitHub repository</li> <li>Navigate to your cloned repository and using your preferred text editor (e.g. VisualStudio or Sublime), update the .env file with your Astra Token and Astra Database ID that you obtained above.</li> </ol> <pre><code>ASTRA_TOKEN=&lt;your Astra token&gt;\nASTRA_DATABASE_ID=&lt;your DB ID&gt;\n</code></pre>"},{"location":"pages/tools/integration/cadence/#3-cadence-schema-migration-to-astra-db","title":"\u2705 3.  Cadence Schema Migration to Astra DB","text":"<p>For this step, you will set up the keyspaces you created earlier in the Astra prerequisites (cadence and cadence_visibility). You will be using <code>cadence-cassandra-tool</code> which is part of the Temporal repo and it relies on schema definition.</p> <ol> <li>Navigate to your cloned <code>cadence-astra-cql-proxy</code> directory</li> <li>Run the following commands to initialize the keyspaces that we created through Astra. Note that there are two sets of commands, one for <code>cadence</code> keyspace and one for <code>cadence_visibility</code> keyspace:</li> </ol> <pre><code>docker-compose -f docker-compose-schema.yaml run cadence \\\n-ep cqlproxy-cadence -k cadence setup-schema -v 0.0\ndocker-compose -f docker-compose-schema.yaml run cadence \\\n-ep cql-proxy -k cadence update-schema -d schema/cassandra/cadence/versioned/\n\ndocker-compose -f docker-compose-schema.yaml run cadence \\\n-ep cql-proxy -k cadence_visibility setup-schema -v 0.0\ndocker-compose -f docker-compose-schema.yaml run cadence \\\n-ep cql-proxy -k cadence_visibility update-schema -d schema/cassandra/visibility/versioned/\n</code></pre> <p>Once the process is completed, you should see a message similar to this:</p> <pre><code>2022/04/05 21:50:24 Starting schema setup, config=&amp;{SchemaFilePath: InitialVersion:0.0 Overwrite:false DisableVersioning:false}\n2022/04/05 21:50:24 Setting up version tables\n2022/04/05 21:50:25 Setting initial schema version to 0.0\n2022/04/05 21:50:25 Updating schema update log\n2022/04/05 21:50:26 Schema setup complete\n...\n2022/04/05 22:13:16 ---- Done ----\n2022/04/05 22:13:16 Schema updated from 0.32 to 0.33, elapsed 1.4960138s\n2022/04/05 22:13:16 All schema changes completed in 32.5941245s\n2022/04/05 22:13:16 UpdateSchemeTask done\n</code></pre> <p>Great! Your schemas have been migrated with Astra DB.</p> <p>Confirm your tables exist in Astra</p> <p>You can double-check to make sure the correct tables have been created by querying your database in Astra DB\u2019s CQL Console. Run <code>DESC tables;</code> in both your <code>cadence</code> and <code>cadence_visibility</code> keyspaces. You should see there are tables loaded in that were created by the schema migration with <code>cadence-cassandra-tool</code>.</p> <pre><code>token@cqlsh&gt; use cadence;\ntoken@cqlsh:cadence&gt; desc tables;\nhistory_node        schema_version  tasks           history_tree\ndomains_by_name_v2  executions      domains         events\ncluster_config      queue           queue_metadata  schema_update_history\n\ntoken@cqlsh:cadence&gt; use cadence_visibility ;\ntoken@cqlsh:cadence_visibility&gt; desc tables;\nopen_executions        closed_executions_v2  closed_executions\nschema_update_history  schema_version\n</code></pre>"},{"location":"pages/tools/integration/cadence/#4-run-docker-compose","title":"\u2705 4.  Run Docker Compose","text":"<p>In this step, the <code>docker-compose.yaml</code> file is already provided for you in the <code>cadence-astra-cql-proxy</code> repo. This file creates different docker containers to run Temporal server. The persistence layer is configured for you to connect with cql-proxy, and it should pull your Astra credentials from when you set it earlier.</p> <pre><code>services:\n cql-proxy:\n   container_name: cqlproxy\n   image: datastax/cql-proxy:v${CQL_PROXY_VERSION}\n...\n   environment:\n     - ASTRA_TOKEN=${ASTRA_TOKEN}\n- ASTRA_DATABASE_ID=${ASTRA_DATABASE_ID}\n- HEALTH_CHECK=true\n</code></pre> <p>Now you can run the docker-compose command to start up Cadence:</p> <pre><code>docker-compose up\n</code></pre>"},{"location":"pages/tools/integration/cadence/#5-test-and-validate","title":"\u2705 5.  Test and Validate","text":"<p>You can test your connection and play with your Cadence cluster with these instructions. Using Cadence\u2019s Command Line tool, you will be able to interact with your local Temporal server.</p> <ol> <li>Create a domain <code>samples-domain</code> by running the following command. You should see the success message once the domain is created:</li> </ol> <pre><code>% cadence --do samples-domain d re\nDomain samples-domain successfully registered.\n</code></pre> <ol> <li>Clone the sample project repository to your machine. Navigate to this project and run make to build all the projects.</li> <li>Once this is complete, you can start by running the sample Hello World project by following the instructions in that repository.</li> </ol> <p>Once you have this all running, you should be able to see your workflows reflect on both the Cadence UI and Astra UI. You can see the domain on the top left is samples-domain, the domain we created, as well as the Status of each workflow as \u201cCompleted\u201d.</p> <p></p> <p>\ud83c\udfe0 Back to HOME</p>"},{"location":"pages/tools/integration/celery/","title":"Celery","text":""},{"location":"pages/tools/integration/celery/#overview","title":"Overview","text":"<p>Celery is a (BSD-licensed) open source, simple and flexible distributed task queue for asynchronous processing of messages. With Celery one can define units of work called \"tasks\" and dispatch them for execution, in a distributed way if desired. Celery is a Python package and as such is easily integrated in any Python project.</p> <p>Typical use cases might be: a queue of uploaded images to resize in the background, long-running tasks initiated by a Web application's API, a batch of emails scheduled for sending, ...</p> <p>Celery is composed of two parts: on one side, one or more clients define the tasks to be run and enqueue/schedule them for execution; on the other side, one or more workers pick up these tasks, execute them and optionally store the resulting values. Communication between these two parts happens through a message bus (such as RabbitMQ) acting as broker, while the return value of a task is made available back to the caller through a backend (de/serialization is transparently handled by the Celery infrastructure).</p> <p>Celery supports several backends for storing and exposing task results. Among the supported backends are Cassandra and (starting with <code>v5.3</code>) Astra DB.</p> <p>Note</p> <p>Support for Astra DB starts with version <code>v5.3</code>. At the time of writing, the latest stable is still <code>5.2</code>: in order to use Astra DB you must install the development version. Likewise, the documentation links below refer to the \"development docs\".</p> <p>In the following we assume familiarity with the <code>celeryconfig</code> configuration object for Celery and with the usage of Cassandra as backend. See the Celery documentation for more details:</p> <ul> <li>\u2139\ufe0f Celery documentation</li> <li>\u2139\ufe0f The <code>celeryconfig</code> object</li> <li>\u2139\ufe0f Cassandra/AstraDB backend configuration guide (which covers the instructions on this page as well)</li> <li>\ud83d\udce5 Celery installation instructions (dev version to support Astra DB)</li> </ul>"},{"location":"pages/tools/integration/celery/#prerequisites","title":"Prerequisites","text":"<ul> <li>Create an Astra Database. In the following example, a keyspace called <code>celeryks</code> is created in the database.</li> <li>Create an Astra Token with the role \"Database Administrator\" (it is desirable to leave table creation to Celery). You should have received your token while creating the database in the previous step.</li> <li>Download your secure connect bundle ZIP.   <li>Install Celery with the Cassandra backend in your local Python environment, e.g. <code>pip install celery[cassandra]</code>. See the backend-settings page for additional info.</li> <p>Keep the token information and the bundle file location ready: these will be soon provided in the Celery configuration.</p>"},{"location":"pages/tools/integration/celery/#installation-and-setup","title":"Installation and Setup","text":"<p>Here a minimal Celery setup that makes use of the Astra DB backend is described start-to-end.</p> <p>A task will be defined and executed through Celery: afterwards, its return value will be retrieved on the client side. For this example to work, a message bus is needed - here, in line with a quickstart on Celery's documentation, a dockerized RabbitMQ is used.</p>"},{"location":"pages/tools/integration/celery/#1-start-a-message-broker","title":"1.  Start a message broker","text":"<p>Make sure you have a RabbitMQ instance running in Docker with <code>docker run -d -p 5672:5672 rabbitmq</code> (it might take a while for the image to be downloaded and complete startup).</p>"},{"location":"pages/tools/integration/celery/#2-define-a-task","title":"2.  Define a task","text":"<p>Create a <code>tasks.py</code> module with the definition of a task, to be later executed through Celery:</p> <pre><code>from celery import Celery\napp = Celery('tasks')\napp.config_from_object('celeryconfig')\n@app.task\ndef sortWords(text, capitalize):\n# Rearrange the text so that words are in alphabetical order.\nwords = text.split(' ')\nsortedWords = sorted(words, key=str.upper)\nreturn ' '.join([\nw if not capitalize else w.upper()\nfor w in sortedWords\n])\n</code></pre>"},{"location":"pages/tools/integration/celery/#3-configure-celery","title":"3.  Configure Celery","text":"<p>Create a module <code>celeryconfig.py</code> in the same directory, providing (among other things) the broker and backend configuration:</p> <pre><code>broker_url = 'pyamqp://guest@localhost//'\nbroker_connection_retry_on_startup = True\ntask_serializer = 'json'\nresult_serializer = 'json'\naccept_content = ['json']\nenable_utc = True\nresult_backend = 'cassandra://'\ncassandra_keyspace = 'celeryks'                       # REPLACE_ME\ncassandra_table = 'celery_tasks'                      # REPLACE_ME\ncassandra_read_consistency = 'quorum'\ncassandra_write_consistency = 'quorum'\ncassandra_auth_provider = 'PlainTextAuthProvider'\ncassandra_auth_kwargs = {\n'username': 'client-id-from-astra-token',           # REPLACE_ME\n'password': 'client-secret-from-astra-token',       # REPLACE_ME\n}\ncassandra_secure_bundle_path = '/path/to/secure-connect-database.zip'   # REPLACE_ME\n</code></pre> <p>In the above, take care of inserting your values for:</p> <ul> <li>the keyspace name you created earlier in Astra DB;</li> <li>the table name you want Celery to store results in (no need to create it beforehand);</li> <li>the Client ID and Client Secret generated in your Astra DB token earlier (resp. as username and password in <code>cassandra_auth_kwargs</code>);</li> <li>the path to the Secure Connect Bundle you downloaded earlier.</li> </ul>"},{"location":"pages/tools/integration/celery/#4-start-the-worker","title":"4.  Start the worker","text":"<p>Start a Celery worker with:</p> <pre><code>celery -A tasks worker --loglevel=INFO\n</code></pre>"},{"location":"pages/tools/integration/celery/#5-run-and-check-a-task","title":"5.  Run and check a task","text":"<p>In a different shell, open a Python REPL and type the following commands to run a couple of tasks and retrieve their result:</p> <pre><code>from tasks import sortWords\nsorted1 = sortWords.delay('storage yay my DB is powerful results Astra', False)\nsorted1.ready()\n# Returns:     True\n# (as soon as the function completes, which here is almost immediately)\nsorted1.get()\n# Returns:     'Astra DB is my powerful results storage yay'\nsorted2 = sortWords.delay('In the land of another wizards day', capitalize=True)\nsorted2.get()\n# Returns:     'ANOTHER DAY IN LAND OF THE WIZARDS'\n</code></pre>"},{"location":"pages/tools/integration/celery/#6-optional-look-at-the-database","title":"6.  (Optional) Look at the database","text":"<p>Check the corresponding data stored on Astra DB. Navigate to the CQL Console for the database you created and enter the following commands:</p> <pre><code>USE celeryks;               // &lt;== enter your keyspace name here\n\nDESCRIBE TABLES;            // the output, e.g. \"celery_tasks\", lists the tables\n\nSELECT * FROM celery_tasks; // &lt;== enter your table name here\n</code></pre> <p></p>"},{"location":"pages/tools/integration/celery/#additional-configuration","title":"Additional configuration","text":"<p>Celery uses the DataStax Python driver for Cassandra; hence, the choice of connection parameters is that for the generic driver-based usage of Cassandra in Python.</p> <p>In particular, one may want to specify additional parameters through the <code>celeryconfig</code> such as protocol level, load-balancing policy and so on. Refer to the \"Additional configuration\" section in the Celery documentation for a more comprehensive setup.</p>"},{"location":"pages/tools/integration/feast/","title":"Feast","text":""},{"location":"pages/tools/integration/feast/#overview","title":"Overview","text":"<p>Feast is a (Apache-licensed) open-source feature store for machine learning. Feast aims at providing a fast solution to the typical MLOps needs one encounters when bringing ML applications to production.</p> <p>Feast offers a solution to the problem of training/serving skew, provides tools to standardize the data engineering workflows (thus avoiding having to \"re-invent the features\" every time), and ensures reproducible feature sets with point-in-time historical retrievals.</p> <p>This feature store supports several backends, both as offline store (for historical time-series data) and online store (with the latest features, synced from the former by Feast itself). Besides a few core backends, the Feast project features additional backends contributed by the community.</p> <p>Feast is built with the cloud in mind: one of its goals is to free MLOps practitioners and data engineers from having to manage their own infrastructure. In this spirit, starting with version <code>0.24</code>, the Feast online store for Cassandra contribution flexibly supports both Cassandra and Astra DB, as will be explained below.</p> <p>Reference documentation:</p> <ul> <li>\u2139\ufe0f Feast Documentation</li> <li>\u2139\ufe0f Cassandra online store</li> <li>\u2139\ufe0f Feast minimal quickstart</li> </ul>"},{"location":"pages/tools/integration/feast/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database In the following example, a keyspace called `feastks` is created in the database.</li> <li>You should Create an Astra Token with the role \"Database Administrator\" (Feast will have to dynamically create and delete tables in the keyspace).</li> <li>You should Download your Secure Connect Bundle.</li> <li>Install Feast, including the dependencies for the Cassandra/Astra DB backend, in your local Python environment: <code>pip install feast[cassandra]</code>.</li> </ul> <p>Keep the token information and the bundle file location ready: these will be soon provided in the Feast configuration.</p>"},{"location":"pages/tools/integration/feast/#quickstart","title":"Quickstart","text":"<p>Note</p> <p>In this minimal quickstart, modeled after the one found in the Feast documentation, you will be providing the store configuration file by hand.</p> <p>Alternatively, an interactive command-line procedure to help you set up your store is available by launching <code>feast init REPO_NAME -t cassandra</code>.</p> <p>All credits for the sample code given here goes to the Feast documentation.</p> <p>A new feature store is created and configured to use Astra DB as online store; next, a few sample features will be materialized to database; finally, historical/online feature retrieval is demonstrated.</p>"},{"location":"pages/tools/integration/feast/#install-feast","title":"Install Feast","text":"<p>See last item in the \"Prerequisites\" above.</p>"},{"location":"pages/tools/integration/feast/#create-a-feature-repository","title":"Create a feature repository","text":"<p>In a directory of your choice, create a new repository and <code>cd</code> to the corresponding repo-definition directory:</p> <pre><code>feast init astraFeatures\ncd astraFeatures/feature_repo\n</code></pre> <p>As you can see, the new feature store already contains sample data and a sample feature definition. These will be used in this walkthrough, so don't delete them.</p>"},{"location":"pages/tools/integration/feast/#configure-astra-db-as-online-store","title":"Configure Astra DB as online store","text":"<p>Locate and open the store configuration file, <code>feature_store.yaml</code>. Replace the <code>online_store</code> portion of the file with something like the following. Make sure you use your values for the Secure Bundle file full path, the Client ID and Client Secret from your token and the keyspace name:</p> <pre><code>online_store:\n    type: cassandra\n    secure_bundle_path: /path/to/secure/bundle.zip\n    username: Client_ID\n    password: Client_Secret\n    keyspace: feastks\n</code></pre> <p>Settings in 'feature_store.yaml' for usage with Cassandra</p> <p>If using regular Cassandra as opposed to Astra DB, the \"online_store\" portion might look like: <pre><code>online_store:\n    type: cassandra\n    hosts:\n        - 192.168.1.1\n        - 192.168.1.2\n        - 192.168.1.3\n    keyspace: feastks\n    port: 9042        # optional\n    username: user    # optional\n    password: 123456  # optional\n</code></pre></p> <p>Additional settings are available when configuring your Cassandra/Astra DB online store: check out the full examples on the Feast documentation.</p>"},{"location":"pages/tools/integration/feast/#register-feature-definitions-and-deploy-the-store","title":"Register feature definitions and deploy the store","text":"<p>With the <code>apply</code> command, features defined in Python modules (in this case, <code>example.py</code>) are scanned and used for actual deployment of the infrastructure.</p> <p>Run the command</p> <pre><code>feast apply\n</code></pre> <p>This is the step that actually accesses the database. After running it, you may want to check directly the presence of a new table in the Astra DB keyspace.</p>"},{"location":"pages/tools/integration/feast/#generate-training-data","title":"Generate training data","text":"<p>This illustrates the <code>get_historical_features</code> store method, which directly scans the offline source data and performs a point-in-time join to construct the features requested up to a certain provided timestamp.</p> <p>Create a file <code>generate.py</code> and run it with <code>python generate.py</code>:</p> <pre><code>from datetime import datetime, timedelta\nimport pandas as pd\nfrom feast import FeatureStore\n# The entity dataframe is the dataframe we want to enrich with feature values\nentity_df = pd.DataFrame.from_dict(\n{\n# entity's join key -&gt; entity values\n\"driver_id\": [1001, 1002, 1003],\n# label name -&gt; label values\n\"label_driver_reported_satisfaction\": [1, 5, 3], \n# \"event_timestamp\" (reserved key) -&gt; timestamps\n\"event_timestamp\": [\ndatetime.now() - timedelta(minutes=11),\ndatetime.now() - timedelta(minutes=36),\ndatetime.now() - timedelta(minutes=73),\n],\n}\n)\nstore = FeatureStore(repo_path=\".\")\ntraining_df = store.get_historical_features(\nentity_df=entity_df,\nfeatures=[\n\"driver_hourly_stats:conv_rate\",\n\"driver_hourly_stats:acc_rate\",\n\"driver_hourly_stats:avg_daily_trips\",\n],\n).to_df()\nprint(\"----- Feature schema -----\\n\")\nprint(training_df.info())\nprint()\nprint(\"----- Example features -----\\n\")\nprint(training_df.head())\n</code></pre>"},{"location":"pages/tools/integration/feast/#load-features-in-the-online-store","title":"Load features in the online store","text":"<p>With the <code>materialize-incremental</code> command, Feast is instructed to carry the latest feature values over to the online store, for quick access during feature serving:</p> <pre><code>CURRENT_TIME=$(date -u +\"%Y-%m-%dT%H:%M:%S\")\nfeast materialize-incremental $CURRENT_TIME\n</code></pre> <p>At this point, inspection of the Astra DB table will show the presence of newly-inserted rows.</p>"},{"location":"pages/tools/integration/feast/#fetch-feature-vectors-from-the-online-store","title":"Fetch feature vectors from the online store","text":"<p>The <code>get_online_features</code> store method will query the online store and return the required features, as resulting from the last \"materialize\" operation.</p> <p>Create a <code>fetch_online.py</code> script and run it with <code>python fetch_online.py</code>:</p> <pre><code>from pprint import pprint\nfrom feast import FeatureStore\nstore = FeatureStore(repo_path=\".\")\nfeature_vector = store.get_online_features(\nfeatures=[\n\"driver_hourly_stats:conv_rate\",\n\"driver_hourly_stats:acc_rate\",\n\"driver_hourly_stats:avg_daily_trips\",\n],\nentity_rows=[\n# {join_key: entity_value}\n{\"driver_id\": 1004},\n{\"driver_id\": 1005},\n],\n).to_dict()\npprint(feature_vector)\n</code></pre>"},{"location":"pages/tools/integration/feast/#next-steps","title":"Next steps","text":"<p>Have a look at the <code>feature_store.yaml</code> examples for Cassandra and Astra DB to check the full set of options available.</p> <p>Head over to the Feast documentation to find out what you can do with your newly-deployed feature store.</p>"},{"location":"pages/tools/integration/flink/","title":"Flink","text":"<ul> <li>This article includes information that was originally written by Bret McGuire on GitHub </li> </ul>"},{"location":"pages/tools/integration/flink/#overview","title":"Overview","text":"<p>Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale. This tutorial will show you step-by-step how to use Astra as a sink for results computed by Flink. These instructions are intended to demonstrate how to enable such support when using a Flink DataStream.</p> <p>This code is intended as a fairly simple demonstration of how to enable an Apache Flink job to interact with DataStax Astra. There is certainly room for optimization here. A simple example: Flink's CassandraSink will open a new Session on each open() call even though these Session objects are thread-safe. A more robust implementation would be more aggressive about memoizing Sessions, encouraging a minimal number of open sessions for multiple operations on the same JVM. This work may be undertaken in the future, but for the moment it is beyond the scope of what we're aiming for here.</p> <ul> <li>\u2139\ufe0f Introduction to Apache Flink</li> <li>\ud83d\udce5 Download Apache Flink</li> </ul>"},{"location":"pages/tools/integration/flink/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should clone this GitHub Repository</li> <li>You should have Apache Flink, Gradle, and Java installed in your system. </li> </ul> <p>Note</p> <p>For this tutorial, you will need either Java 8 or Java 11 to run it. Any other version might run into an exception and cause build failure.</p>"},{"location":"pages/tools/integration/flink/#installation-and-setup","title":"Installation and Setup","text":"<p>Now that you have gathered all of your prerequisites, you are ready to configure and setup for this example.</p> <ol> <li>Create a keyspace named <code>example</code> in your Astra database. At the moment, this name will be hard-coded.</li> <li>Download the secure connect bundle (SCB) for your database. You can find this under the \"Connect\" tab in the UI. </li> <li>Once you have downloaded your secure connect bundle, place it in <code>app/src/main/resources</code> in your GitHub directory (You do not have to unzip the file).</li> <li>Create a properties file titled <code>app.properties</code>, and place it in <code>app/src/main/resources/</code>.</li> <li>Add properties specifying your Astra client ID, Astra secret, and SCB file name. These should map to the \"astra.clientid\", \"astra.secret\", and \"astra.scb\" properties respectively. Your <code>app.properties</code> file should look something like this: <pre><code>astra.clientid=Bwy...\nastra.secret=E4dfE...\nastra.scb=secure-connect-test.zip\n</code></pre></li> </ol>"},{"location":"pages/tools/integration/flink/#test-and-validate","title":"Test and Validate","text":"<p>Once you have completed all of the prerequisites along with the section above, you can move on to this section to run the sample app and validate the connection between Flink and Astra.</p> <ol> <li>In your <code>flink-astra</code> cloned GitHub directory, run <code>./gradlew run</code></li> <li>Verify that the application runs and exits normally. If this completed successfully you should see the following message: <pre><code>BUILD SUCCESSFUL in 31s\n3 actionable tasks: 2 executed, 1 up-to-date\n</code></pre></li> <li>Navigate back to the Astra UI to use the CQL Console. You can run this sample query to confirm that the defined data from the sample app has been loaded properly: <pre><code>token@cqlsh:example&gt; select * from wordcount ;\n\n word   | count\n--------+-------\n   dogs |     1\n lazier |     1\n  least |     1\n  foxes |     1\n jumped |     1\n     at |     1\n    are |     1\n   just |     1\n  quick |     1\n   than |     1\n    fox |     1\n    our |     1\n    dog |     2\n     or |     1\n   over |     1\n  brown |     1\n   lazy |     1\n    the |     2\n\n(18 rows)\ntoken@cqlsh:example&gt; \n</code></pre> \ud83c\udfe0 Back to home </li> </ol>"},{"location":"pages/tools/integration/grafana/","title":"Grafana","text":""},{"location":"pages/tools/integration/grafana/#overview","title":"Overview","text":"<p>Grafana is a multi-platform open source analytics and interactive visualization web application. It provides charts, graphs, and alerts for the web when connected to supported data sources. A licensed Grafana Enterprise version with additional capabilities is also available as a self-hosted installation or an account on the Grafana Labs cloud service. It is expandable through a plug-in system. End users can create complex dashboards using interactive query builders.</p> <p>Community-developed Cassandra Datasource for Grafana supports both Apache Cassandra as well as DataStax AstraDB, allowing to use Cassandra as a data backend for Grafana. Data can be pulled using simple Query Configurator or more advanced but powerful Query Editor.</p> <p></p> <p>(On the picture: Query Editor at work)</p>"},{"location":"pages/tools/integration/grafana/#prerequisites","title":"Prerequisites","text":"<ul> <li>To use Grafana, you will need a running Grafana instance deployed locally or in a cloud. Locally launched Grafana in Docker works well too.</li> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle and unpack it.</li> </ul> <p>Keep the token information and the bundle file location ready: these will be soon provided in the datasource configuration.</p>"},{"location":"pages/tools/integration/grafana/#quickstart","title":"Quickstart","text":""},{"location":"pages/tools/integration/grafana/#install-the-plugin-using-cli-or-using-web-interface","title":"Install the plugin using CLI or using web-interface","text":"<ul> <li>Install the plugin using grafana console tool:</li> </ul> <pre><code>grafana-cli plugins install hadesarchitect-cassandra-datasource\n</code></pre> <p>It will be installed into your grafana plugins directory; the default is /var/lib/grafana/plugins. Alternatively, enable it using Grafana Web UI.</p>"},{"location":"pages/tools/integration/grafana/#create-a-datasource","title":"Create a Datasource","text":"<ul> <li>Add the Apache Cassandra Data Source as a data source at the datasource configuration page. </li> <li> <p>Enable <code>Custom TLS Settings</code> button and configure the datasource using following details:</p> </li> <li> <p>Host: specify the <code>host:cql_port</code> values from the <code>config.json</code> file from the SecureConnectBundle. It should look like <code>1234567890qwerty-eu-central-1.db.astra.datastax.com:29402</code> IMPORTANT Notice, it has to be the <code>cql_port</code> value, not just <code>port</code></p> </li> <li>User: <code>Client ID</code> of the API Token</li> <li>Password: <code>Client Secret</code> of the API Token</li> <li>Certificate Path: <code>/path/to/cert</code> (use <code>cert</code> file from SecureConnectBundle)</li> <li>Root Certificate Path: <code>/path/to/key</code> (use <code>key</code> file from SecureConnectBundle)</li> <li>RootCA Certificate Path: <code>/path/to/ca.crt</code> (use <code>ca.crt</code> file from SecureConnectBundle)</li> </ul> <p>Push the <code>Save and Test</code> button, if everything is right, you will see a <code>Database Connection OK</code> message.</p> <p></p> <p>If the database cannot be connected, check the following known common issues:</p>"},{"location":"pages/tools/integration/grafana/#known-issues","title":"Known issues:","text":"<p>Misconfigured Port (Using <code>port</code> instead of <code>cql-port</code>)</p> <p>Sometimes users specify the wrong port and a connection cannot be established. If you can't connect to your Astra instance, please check if the correct port specified in the datasource config (See step 3 above)</p> <p>Unavailable TLS files</p> <p>if you have an error message like <code>[ERROR] cassandra-backend-datasource: Unable create tls config, open /cert: permission denied</code>, it means that Grafana cannot open TLS certificate files. Set the proper permission f.e. using <code>chown</code> command. If you copied the files using <code>docker cp</code> command, they'll be copied by a root user and grafana will have no access to them.</p>"},{"location":"pages/tools/integration/grafana/#usage","title":"Usage","text":"<p>First, to visualize the data, you have to create a panel. Choose or create a dashboard and create a panel. In the panel setup, choose the correct datasource from the previous steps.</p> <p>There are two ways to query data from Cassandra: Query Configurator and Query Editor. Configurator is easier to use but has limited capabilities, Editor is more powerful but requires an understanding of CQL. </p>"},{"location":"pages/tools/integration/grafana/#query-configurator","title":"Query Configurator","text":"<p>Query Configurator is the easiest way to query data. At first, enter the keyspace and table name, then pick proper columns. If keyspace and table names are given correctly, the datasource will suggest the column names automatically.</p> <ul> <li>Time Column - the column storing the timestamp value, it's used to answer \"when\" question. </li> <li>Value Column - the column storing the value you'd like to show. It can be the <code>value</code>, <code>temperature</code> or whatever property you need.</li> <li>ID Column - the column to uniquely identify the source of the data, e.g. <code>sensor_id</code>, <code>shop_id</code>, or whatever allows you to identify the origin of data.</li> </ul> <p>After that, you have to specify the <code>ID Value</code>, the particular ID of the data origin you want to show. You may need to enable \"ALLOW FILTERING\" although we recommend avoiding it.</p> <p>Example Imagine you want to visualise reports of a temperature sensor installed in your smart home. Given the sensor reports its ID, time, location and temperature every minute, we create a table to store the data and put some values there:</p> <pre><code>CREATE TABLE IF NOT EXISTS temperature (\n    sensor_id uuid,\n    registered_at timestamp,\n    temperature int,\n    location text,\n    PRIMARY KEY ((sensor_id), registered_at)\n);\n\ninsert into temperature (sensor_id, registered_at, temperature, location) values (99051fe9-6a9c-46c2-b949-38ef78858dd0, '2020-04-01T11:21:59.001+0000', 18, 'kitchen');\ninsert into temperature (sensor_id, registered_at, temperature, location) values (99051fe9-6a9c-46c2-b949-38ef78858dd0, '2020-04-01T11:22:59.001+0000', 19, 'kitchen');\ninsert into temperature (sensor_id, registered_at, temperature, location) values (99051fe9-6a9c-46c2-b949-38ef78858dd0, '2020-04-01T11:23:59.001+0000', 20, 'kitchen');\n</code></pre> <p>In this case, we have to fill the configurator fields the following way to get the results:</p> <ul> <li>Keyspace - smarthome (keyspace name)</li> <li>Table - temperature (table name)</li> <li>Time Column - registered_at (occurence)</li> <li>Value Column - temperature (value to show)</li> <li>ID Column - sensor_id (ID of the data origin)</li> <li>ID Value - 99051fe9-6a9c-46c2-b949-38ef78858dd0 ID of the sensor</li> <li>ALLOW FILTERING - FALSE (not required, so we are happy to avoid)</li> </ul> <p>In the case of a few origins (multiple sensors), you will need to add more rows. If your case is as simple as that, a query configurator will be a good choice, otherwise please proceed to the query editor.</p>"},{"location":"pages/tools/integration/grafana/#query-editor","title":"Query Editor","text":"<p>Query Editor is a more powerful way to query data. To enable query editor, press the \"toggle text edit mode\" button.</p> <p></p> <p>Query Editor unlocks all possibilities of CQL including aggregations, etc. </p> <pre><code>SELECT sensor_id, CAST(temperature as double), registered_at FROM test.test WHERE id IN (99051fe9-6a9c-46c2-b949-38ef78858dd1, 99051fe9-6a9c-46c2-b949-38ef78858dd0) AND created_at &gt; $__timeFrom and created_at &lt; $__timeTo\n</code></pre> <ol> <li>Follow the order of the SELECT expressions, it's important! </li> <li>Identifier - the first property in the SELECT expression must be the ID, something that uniquely identifies the data (e.g. <code>sensor_id</code>)</li> <li>Value - The second property must be the value that you are going to show </li> <li> <p>Timestamp - The third value must be a timestamp of the value. All other properties will be ignored</p> </li> <li> <p>To filter data by time, use <code>$__timeFrom</code> and <code>$__timeTo</code> placeholders as in the example. The datasource will replace them with time values from the panel. Notice It's important to add the placeholders otherwise query will try to fetch data for the whole period of time. Don't try to specify the timeframe on your own, just put the placeholders. It's grafana's job to specify time limits.</p> </li> </ol> <p></p>"},{"location":"pages/tools/integration/grafana/#contacts","title":"Contacts","text":"<p>We hope it works well for you! In case of any questions please contact developers using GitHub Discussions.</p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/integration/liquibase/","title":"Liquibase","text":""},{"location":"pages/tools/integration/liquibase/#overview","title":"Overview","text":"<p>The purpose of this document is to guide you through the process of creating a new Liquibase project with Cassandra. In this tutorial, you will generate an example project and follow the instructions to apply and learn concepts associated with creating new Liquibase projects with Cassandra on DataStax Astra. </p> <ul> <li>\u2139\ufe0f Introduction to Liquibase</li> <li>\ud83d\udce5 Liquibase Quick Install</li> </ul>"},{"location":"pages/tools/integration/liquibase/#prerequisites","title":"Prerequisites","text":""},{"location":"pages/tools/integration/liquibase/#liquibase-prerequisites","title":"Liquibase Prerequisites","text":"<ul> <li>Install the latest version of Liquibase</li> <li>Ensure the Liquibase install directory path is set to a location in the PATH System variable</li> <li>Download the liquibase-cassandra-.jar latest release extension jar file and place this file in the `liquibase/lib` install directory"},{"location":"pages/tools/integration/liquibase/#astra-prerequisites","title":"Astra Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>Download the Simba JDBC Jar driver file for Apache Cassandra and place this file in the `liquibase/lib` install directory</li> <li>Clone this repository to use to set up CQL-Proxy which is a sidecar that enables unsupported CQL drivers to work with DataStax Astra</li> <li>You need your Astra Token and Astra Database ID to use CQL-Proxy</li> <li>Follow the steps in the repo to spin up CQL-Proxy using Terminal/Command Line. Once successfully running, you should see the following output:</li> <pre><code>{\"level\":\"info\",\"ts\":1651012815.176512,\"caller\":\"proxy/proxy.go:222\",\"msg\":\"proxy is listening\",\"address\":\"[::]:9042\"}\n</code></pre> </ul>"},{"location":"pages/tools/integration/liquibase/#installation-and-setup","title":"Installation and Setup","text":"<p>To create a Liquibase project with Cassandra on DataStax Astra on your machine, begin with the following steps:</p> <ol> <li> <p>Create a new project folder and name it LiquibaseProj.</p> </li> <li> <p>In your LiquibaseProj folder, create a new text file and name it dbchangelog.sql.</p> </li> <li> <p>Open the dbchangelog.sql file and update the changelog file with the following code snippet:  <code>--liquibase formatted sql</code> </p> </li> <li> <p>In your LiquibaseProj folder, create a new text file and name it liquibase.properties.</p> </li> <li> <p>Edit the liquibase.properties file to add the following properties:</p> </li> </ol> <p><pre><code>changelog-file: dbchangelog.sql\nurl: jdbc:cassandra://localhost:9042/test;DefaultKeyspace=test;TunableConsistency=6\ndriver: com.simba.cassandra.jdbc42.Driver\ndefaultSchemaName: test\nliquibase.hub.mode=off \n</code></pre> In <code>liquibase.properties</code> above, replace test with the name of your own keyspace.</p> <ol> <li>Add a changeset to the changelog \u2013 changeset are uniquely identified by author and id attributes. Liquibase attempts to execute each changeset in a transaction that is committed at the end. In the <code>dbchangelog.sql</code> file, add a new changeset with a create table statement. We will create a new table department using a changeset as follows:</li> </ol> <pre><code>--liquibase formatted sql\n\n--changeset bob:1\nCREATE TABLE test.DEPARTMENT (id int PRIMARY KEY, NAME text, ACTIVE BOOLEAN);\n</code></pre> <ol> <li> <p>Open the command prompt. Navigate to the LiquibaseProj directory. Run the following command: liquibase update</p> </li> <li> <p>From a SQL Client User Interface, check your database changes. You should see a new department table added to the database. For example: <code>SELECT * FROM \"keyspace\".\"department\";</code></p> </li> </ol> ID NAME ACTIVE NULL NULL NULL <p>After your first update, your database will contain the table you added along with the DATABASECHANGELOG and DATABASECHANGELOGLOCK tables:</p> <ul> <li>DATABASECHANGELOG table. This table keeps a record of all the changesets that were deployed. When you deploy, the changesets in the changelog are compared with the DATABASECHANGELOG tracking table, and only the new changesets that were not found in the DATABASECHANGELOG will be deployed.</li> <li>DATABASECHANGELOGLOCK table. This table is used internally by Liquibase to manage access to the DATABASECHANGELOG table during deployment and ensure only one instance of Liquibase is updating the database at a time, whether that is creating, updating, or deleting changes.</li> </ul>"},{"location":"pages/tools/integration/pentaho/","title":"Pentaho","text":"<p>This article was originally written by Erick Ramirez on community.datastax.com</p> <p></p>"},{"location":"pages/tools/integration/pentaho/#overview","title":"Overview","text":"<p>Pentaho Data Integration (PDI) provides the Extract, Transform, and Load (ETL) capabilities that facilitate the process of capturing, cleansing, and storing data using a uniform and consistent format that is accessible and relevant to end users and IoT technologies.</p> <ul> <li>\u2139\ufe0f Introduction to PDI</li> <li>\ud83d\udce5 PDI Download Link</li> <li>\ud83d\udcd8 Installation Guide on Linux</li> <li>\ud83d\udcd8 Installation Guide on Windows</li> </ul>"},{"location":"pages/tools/integration/pentaho/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure bundle</li> <li>You should Download and install PDI</li> </ul> <p>This article was written for version <code>9.1</code> on <code>MacOS</code> but it should also work for the Windows version.</p>"},{"location":"pages/tools/integration/pentaho/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"pages/tools/integration/pentaho/#step-1-download-jdbc-driver","title":"\u2705 Step 1: Download JDBC Driver","text":"<p>Download the JDBC driver from the DataStax website:</p> <ol> <li>Go to https://downloads.datastax.com/#odbc-jdbc-drivers.</li> <li>Select Simba JDBC Driver for Apache Cassandra.</li> <li>Select JDBC 4.2.</li> <li>Read the license terms and accept it (click the checkbox).</li> <li>Hit the blue Download button.</li> <li>Once the download completes, unzip the downloaded file.</li> </ol>"},{"location":"pages/tools/integration/pentaho/#step-2-import-driver-jar-in-pentaho","title":"\u2705 Step 2: Import Driver JAR in Pentaho","text":"<p>Deploy the Simba driver to Pentaho servers using the distribution tool:</p> <ol> <li> <p>On your laptop or PC, copy the Simba JAR to the JDBC distribution directory:</p> <pre><code>$ cp CassandraJDBC42.jar pentaho/jdbc-distribution/\n</code></pre> </li> <li> <p>Run the distribution tool (<code>distribute-files.bat</code> on Windows)</p> <pre><code>$ cd /Applications/Pentaho/jdbc-distribution\n$ ./distribute-files.sh CassandraJDBC42.jar\n</code></pre> </li> <li> <p>Verify that the JAR has been copied to the PDI library:</p> <pre><code>$ cd /Applications/Pentaho\n$ ls -lh design-tools/data-integration/lib/CassandraJDBC42.jar\n</code></pre> <ul> <li>Expected output:</li> </ul> <pre><code>-rw-r--r--  1 erick  vaxxed   16M 14 Sep 22:18 design-tools/data-integration/lib/CassandraJDBC42.jar\n</code></pre> <pre><code>$ file design-tools/data-integration/lib/CassandraJDBC42.jar\n</code></pre> <ul> <li>Expected output:</li> </ul> <pre><code>design-tools/data-integration/lib/CassandraJDBC42.jar: Java archive data (JAR)\n</code></pre> </li> <li> <p>Restart Pentaho on your workstation for the Simba driver to be loaded.</p> </li> </ol>"},{"location":"pages/tools/integration/pentaho/#step-3-define-a-connection-in-pentaho","title":"\u2705 Step 3: Define a connection in Pentaho","text":"<p>In this section we assume that your database in Astra is called <code>pentaho</code> and as such the download secure bundle is called <code>secure-connect-pentaho.zip</code></p> <ol> <li>Create a new Transformation.</li> <li>Open a new Database Connection dialog box.</li> <li>In the Connection name field, give your DB connection a name.</li> <li>Under Connection type, select Generic database.</li> <li> <p>Set the Custom connection URL. (Note that you will need to specify the full path to your secure bundle and adapt to your database name)</p> <pre><code> jdbc:cassandra://;AuthMech=2;TunableConsistency=6;SecureConnectionBundlePath=/path/to/secure-connect-pentaho.zip\n</code></pre> </li> <li> <p>In the Username field, enter the string <code>token</code>.</p> </li> <li>In the Password field, paste the value of the token you created in the Prerequisites section above. The token looks like <code>AstraCS:AbC...XYz:123...edf0</code> </li> <li>Click on the Test Connection button to confirm that the driver configuration is working:    </li> <li>Click on the OK button to save the connection settings.</li> </ol>"},{"location":"pages/tools/integration/pentaho/#step-4-final-test","title":"\u2705 Step 4: Final Test","text":"<p>Connect to your Astra DB by launching the SQL Editor in Pentaho and run a simple CQL statement. For example:</p> <p></p> <p>Here's an example output:</p> <p></p> <p>You should also be able to browse the keyspaces in your Astra DB using the DataBase Explorer. Here's an example output:</p> <p></p> <p>\ud83c\udfe0 Back to HOME |</p>"},{"location":"pages/tools/integration/quine.io/","title":"Quine","text":""},{"location":"pages/tools/integration/quine.io/#overview","title":"Overview","text":"<p>Quine is a streaming graph capable of building high-volumes of data into a stateful graph.  It allows for real-time traversals on a graph, as well as for the data to be streamed-out for event processing.</p> <ul> <li>\u2139\ufe0f Quine Documentation - Core Concepts</li> </ul>"},{"location":"pages/tools/integration/quine.io/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Connect Bundle</li> <li>You should install a JDK (version 11 or higher).</li> </ul> <p>This article was written for Quine version <code>1.2.1</code> on <code>MacOS</code> with Java <code>11.10</code>.</p>"},{"location":"pages/tools/integration/quine.io/#installation","title":"Installation","text":"<p>\u2705 Step 1 Download and install</p> <p>Follow the Download Quine page to download the JAR.  Choose/create a directory for Quine, and copy the JAR to this location:</p> <pre><code>mkdir ~/local/quine\ncp ~/Downloads/quine-1.2.1.jar ~/local/quine\n</code></pre> <p>\u2705Step 2 Create the keyspace <code>quine</code></p> <p>From the Astra DB console, click on your database name, or create a new one called <code>quine</code> (or another name of your preference). Scroll down to where the keyspaces are listed, and click the <code>Add Keyspace</code> button to create a new keyspace. Name this keyspace <code>quine</code>.</p> <p>\u2705 Step 3 Configuration</p> <p>Create a <code>quine.conf</code> file inside the <code>quine</code> directory:</p> <pre><code>cd ~/local/quine\ntouch quine.conf\n</code></pre> <p>Edit the <code>quine.conf</code> file to look like the following:</p> <pre><code>quine.store {\n  # store data in an Apache Cassandra instance\n  type = cassandra\n\n  # the keyspace to use\n  keyspace = quine\n\n  should-create-keyspace = false\n  should-create-tables = true\n\n  replication-factor = 3\n\n  write-consistency = LOCAL_QUORUM\n  read-consistency = LOCAL_QUORUM\n\n  local-datacenter = \"us-east1\"\n\n  write-timeout = \"10s\"\n  read-timeout = \"10s\"\n}\ndatastax-java-driver {\n  advanced {\n    auth-provider {\n      class = PlainTextAuthProvider\n      username = \"token\"\n      password = \"AstraCS:qFDPGZEgBlahBlahYourTokenGoesHerecff15fc\"\n    }\n  }\n  basic {\n    cloud {\n      secure-connect-bundle = \"/Users/aaronploetz/local/secure-connect-quine.zip\"\n    }\n  }\n}\n</code></pre> <p>Astra-Specific Settings:</p> <p><code>type = cassandra</code> - If the <code>type</code> is not specified, Quine defaults to use RocksDB.</p> <p><code>should-create-keyspace = false</code> - Remember keyspaces can only be created in Astra via the dashboard.</p> <p><code>replication-factor = 3</code> - Defaults to <code>1</code> if not set, which will not work with Astra DB.</p> <p><code>write-consistency = LOCAL_QUORUM</code> - Minimum consistency level required by Astra.</p> <p><code>read-consistency = LOCAL_QUORUM</code> - Minimum consistency level required by Astra.</p> <p><code>local-datacenter = \"us-east1\"</code> - Set Astra DB's cloud region as the local DC.</p> <p><code>username = \"token\"</code> - No need to mess with this.  Just leave it as the literal word \"token.\"</p> <p><code>password</code> - A valid token for an Astra DB cluster.</p> <p><code>secure-connect-bundle</code> - A valid, local file location of a downloaded secure connect bundle.  Also, the driver gets the Astra DB hostname and Cloud provider from the secure bundle, so there is no need to specify endpoints separately.</p> <p>\u2705 Step 4 Download Secure Connect Bundle (SCB) In your Astra DB console navigate to your database in the dashboard, then the connect tab.  In the 'Connect using a Driver' , and then the click 'Java' Java section. Then click the 'download bundle' on the right. Without unzipping it, move the downloaded file to the directory you created in step 1, that contains the quine-1.2.1.jar.  The file will be named <code>secure-connect-[your databasename].zip</code>, so in this example <code>secure-connect-quine.zip</code>.  You will reference this file directly in the previous configation file step above.</p> <p>\u2705 Step 5 Run Quine</p> <p>To run Quine, invoke the JAR with Java, while passing the <code>quine.conf</code> in the <code>config.file</code> parameter:</p> <pre><code>$ java -Dconfig.file=quine.conf -jar quine-1.2.1.jar\n\n2022-06-15 15:11:52,666 WARN [NotFromActor] [s0-io-4] com.datastax.oss.driver.internal.core.cql.CqlRequestHandler - Query '[0 values] CREATE TABLE IF NOT EXISTS journals (quine_id blob,timestamp bigint,data blob,PRIMARY KEY(quine_id,timestamp)) WITH CLUSTERING ORDER BY (timestamp ASC) AND compaction={'class':'TimeWindowCompactionStrategy'}' generated server side warning(s): Ignoring provided values [compaction] as they are not supported for Table Properties (ignored values are: [additional_write_policy, bloom_filter_fp_chance, caching, cdc, compaction, compression, crc_check_chance, dclocal_read_repair_chance, extensions, gc_grace_seconds, id, max_index_interval, memtable_flush_period_in_ms, min_index_interval, nodesync, read_repair, read_repair_chance, speculative_retry])\nGraph is ready!\nApplication state loaded.\nQuine app web server available at http://localhost:8080\n</code></pre> <p>As shown above, Astra DB will return a warning about table valid options which it will ignore.</p> <p>You can now use Quine's visual graph explorer in a web browser, and create/traverse data with either Gremlin or Cypher: http://localhost:8080/</p> <p></p> <p>The Swagger spec for the Quine API can also be found locally at: http://localhost:8080/docs</p> <p>\u2705 Optional Step 6: Loading some sample data</p> <p>Download attempts.json (74.MB) from the Quine Password Spraying example and locate it in the root of your Quine directory alongside the quine-1.2.1.jar file. Make sure the Quine server is not running -- it's requires graceful shutdown.  Simply issue a curl -X \"POST\" \"http://127.0.0.1:8080/api/v1/admin/shutdown\" in a seperate terminal or command prompt window to do so.</p> <p>Then execute </p> <pre><code>java -Dconfig.file=quine.conf -jar quine-1.2.1.jar -r passwordspraying\n</code></pre> <p>Note that it will take a few minutes to load!  When it is completed successfully you will see:</p> <pre><code>INGEST-1 status is completed and ingested 55000\n</code></pre> <p>\u2705 Troubleshooting</p> <p>If the output does not read: </p> <pre><code>Graph is ready!\nApplication state loaded.\nQuine app web server available at http://locahost:8080\n</code></pre> <p>Then look for exceptions.</p> <p>If you see an error:</p> <pre><code>com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Clustering key columns must exactly match columns in CLUSTERING ORDER BY directive\n</code></pre> <p>Check to ensure the snapshots table exists:</p> <pre><code>cqlsh&gt; use quine;\n\ncqlsh&gt; desc quine;\n</code></pre> <p>If not, execute this command in CQLSH to create it:</p> <pre><code>CREATE TABLE quine.snapshots (\n    quine_id blob,\n    timestamp bigint,\n    multipart_index int,\n    data blob,\n    multipart_count int,\n    PRIMARY KEY (quine_id, timestamp, multipart_index)\n) WITH CLUSTERING ORDER BY (timestamp DESC, multipart_index ASC)\n    AND additional_write_policy = '99PERCENTILE'\n    AND bloom_filter_fp_chance = 0.01\n    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n    AND comment = ''\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.UnifiedCompactionStrategy'}\n    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n    AND crc_check_chance = 1.0\n    AND default_time_to_live = 0\n    AND gc_grace_seconds = 864000\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 128\n    AND read_repair = 'BLOCKING'\n    AND speculative_retry = '99PERCENTILE';\n</code></pre>"},{"location":"pages/tools/integration/quine.io/#acknowledgements","title":"Acknowledgements","text":"<p>Special thanks goes out to Ryan Wright and Leif Warner of thatDot for their help with getting Quine running and connected.</p> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/integration/stepzen/","title":"StepZen","text":""},{"location":"pages/tools/integration/stepzen/#overview","title":"Overview","text":"<p>StepZen helps developers build GraphQL faster, deploy in seconds, and run on StepZen. It simplifies how you access the data you need, and with zero infrastructure to build or manage, you can focus on crafting modern data-driven experiences. </p> <ul> <li>\u2139\ufe0f Introduction to StepZen</li> <li>\ud83d\udce5 StepZen Quick Install</li> </ul>"},{"location":"pages/tools/integration/stepzen/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should create a StepZen account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should retrieve your **Database ID** and **Region** from your Astra DB dashboard</li> </ul>"},{"location":"pages/tools/integration/stepzen/#installation-and-setup","title":"Installation and Setup","text":"<p>After logging into your StepZen account and have all of your credentials ready, you can navigate to this page or follow the steps below to setup StepZen.</p> <ol> <li> <p>First, install the StepZen CLI  <pre><code>npm install -g stepzen\n</code></pre></p> </li> <li> <p>Log in with your StepZen account <pre><code>stepzen login -a YOUR_ACCOUNT\n</code></pre></p> </li> <li> <p>Enter your Admin Key when prompted <pre><code>YOUR_ADMIN_KEY\n</code></pre> Note: For steps #2 and #3, if it does not autopopulate, you can find this information in your StepZen account under \"My Stepzen\".</p> </li> <li> <p>Import a DataStax Astra DB GraphQL API from your terminal <pre><code>stepzen import graphql\n</code></pre></p> </li> <li>When prompted, enter your GraphQL API details:</li> </ol> What is the GraphQL endpoint URL? <code>https://&lt;ASTRA_DB_ID&gt;-&lt;ASTRA_DB_REGION&gt;.apps.astra.datastax.com/api/graphql/&lt;KEYSPACE_NAME&gt;</code> Prefix to add to all generated type names (leave blank for none) Optional. Adviced to use when you're importing multiple data sources. Add an HTTP header, e.g. Header-Name: header value (leave blank for none) <code>X-Cassandra-Token: &lt;APPLICATION_TOKEN&gt;</code> <p>Once successful, you should see the following output: <pre><code>Generating schemas...... done\nSuccessfully imported schema graphql from StepZen\n</code></pre> 6. Type <code>stepzen start</code> in your terminal</p> <p>StepZen introspects your DataStax Astra DB GraphQL API and builds your endpoint. </p> <p>You should receive something similar to this output: <pre><code>File changed: /your/path/.DS_Store\nDeploying api/coy-aardwolf to StepZen... done in 4.8s\n\nYour API url is  https://&lt;YOUR_ACCOUNT&gt;.stepzen.net/api/&lt;YOUR_ENDPOINT_NAME&gt;/__graphql\n\nYou can test your hosted API with cURL:\n\ncurl https://&lt;YOUR_ACCOUNT&gt;.stepzen.net/api/&lt;YOUR_ENDPOINT_NAME&gt;/__graphql \\\n   --header \"Authorization: Apikey $(stepzen whoami --apikey)\" \\\n   --header \"Content-Type: application/json\" \\\n   --data '{\"query\": \"your graphql query\"}'\n\nor explore it with GraphiQL at  http://localhost:5001/api/&lt;YOUR_ENDPOINT_NAME&gt;\n\nWatching ~/your/path/here for GraphQL changes...\n</code></pre></p>"},{"location":"pages/tools/integration/stepzen/#test-and-validate","title":"Test and Validate","text":"<ol> <li>To quickly validate that the previous steps went smoothly, navigate to your local host to view the StepZen UI.  <code>http://localhost:5001/api/&lt;YOUR_ENDPOINT_NAME&gt;</code></li> <li>Using the Explorer you can visualize what tables are in your keyspace, and by selecting each box, you are building your GraphQL query which shows up in the middle console.  </li> </ol> <p>...and you're done! You can now use StepZen to build your GraphQL queries with ease to use with your applications. </p>"},{"location":"pages/tools/integration/strapi/","title":"Strapi","text":""},{"location":"pages/tools/integration/strapi/#overview","title":"Overview","text":"<p>Strapi is an open-source headless CMS that gives developers the freedom to choose their favorite tools and frameworks and allows editors to manage and distribute their content using their application\u2019s admin panel. Based on a plugin system, its admin panel and API are extensible. Every part is customizable to match any use case. Strapi also has a built-in user system to manage what the administrators and end users can access.</p> <ul> <li>\u2139\ufe0f Introduction to Strapi</li> <li>\ud83d\udce5 Strapi Quick Install</li> </ul>"},{"location":"pages/tools/integration/strapi/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should retrieve your **Database ID** and **Region** from your Astra DB dashboard</li> <li>Install node (14.17.3 version).</li> </ul>"},{"location":"pages/tools/integration/strapi/#installation-and-setup","title":"Installation and Setup","text":"<p>Follow the steps below to setup Strapi locally.</p> <ol> <li> <p>First, install Strapi locally:  <pre><code>npx create-strapi-app my-project\n</code></pre> You can view your Strapi project as it is hosted locally at http://localhost:1337/admin.</p> </li> <li> <p>Install the Strapi hook: <pre><code>npm i strapi-hook-astra\n</code></pre></p> </li> <li> <p>Activate the hook by adding the following to <code>./config/hook.js</code> of the sample Strapi Project: <pre><code>module.exports = {\n    settings: {\n        astra: {\n            enabled: true,\n            token: 'REPLACE_ME',\n            databaseId: 'REPLACE_ME',\n            databaseRegion: 'REPLACE_ME',\n            keyspace: 'REPLACE_ME',\n            collection: 'REPLACE_ME'\n        },\n    }\n};\n</code></pre> Where:</p> </li> <li><code>token</code>: Generate a token from Astra DB.</li> <li><code>databaseId</code>: Enter your Astra DB database ID from your database URL.</li> <li><code>databaseRegion</code>: Enter your Astra DB database region</li> <li><code>keyspace</code>: Enter your Astra DB keyspace name.</li> <li><code>collection</code>: Enter your Astra DB collection name.</li> </ol>"},{"location":"pages/tools/integration/strapi/#test-and-validate","title":"Test and Validate","text":"<ol> <li> <p>Create a document: <pre><code>strapi.services.astra.create(document);\n</code></pre> |Parameter|Type|Explanation|Values| |:---|:---|:---|:---| |document|json|Create a document|var dataString = '{ \"name\": \"John\", \"last_name\": \"Doe\" }'|</p> </li> <li> <p>Get document by ID: <pre><code>strapi.services.astra.getById(documentId);\n</code></pre> |Parameter|Type|Explanation|Values| |:---|:---|:---|:---| |documentId|string|Get document by documentId|var documentId = \"your_document_id\"|</p> </li> <li> <p>Get document by path: <pre><code>strapi.services.astra.getByPath();\n</code></pre></p> </li> <li> <p>Search a collection: <pre><code>strapi.services.astra.searchCollection(query,pagesize);\n</code></pre> |Parameter|Type|Explanation|Values| |:---|:---|:---|:---| |query|string|Search collection via query|var query = {\"name\": { \"$eq\": \"John\" }}| |pagesize|int|Number of documents to fetch|int page_size = 3|</p> </li> </ol> <p>For more, see the Strapi documentation.</p>"},{"location":"pages/tools/integration/temporal/","title":"Temporal","text":""},{"location":"pages/tools/integration/temporal/#overview","title":"Overview","text":"<p>Temporal.io is an open source microservice orchestration platform that assists in tracking workflows in your application development. It provides the user with a plug-and-play persistence layer that lets the user choose and configure their Temporal Server with their preferred backend. Currently, Temporal is compatible with Postgres, MySQL, and Apache Cassandra\u24c7 as backend dependencies. </p> <ul> <li>\ud83d\udce5 Temporal Quick Install</li> <li>\u2139\ufe0f Introduction to Temporal</li> <li>\u2139\ufe0f Part 1: Introduction to Temporal and Cassandra, Astra DB</li> <li>\u2139\ufe0f Part 2: Connect Temporalio to Astra DB in 5 Easy Steps</li> <li>\u2139\ufe0f Part 3: Connect Temporalio to Astra DB With Kubernetes</li> <li>\ud83c\udfa5 Workflow with Temporal and Astra DB in 5 minutes</li> </ul>"},{"location":"pages/tools/integration/temporal/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul> <p>Note</p> <p>This runbook was written using Mac OS Monterey but it will also work with Windows. Any Windows-specific instructions will be noted as such.  </p>"},{"location":"pages/tools/integration/temporal/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"pages/tools/integration/temporal/#step-1-setup-astra","title":"\u2705 Step 1: Setup Astra","text":"<ol> <li>In your Astra database, create two new keyspaces called \"temporal\" and \"temporal_visibility\". You will be using both of these in the next steps.</li> <li>Make sure to create an Astra token with Admin Role</li> <li>Get your Database ID</li> </ol> Find your Database ID in one of two ways: <ol> <li>Navigate to your your database and get the last ID in the URL: <code>https://astra.datastax.com/org/.../database/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx</code></li> <li>Copy and paste the Datacenter ID without the trailing <code>-1</code> from the Regions section of your Astra Dashboard. </li> </ol>"},{"location":"pages/tools/integration/temporal/#step-2-temporal-pre-setup","title":"\u2705 Step 2: Temporal Pre-setup","text":"<ol> <li>Clone this GitHub repository</li> <li>Navigate to your cloned repository and using your preferred text editor (e.g. VisualStudio or Sublime), update the .env file with your Astra Token and Astra Database ID that you obtained above. </li> </ol> <pre><code>ASTRA_TOKEN=&lt;your Astra token&gt;\nASTRA_DATABASE_ID=&lt;your DB ID&gt;\n</code></pre>"},{"location":"pages/tools/integration/temporal/#step-3-temporal-schema-migration-to-astra-db","title":"\u2705 Step 3: Temporal Schema Migration to Astra DB","text":"<p>For this step, you will set up the keyspaces you created earlier in the Astra prerequisites (temporal and temporal_visibility). You will be using <code>temporal-cassandra-tool</code> which is part of the Temporal repo and it relies on schema definition. </p> <ol> <li>Navigate to your cloned <code>temporal-astra-cql-proxy</code> directory</li> <li>Run the following commands to initialize the keyspaces that we created through Astra. Note that there are two sets of commands, one for <code>temporal</code> keyspace and one for <code>temporal_visibility</code> keyspace:</li> </ol> <pre><code>docker-compose -f docker-compose-schema.yaml run temporal-admin-tools \\\n-ep cql-proxy -k temporal setup-schema -v 0.0\ndocker-compose -f docker-compose-schema.yaml run temporal-admin-tools \\\n-ep cql-proxy -k temporal update-schema -d schema/cassandra/temporal/versioned/\n\ndocker-compose -f docker-compose-schema.yaml run temporal-admin-tools \\\n-ep cql-proxy -k temporal_visibility setup-schema -v 0.0\ndocker-compose -f docker-compose-schema.yaml run temporal-admin-tools \\\n-ep cql-proxy -k temporal_visibility update-schema -d schema/cassandra/visibility/versioned/\n</code></pre> <p>Once the process is completed, you should see a message similar to this: </p> <pre><code>2022-03-02T22:23:27.618Z    INFO    Validating connection to cassandra cluster. {\"logging-call-at\": \"cqlclient.go:112\"}\n2022-03-02T22:42:53.526Z    INFO    Connection validation succeeded.    {\"logging-call-at\": \"cqlclient.go:118\"}\n2022-03-02T22:42:53.526Z    INFO    Starting schema setup   {\"config\": {\"SchemaFilePath\":\"\",\"InitialVersion\":\"0.0\",\"Overwrite\":false,\"DisableVersioning\":false}, \"logging-call-at\": \"setuptask.go:57\"}\n2022-03-02T22:42:53.526Z    DEBUG   Setting up version tables   {\"logging-call-at\": \"setuptask.go:67\"}\n2022-03-02T22:42:54.120Z    DEBUG   Current database schema version 1.6 is greater than initial schema version 0.0. Skip version upgrade    {\"logging-call-at\": \"setuptask.go:116\"}\n2022-03-02T22:42:54.120Z    INFO    Schema setup complete   {\"logging-call-at\": \"setuptask.go:131\"}\n</code></pre> <p>Great! Your schemas have been migrated with Astra DB. </p> Confirm your tables exist in Astra <ul> <li>You can double-check to make sure the correct tables have been created by querying your database in Astra DB\u2019s CQL Console.</li> <li>Run <code>DESC tables;</code> in both your <code>temporal</code> and <code>temporal_visibility</code> keyspaces. You should see there are tables loaded in that were created by the schema migration with <code>temporal-cassandra-tool</code>. </li> </ul> <pre><code>token@cqlsh&gt; use temporal;\ntoken@cqlsh:temporal&gt; desc tables;\nhistory_node        tasks             cluster_metadata_info\ncluster_membership  namespaces        cluster_metadata     schema_version      namespaces_by_id  schema_update_history\nexecutions          queue_metadata  queue               history_tree    token@cqlsh:temporal&gt; use temporal_visibility;\ntoken@cqlsh:temporal_visibility&gt; desc tables;\nopen_executions  schema_update_history  schema_version  closed_executions\n</code></pre>"},{"location":"pages/tools/integration/temporal/#step-4-run-docker-compose","title":"\u2705 Step 4: Run Docker Compose","text":"<p>In this step, the <code>docker-compose.yaml</code> file is already provided for you in the <code>temporal-astra-cql-proxy</code> repo. This file creates different docker containers to run Temporal server. The persistence layer is configured for you to connect with <code>cql-proxy</code>, and it should pull your Astra credentials from when you set it earlier:</p> <pre><code>services:\n cql-proxy:\n   container_name: cqlproxy\n   image: datastax/cql-proxy:v${CQL_PROXY_VERSION}\n...\n   environment:\n     - ASTRA_TOKEN=${ASTRA_TOKEN}\n- ASTRA_DATABASE_ID=${ASTRA_DATABASE_ID}\n- HEALTH_CHECK=true\n</code></pre> <p>Now you can run the docker-compose command to start up Temporal:  <pre><code>docker-compose up\n</code></pre></p>"},{"location":"pages/tools/integration/temporal/#step-5-test-and-validate","title":"\u2705 Step 5: Test and Validate","text":"<p>You can test your connection and play with your Temporal cluster with these instructions.</p> <ol> <li>Make sure to use tctl to create namespaces dedicated to certain workflows: <pre><code>bash-5.0# tctl --namespace test namespace re\nNamespace test successfully registered.\n</code></pre></li> <li>When using the sample apps, keep in mind that you want to modify the starter and worker code so that it points to this specific Temporal deployment. For example: <pre><code>c, err := client.NewClient(client.Options{HostPort: \"127.0.0.1:7233\", Namespace: \"test\"})\n</code></pre></li> </ol> <p>Once you have this all running, you should be able to see your workflows reflect on both the Temporal UI and Astra UI.</p> <p></p> <p> \ud83c\udfe0 Back to HOME </p>"},{"location":"pages/tools/integration/vault/","title":"Vault","text":""},{"location":"pages/tools/integration/vault/#overview","title":"Overview","text":"<p>The purpose of this document is to guide you through the process using Astra DB as the storage configuration for your  HashiCorp Vault instance. In this tutorial, you will install Vault and edit the configuration file to point to Astra DB.</p> <ul> <li>\u2139\ufe0f Introduction to Vault</li> <li>\ud83d\udce5 Vault Quick Install</li> </ul>"},{"location":"pages/tools/integration/vault/#prerequisites","title":"Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> <li>You should Download your Secure Bundle</li> <li>You should Install Vault</li> <li>Clone this repository to use to set up CQL-Proxy which is a sidecar that enables unsupported CQL drivers to work with DataStax Astra   <li>You need your Astra Token and Astra Database ID to use CQL-Proxy</li> <li>Follow the steps in the repo to spin up CQL-Proxy using Terminal/Command Line. Once successfully running, you should see the following output: <code>{\"level\":\"info\",\"ts\":1651012815.176512,\"caller\":\"proxy/proxy.go:222\",\"msg\":\"proxy is listening\",\"address\":\"[::]:9042\"}</code></li>"},{"location":"pages/tools/integration/vault/#installation-and-setup","title":"Installation and Setup","text":"<ol> <li>In the Astra UI, create a keyspace called vault. </li> <li>Navigate to your CQL Console in the Astra UI. Issue the following statement to create a table called entries <pre><code>CREATE TABLE vault.\"entries\" (\nbucket text,\n    key text,\n    value blob,\n    PRIMARY KEY (bucket, key)\n) WITH CLUSTERING ORDER BY (key ASC);\n</code></pre></li> <li>Navigate to your terminal. Create a Vault configuration file <code>config.hcl</code> in your local directory.</li> <li>Edit your <code>config.hcl</code> file. Copy and paste the following to your configuration file:</li> </ol> <p><pre><code>storage \"cassandra\" {\nhosts            = \"localhost\"\nconsistency      = \"LOCAL_QUORUM\"\nprotocol_version = 3\n}\nlistener \"tcp\" {\naddress     = \"127.0.0.1:8200\"\ntls_disable = \"true\"\n}\napi_addr = \"http://127.0.0.1:8200\"\ncluster_addr = \"https://127.0.0.1:8201\"\nui = true\n</code></pre> 4. Run Vault from your terminal with the following command:</p> <p><code>vault server -config=config.hcl</code></p> <p>Successful output should look like this: <pre><code>==&gt; Vault server configuration:\n\nApi Address: http://127.0.0.1:8200\n                     Cgo: disabled\n         Cluster Address: https://127.0.0.1:8201\n              Go Version: go1.17.9\n              Listener 1: tcp (addr: \"127.0.0.1:8200\", cluster address: \"127.0.0.1:8201\", max_request_duration: \"1m30s\", max_request_size: \"33554432\", tls: \"disabled\")\nLog Level: info\n                   Mlock: supported: false, enabled: false\nRecovery Mode: false\nStorage: cassandra\n                 Version: Vault v1.10.2\n             Version Sha: 94325865b12662cb72efa3003d6aaa4f5ae57f3a\n==&gt; Vault server started! Log data will stream in below:\n</code></pre></p> <p>Note</p> <p>If you get a warning message about mlock not being supported, that is okay. However, for maximum security you should run Vault on a system that supports mlock.</p>"},{"location":"pages/tools/integration/vault/#test-and-validate","title":"Test and Validate","text":"<ol> <li>Once you see the above message that you successfully started Vault server, open a new terminal window.</li> <li>Run <code>vault operator init</code>. This will give you 5 Unseal Keys and a Root Token. Vault needs 3 Unseal Keys to properly unseal. </li> </ol> <p>Note</p> <p>You may get an error that looks like this: <code>Error initializing: Put \"https://127.0.0.1:8200/v1/sys/init\": http: server gave HTTP response to HTTPS client</code> This is because Vault runs on localhost, but the default address is HTTPS. Instead, you might need to specify the explicit address with the follow command: <code>vault operator init -address=http://127.0.0.1:8200</code></p> <p>Once Vault is initialized, it should give you an output of your Unseal Keys:</p> <pre><code>% vault operator init\nUnseal Key 1: rVRPym...\nUnseal Key 2: 71tY5X...\nUnseal Key 3: ETYWDf...\nUnseal Key 4: 4mDtrr...\nUnseal Key 5: o9X46m...\n\nInitial Root Token: hvs.gF14F...\n\nVault initialized with 5 key shares and a key threshold of 3. Please securely\ndistribute the key shares printed above. When the Vault is re-sealed,\nrestarted, or stopped, you must supply at least 3 of these keys to unseal it\nbefore it can start servicing requests.\n\nVault does not store the generated root key. Without at least 3 keys to\nreconstruct the root key, Vault will remain permanently sealed!\n</code></pre> <p>Note</p> <p>Make sure to save these keys somewhere safe. This is the only time that Vault will generate these keys. </p> <ol> <li>Run the Vault UI at http://127.0.0.1:8200</li> <li>Enter your Unseal Keys and Root Token</li> </ol> <p> </p> <ol> <li>You should now be able to access the Vault UI as well as cross-reference your CQL Console to make sure the requests are properly being written to your entries table! </li> </ol> <p>Note: When querying from the entries table, you must use double-quotes as <code>entries</code> is a reserved word for CQL.</p> <p> </p> <pre><code>token@cqlsh:vault&gt; use vault;                           //Switches to Vault keyspace\ntoken@cqlsh:vault&gt; expand on;                           //Prints output in readable format\ntoken@cqlsh:vault&gt; select * from \"entries\" limit 1;     //Select statement from \"entries\" table\n\n@ Row 1\n--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n bucket | logical/59ca7834-32f6-a70a-8a61-53dce6dd9c18/oidc_provider/provider\n key    | logical/59ca7834-32f6-a70a-8a61-53dce6dd9c18/oidc_provider/provider/default\n value  | 0x0000000102002d31867373d44b1ae2412b4a1a2bd895c3eec2b2db671ec6a8e323e69539cf6d5e1b43e2e11fabc9cc76ad3c77a722caac47cc3f877013df200e4e6d268e6dbff10ba4007cef042643721101e669ae35ff08842e2d1f70e19de2\n\n(1 rows)\n</code></pre> <p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/notebooks/datastax-studio/","title":"DataStax Studio","text":""},{"location":"pages/tools/notebooks/datastax-studio/#overview","title":"Overview","text":"<p>DataStax Studio is an interactive developer tool for CQL (Cassandra Query Language), Spark SQL, and DSE Graph. Developers and analysts collaborate by mixing code, documentation, query results, and visualizations in self-documenting notebooks.</p> <ul> <li>\u2139\ufe0f Introduction to DataStax Studio</li> <li>\ud83d\udce5 DataStax Studio Quick Install</li> </ul>"},{"location":"pages/tools/notebooks/datastax-studio/#prerequisites","title":"Prerequisites","text":""},{"location":"pages/tools/notebooks/datastax-studio/#datastax-studio-prerequisites","title":"DataStax Studio Prerequisites","text":"<ul> <li>You should have a supported browser</li> <li>You should have a supported version of Java</li> <ul> <li>Recommended: OpenJDK 8</li> <li>Supported: Oracle Java SE 8 (JRE or JDK)</li> </ul> </ul>"},{"location":"pages/tools/notebooks/datastax-studio/#astra-prerequisites","title":"Astra Prerequisites","text":"<ul> <li>You should have an Astra account</li> <li>You should Create an Astra Database</li> <li>You should Have an Astra Token</li> </ul>"},{"location":"pages/tools/notebooks/datastax-studio/#installation-and-setup","title":"Installation and Setup","text":"<p>As mentioned in the Prerequisites above, you must have DataStax Studio already installed. You can follow the quick installation steps here. Once you have successfully installed DataStax Studio, you may proceed to the following steps. </p> <ol> <li>Start up DataStax Studio by running the Studio Server shell script:<ul> <li>Linux:  <pre><code>cd installation_location/datastax-studio-6.8.0\n./bin/server.sh\n</code></pre></li> <li>Windows: <pre><code>C:/&gt; cd installation_location\\datastax-studio-6.8.0\\bin\\\nC:/&gt; server.bat\n</code></pre> Once Studio is running, your output should look something similar to this: <pre><code>Studio is now running at: http://127.0.0.1:9091\n</code></pre></li> </ul> </li> <li> <p>You may now use the <code>localhost</code> URL provided in your terminal or command line to navigate to the DataStax Studio UI. This should look something like this: </p> </li> <li> <p>For this example, we will use the Getting Started with Astra notebook. A notebook is essentially a workspace used to visualize queries from your database, test and run different commands, and more.  </p> </li> <li> <p>On the top right corner of the notebook, click <code>default localhost</code> and then <code>Add Connection</code> to configure a new connection for the notebook. </p> </li> <li> <p>A screen should appear with the options <code>Standard Connection</code> and <code>Astra Connection</code>. For this example, you will select <code>Astra Connection</code>. </p> </li> <li> <p>Here, you will need the credentials that you gathered in the Astra Prerequisites.      <pre><code>Name: &lt;Your Database Name&gt;\nSecure Connection Bundle path: &lt;The path to your SCB locally&gt;\nClient ID: &lt;Your Client ID&gt;\nClient Secret: &lt;Your Client Secret&gt;\n</code></pre> </p> </li> <li> <p>Once you have filled this information out, you can select Test in the bottom right corner. If this is successful, you should see a message that says <code>CQL connected successfully</code>. Once this is completed, click Save. </p> </li> <li> <p>In the upper right hand corner, you should be able to switch the connection to the name of the database you just configured. </p> </li> </ol>"},{"location":"pages/tools/notebooks/datastax-studio/#test-and-validate","title":"Test and Validate","text":"<p>Finally, we will test and validate once more that the connection is validated by submitting a couple test queries.</p> <ol> <li> <p>Click the + symbol in the top-middle of the screen to add a new cell.  </p> </li> <li> <p>In the cell, you can select which Keyspace that you want to query from. </p> </li> <li> <p>Run the following queries to confirm that the connection to your Astra Database is successful. </p> </li> </ol> <p><pre><code>describe tables;\nselect * from &lt;YOUR_TABLE&gt;;\n</code></pre> </p> <p>Once you have received the correct results back, that's it! You have successfully connected DataStax Studio to Astra DB and can use this as a tool to help model your queries. You may also scroll down within the Getting Started with Astra notebook for more examples and recommendations. </p> <p>\ud83c\udfe0 Back to HOME</p>"},{"location":"pages/tools/notebooks/jupyter/","title":"\u2022 Jupyter Notebooks","text":"<p>\ud83c\udfe0 Back to home </p>"},{"location":"pages/tools/notebooks/jupyter/#overview","title":"Overview","text":"<p>Jupyter Notebooks are an execution environment for Julia, Python and R code (hence, Ju-Py-te-R) in technical computing domains, but are especially popular with data scientists working on machine learning models. Jupyter blends the ability to present explanatory text and imagery with interactive code blocks. Jupyter notebooks can run on your own computer, or via a hoted service like Google Colab. </p> <ul> <li> <p>\u2139\ufe0f Google Colab FAQ</p> </li> <li> <p>\u2139\ufe0f Project Jupyter Homepage</p> </li> </ul>"},{"location":"pages/tools/notebooks/jupyter/#get-started","title":"Get Started","text":"Overview Prerequisites Links Astra can be a little tricky to get started with when working inside a Jupyter notebook. This sample notebook shows how to connect to Astra, create a new database, download the secure connect bundle, and load and index data into tables. Finally, just because it's a notebook, we'll train a model and plot the test error from the sample dataset. <ul> <li>You should have an Astra account</li> <li>You should Have an Astra Token (with Administrator privileges)</li> </ul>  Or, download the notebook. Learn about Kaskada from this (non-runnable) notebook that provides an overview of using the Kaskada language to perform feature engineering for a popular Kaggle data set. None  Or, download the notebook. <p>If you open the notebook in Colab, and would like to make changes to it, choose \"Save a copy in Drive\" from the File menu in Colab. Have fun!</p>"},{"location":"pages/tools/notebooks/zeppelin/","title":"\u2022 Apache Zeppelin","text":"<p>s</p> <p></p> <p>Check back soon</p> <p>Nothing to see here yet! Check back for updates! </p>"},{"location":"pages/tools/plugins/astradb-vault-plugin/","title":"\u2022 HashiCorp Vault","text":""},{"location":"pages/tools/plugins/astradb-vault-plugin/#overview","title":"Overview","text":"<p>DataStax Astra DB Plugin for HashiCorp Vault is an open-source project that adds robust token lifecycle management features for Astra DB. Due to the nature of the Astra DB object hierarchy, by default, API tokens are not associated with specific users and currently the tokens do not have metadata descriptions.</p> <p>For more details, see the full Astra DB Plugin for HashiCorp Vault documentation in the plugin\u2019s open-source GitHub repo.</p> <p>Without the plugin, it\u2019s easy to lose track of:</p> <ul> <li>Who created tokens</li> <li>The purpose of each token</li> <li>Which tokens are being used actively</li> </ul> <p>Consequently, there\u2019s no audit trail of who has downloaded and used tokens, and there\u2019s no tracking regarding who may have manually shared tokens with others.</p> <p>Astra DB Plugin for HashiCorp Vault solves these security management issues. To ensure that your token ownership and usage are well understood, the plugin gives you the ability to associate metadata with tokens\u2014such as the user who created each token, and what it is being used for. The plugin also logs who has accessed the tokens.</p>"},{"location":"pages/tools/plugins/astradb-vault-plugin/#what-is-hashi-vault","title":"What is Hashi Vault?","text":"<p>HashiCorp Vault is a widely-used solution across the tech industry. It\u2019s an identity-based secrets and encryption management system. HashiCorp Vault from HashiCorp provides key-value encryption services that are gated by authentication and authorization methods. Access to tokens, secrets, and other sensitive data are securely stored, managed, and tightly controlled. Audit trails are provided. HashiCorp Vault is also extensible via a variety of interfaces, allowing plugins (including Astra DB Plugin for HashiCorp Vault) to contribute to this ecosystem.</p>"},{"location":"pages/tools/plugins/astradb-vault-plugin/#whats-next","title":"What's next?","text":"<p>See the full Astra DB Plugin for HashiCorp Vault documentation in the plugin\u2019s open-source GitHub repo.</p>"},{"location":"pages/tools/plugins/github-actions/","title":"GitHub Actions","text":""},{"location":"pages/tools/plugins/github-actions/#overview","title":"Overview","text":"<p>GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline. You can create workflows that build and test every pull request to your repository, or deploy merged pull requests to production.</p> <p>GitHub Actions goes beyond just DevOps and lets you run workflows when other events happen in your repository. For example, you can run a workflow to automatically add the appropriate labels whenever someone creates a new issue in your repository.</p> <p>GitHub provides Linux, Windows, and macOS virtual machines to run your workflows, or you can host your own self-hosted runners in your own data center or cloud infrastructure.</p> <p>Reference documentation:</p> <ul> <li>\u2139\ufe0f GitHub Documentation</li> <li>\u2139\ufe0f Understanding GitHub Actions</li> </ul>"},{"location":"pages/tools/plugins/github-actions/#prerequisites","title":"Prerequisites","text":"<ul> <li>Create an Astra Database. In the following example, a keyspace called <code>demo</code> is created in the <code>demo</code> database.</li> <li>Create an Astra Token. You should have received your token while creating the database in the previous step.</li> <li>Have a GitHub account and a repository in it.</li> </ul>"},{"location":"pages/tools/plugins/github-actions/#github-repository-configuration","title":"GitHub Repository Configuration","text":"<p>Note</p> <p>Getting started is simple. Ask GitHub for an ubuntu environment, install the Astra CLI, and use the <code>CLI</code> to create a database.</p>"},{"location":"pages/tools/plugins/github-actions/#create-a-secret-for-token","title":"Create a secret for token","text":"<ol> <li>Open your github Repository and locate the tabs <code>Settings</code></li> <li>On the left menu locate `Secrets and variables` and expand to list different options. Click on <code>Actions</code></li> <li>Click on the <code>[New Repository Secret]</code> on the top right hand corner </li> <li>Enter the new secret name <code>ASTRA_DB_APPLICATION_TOKEN</code> and provide the value for your secret </li> <li>The Secret should now be visible in your secret list </li> </ol>"},{"location":"pages/tools/plugins/github-actions/#create-a-new-action","title":"Create a new action","text":"<ul> <li> <p>Create a new folder in your github repository <code>.github/actions</code></p> </li> <li> <p>Create a new Yaml file and name it as you like here i use <code>cli-db-create</code></p> </li> </ul> <p></p> <ul> <li>Populate the file as follows</li> </ul> <pre><code>name: Astra Cli Sample\non:\npush:\nbranches:\n- main\njobs:\ncli-create-db:\nenv:\nASTRA_DB_APPLICATION_TOKEN: ${{ secrets.ASTRA_DB_APPLICATION_TOKEN }}\nASTRA_DB_NAME: demo\nASTRA_DB_KEYSPACE: demo\nTERM: linux\nruns-on: ubuntu-latest\nsteps:\n- name: Checkout\nuses: actions/checkout@v3\n- name: Install Astra CLI\nrun: curl -Ls \"https://dtsx.io/get-astra-cli\" | bash\n- name: Create DB\nrun: |\necho $ASTRA_DB_NAME\n/home/runner/.astra/cli/astra db create $ASTRA_DB_NAME -k $ASTRA_DB_KEYSPACE --token $ASTRA_DB_APPLICATION_TOKEN --if-not-exists \n</code></pre> <p>Information Regarding the variables</p> <p>ASTRA_DB_NAME: The name of your database. ASTRA_DB_KEYSPACE: The keyspace (if not provided defaulting to same name as db). ASTRA_DB_APPLICATION_TOKEN: The secret we defined before.</p>"},{"location":"pages/tools/plugins/github-actions/#run-the-action","title":"Run the action","text":"<p>With the configuration above the CLI is triggered at each commit. As we provided the options <code>--if-not-exists</code> in the command line, it is not harmful.</p> <ul> <li>Locate the tab <code>ACTIONS</code> in your github repository and select the last execution</li> </ul> <p></p> <ul> <li>You will get the following output</li> </ul> <p></p> <p>Here is a sample repository you can use as a reference.</p>"},{"location":"pages/tools/plugins/github-actions/#whats-next","title":"What's NEXT ?","text":"<p>If you are not familiar with the CLI all available commands are available in the documentation or in the help of the tools.</p> <pre><code>$&gt; astra help db create\n\nNAME\n        astra db create - Create a database with cli\n\nSYNOPSIS\n        astra db create [ --async ] [ {-cf | --config-file} &lt;CONFIG_FILE&gt; ]\n                [ {-conf | --config} &lt;CONFIG_SECTION&gt; ]\n                [ {--if-not-exist | --if-not-exists} ]\n                [ {-k | --keyspace} &lt;KEYSPACE&gt; ] [ --no-color ]\n                [ {-o | --output} &lt;FORMAT&gt; ] [ {-r | --region} &lt;DB_REGION&gt; ]\n                [ --timeout &lt;timeout&gt; ] [ --token &lt;AUTH_TOKEN&gt; ]\n                [ {-v | --verbose} ] [ --wait ] [--] &lt;DB&gt;\n\nOPTIONS\n        --async\n            Will not wait for the resource to become available\n\n        -cf &lt;CONFIG_FILE&gt;, --config-file &lt;CONFIG_FILE&gt;\n            Configuration file (default = ~/.astrarc)\n\n        -conf &lt;CONFIG_SECTION&gt;, --config &lt;CONFIG_SECTION&gt;\n            Section in configuration file (default = ~/.astrarc)\n\n        --if-not-exist, --if-not-exists\n            will create a new DB only if none with same name\n\n        -k &lt;KEYSPACE&gt;, --keyspace &lt;KEYSPACE&gt;\n            Default keyspace created with the Db\n\n        --no-color\n            Remove all colors in output\n\n        -o &lt;FORMAT&gt;, --output &lt;FORMAT&gt;\n            Output format, valid values are: human,json,csv\n\n        -r &lt;DB_REGION&gt;, --region &lt;DB_REGION&gt;\n            Cloud provider region to provision\n\n        --timeout &lt;timeout&gt;\n            Provide a limit to the wait period in seconds, default is 300s.\n\n        --token &lt;AUTH_TOKEN&gt;\n            Key to use authenticate each call.\n\n        -v, --verbose\n            Verbose mode with log in console\n\n        --wait\n            Will wait until the database become ACTIVE\n\n        --\n            This option can be used to separate command-line options from the\n            list of arguments (useful when arguments might be mistaken for\n            command-line options)\n\n        &lt;DB&gt;\n            Database name (not unique)\n</code></pre>"}]}